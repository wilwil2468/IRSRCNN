{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bb1382",
   "metadata": {
    "id": "0qFuIBWYtEA-",
    "papermill": {
     "duration": 0.003084,
     "end_time": "2025-05-03T07:17:38.912123",
     "exception": false,
     "start_time": "2025-05-03T07:17:38.909039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64713ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:17:38.918454Z",
     "iopub.status.busy": "2025-05-03T07:17:38.918146Z",
     "iopub.status.idle": "2025-05-03T07:17:43.293129Z",
     "shell.execute_reply": "2025-05-03T07:17:43.292109Z"
    },
    "papermill": {
     "duration": 4.379969,
     "end_time": "2025-05-03T07:17:43.294828",
     "exception": false,
     "start_time": "2025-05-03T07:17:38.914859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lmdb\r\n",
      "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lmdb\r\n",
      "Successfully installed lmdb-1.6.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0014f52d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:17:43.301492Z",
     "iopub.status.busy": "2025-05-03T07:17:43.301213Z",
     "iopub.status.idle": "2025-05-03T07:18:21.639350Z",
     "shell.execute_reply": "2025-05-03T07:18:21.638431Z"
    },
    "id": "OVwQVHdppYwh",
    "papermill": {
     "duration": 38.343194,
     "end_time": "2025-05-03T07:18:21.640904",
     "exception": false,
     "start_time": "2025-05-03T07:17:43.297710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'IRSRCNN'...\r\n",
      "remote: Enumerating objects: 12611, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (72/72), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (40/40), done.\u001b[K\r\n",
      "remote: Total 12611 (delta 47), reused 56 (delta 32), pack-reused 12539 (from 2)\u001b[K\r\n",
      "Receiving objects: 100% (12611/12611), 1.12 GiB | 40.43 MiB/s, done.\r\n",
      "Resolving deltas: 100% (259/259), done.\r\n",
      "Updating files: 100% (12014/12014), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/wilwil2468/IRSRCNN.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112eeae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:18:21.662882Z",
     "iopub.status.busy": "2025-05-03T07:18:21.662573Z",
     "iopub.status.idle": "2025-05-03T07:18:21.668797Z",
     "shell.execute_reply": "2025-05-03T07:18:21.668141Z"
    },
    "id": "xAcYhhlQqRYx",
    "papermill": {
     "duration": 0.018856,
     "end_time": "2025-05-03T07:18:21.669877",
     "exception": false,
     "start_time": "2025-05-03T07:18:21.651021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/IRSRCNN\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/IRSRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e727843",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:18:21.691015Z",
     "iopub.status.busy": "2025-05-03T07:18:21.690739Z",
     "iopub.status.idle": "2025-05-03T07:18:22.177802Z",
     "shell.execute_reply": "2025-05-03T07:18:22.176969Z"
    },
    "id": "6TPUBIpZq0i7",
    "papermill": {
     "duration": 0.499443,
     "end_time": "2025-05-03T07:18:22.179337",
     "exception": false,
     "start_time": "2025-05-03T07:18:21.679894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22db54b5",
   "metadata": {
    "papermill": {
     "duration": 0.01003,
     "end_time": "2025-05-03T07:18:22.199730",
     "exception": false,
     "start_time": "2025-05-03T07:18:22.189700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For “915” (k9–k1–k5) you used hr_crop_size = 21\n",
    "\n",
    "For “935” (k9–k3–k5) you used hr_crop_size = 19\n",
    "\n",
    "For “955” (k9–k5–k5) you used hr_crop_size = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "938c5353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:18:22.221186Z",
     "iopub.status.busy": "2025-05-03T07:18:22.220893Z",
     "iopub.status.idle": "2025-05-03T07:18:22.341238Z",
     "shell.execute_reply": "2025-05-03T07:18:22.340159Z"
    },
    "papermill": {
     "duration": 0.133172,
     "end_time": "2025-05-03T07:18:22.342848",
     "exception": false,
     "start_time": "2025-05-03T07:18:22.209676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm checkpoint/SRCNN955/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a3b5ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:18:22.364353Z",
     "iopub.status.busy": "2025-05-03T07:18:22.363712Z",
     "iopub.status.idle": "2025-05-03T07:20:09.469657Z",
     "shell.execute_reply": "2025-05-03T07:20:09.468419Z"
    },
    "papermill": {
     "duration": 107.119006,
     "end_time": "2025-05-03T07:20:09.471871",
     "exception": false,
     "start_time": "2025-05-03T07:18:22.352865",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Dumped 1879850 patches → train_patches_955.lmdb\r\n"
     ]
    }
   ],
   "source": [
    "!python precompute_patches.py dataset/train train_patches_955.lmdb \\\n",
    "    --hr 17 --lr 33 --per-image 175 --augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f9d6b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T07:20:09.590275Z",
     "iopub.status.busy": "2025-05-03T07:20:09.589775Z",
     "iopub.status.idle": "2025-05-03T07:20:22.615072Z",
     "shell.execute_reply": "2025-05-03T07:20:22.614289Z"
    },
    "papermill": {
     "duration": 13.09843,
     "end_time": "2025-05-03T07:20:22.617458",
     "exception": false,
     "start_time": "2025-05-03T07:20:09.519028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Dumped 200200 patches → valid_patches_955.lmdb\r\n"
     ]
    }
   ],
   "source": [
    "!python precompute_patches.py dataset/validation valid_patches_955.lmdb \\\n",
    "    --hr 17 --lr 33 --per-image 175 --augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b686ad57",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-03T07:20:22.638959Z",
     "iopub.status.busy": "2025-05-03T07:20:22.638659Z",
     "iopub.status.idle": "2025-05-03T09:29:28.708674Z",
     "shell.execute_reply": "2025-05-03T09:29:28.707717Z"
    },
    "id": "QzWvEedFF3o2",
    "papermill": {
     "duration": 7746.082973,
     "end_time": "2025-05-03T09:29:28.710403",
     "exception": false,
     "start_time": "2025-05-03T07:20:22.627430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Loading train patches from LMDB: train_patches_955.lmdb\r\n",
      "→ Loading valid patches from LMDB: valid_patches_955.lmdb\r\n",
      "Training start..\r\n",
      "[07:20:33] Starting training for 300000 steps (from step 0)\r\n",
      "[07:20:38] Progress step 100/300000 — loss 0.1674265 — PSNR 11.807\r\n",
      "[07:20:42] Progress step 200/300000 — loss 0.0851593 — PSNR 18.623\r\n",
      "[07:20:45] Progress step 300/300000 — loss 0.0577239 — PSNR 20.912\r\n",
      "[07:20:49] Progress step 400/300000 — loss 0.0439933 — PSNR 22.076\r\n",
      "[07:20:52] Progress step 500/300000 — loss 0.0357567 — PSNR 22.771\r\n",
      "[07:20:55] Progress step 600/300000 — loss 0.0302754 — PSNR 23.220\r\n",
      "[07:20:58] Progress step 700/300000 — loss 0.0263423 — PSNR 23.568\r\n",
      "[07:21:02] Progress step 800/300000 — loss 0.0234086 — PSNR 23.804\r\n",
      "[07:21:05] Progress step 900/300000 — loss 0.0211131 — PSNR 24.010\r\n",
      "[07:21:08] Progress step 1000/300000 — loss 0.0192870 — PSNR 24.158\r\n",
      "[07:21:27] Eval @ 1000: train_loss 0.0192870 — train_PSNR 24.158 — val_loss 0.0027541 — val_PSNR 26.231\r\n",
      "[07:21:27] Saved best model at step 1000\r\n",
      "[07:21:30] Progress step 1100/300000 — loss 0.0027624 — PSNR 25.637\r\n",
      "[07:21:33] Progress step 1200/300000 — loss 0.0027462 — PSNR 25.664\r\n",
      "[07:21:36] Progress step 1300/300000 — loss 0.0027733 — PSNR 25.618\r\n",
      "[07:21:39] Progress step 1400/300000 — loss 0.0027719 — PSNR 25.620\r\n",
      "[07:21:42] Progress step 1500/300000 — loss 0.0027707 — PSNR 25.620\r\n",
      "[07:21:45] Progress step 1600/300000 — loss 0.0027679 — PSNR 25.625\r\n",
      "[07:21:48] Progress step 1700/300000 — loss 0.0027730 — PSNR 25.615\r\n",
      "[07:21:51] Progress step 1800/300000 — loss 0.0027784 — PSNR 25.606\r\n",
      "[07:21:54] Progress step 1900/300000 — loss 0.0027790 — PSNR 25.604\r\n",
      "[07:21:57] Progress step 2000/300000 — loss 0.0027757 — PSNR 25.610\r\n",
      "[07:21:57] Eval @ 2000: train_loss 0.0027757 — train_PSNR 25.610 — val_loss 0.0033773 — val_PSNR 24.714\r\n",
      "[07:21:59] Progress step 2100/300000 — loss 0.0026718 — PSNR 25.759\r\n",
      "[07:22:02] Progress step 2200/300000 — loss 0.0027189 — PSNR 25.691\r\n",
      "[07:22:05] Progress step 2300/300000 — loss 0.0027170 — PSNR 25.697\r\n",
      "[07:22:08] Progress step 2400/300000 — loss 0.0027085 — PSNR 25.712\r\n",
      "[07:22:10] Progress step 2500/300000 — loss 0.0026989 — PSNR 25.728\r\n",
      "[07:22:13] Progress step 2600/300000 — loss 0.0026943 — PSNR 25.736\r\n",
      "[07:22:16] Progress step 2700/300000 — loss 0.0026911 — PSNR 25.742\r\n",
      "[07:22:18] Progress step 2800/300000 — loss 0.0026903 — PSNR 25.743\r\n",
      "[07:22:21] Progress step 2900/300000 — loss 0.0026952 — PSNR 25.735\r\n",
      "[07:22:23] Progress step 3000/300000 — loss 0.0026944 — PSNR 25.737\r\n",
      "[07:22:42] Eval @ 3000: train_loss 0.0026944 — train_PSNR 25.737 — val_loss 0.0026688 — val_PSNR 26.364\r\n",
      "[07:22:42] Saved best model at step 3000\r\n",
      "[07:22:45] Progress step 3100/300000 — loss 0.0027139 — PSNR 25.694\r\n",
      "[07:22:47] Progress step 3200/300000 — loss 0.0027317 — PSNR 25.674\r\n",
      "[07:22:50] Progress step 3300/300000 — loss 0.0027129 — PSNR 25.707\r\n",
      "[07:22:52] Progress step 3400/300000 — loss 0.0027041 — PSNR 25.719\r\n",
      "[07:22:55] Progress step 3500/300000 — loss 0.0026982 — PSNR 25.729\r\n",
      "[07:22:57] Progress step 3600/300000 — loss 0.0027004 — PSNR 25.726\r\n",
      "[07:23:00] Progress step 3700/300000 — loss 0.0026975 — PSNR 25.731\r\n",
      "[07:23:02] Progress step 3800/300000 — loss 0.0027021 — PSNR 25.724\r\n",
      "[07:23:04] Progress step 3900/300000 — loss 0.0026966 — PSNR 25.733\r\n",
      "[07:23:07] Progress step 4000/300000 — loss 0.0026927 — PSNR 25.739\r\n",
      "[07:23:07] Eval @ 4000: train_loss 0.0026927 — train_PSNR 25.739 — val_loss 0.0032861 — val_PSNR 24.833\r\n",
      "[07:23:09] Progress step 4100/300000 — loss 0.0027179 — PSNR 25.692\r\n",
      "[07:23:12] Progress step 4200/300000 — loss 0.0026941 — PSNR 25.741\r\n",
      "[07:23:14] Progress step 4300/300000 — loss 0.0026828 — PSNR 25.758\r\n",
      "[07:23:16] Progress step 4400/300000 — loss 0.0026898 — PSNR 25.745\r\n",
      "[07:23:18] Progress step 4500/300000 — loss 0.0026969 — PSNR 25.733\r\n",
      "[07:23:21] Progress step 4600/300000 — loss 0.0026941 — PSNR 25.739\r\n",
      "[07:23:23] Progress step 4700/300000 — loss 0.0027004 — PSNR 25.730\r\n",
      "[07:23:25] Progress step 4800/300000 — loss 0.0026943 — PSNR 25.740\r\n",
      "[07:23:28] Progress step 4900/300000 — loss 0.0027025 — PSNR 25.727\r\n",
      "[07:23:30] Progress step 5000/300000 — loss 0.0026989 — PSNR 25.732\r\n",
      "[07:23:49] Eval @ 5000: train_loss 0.0026989 — train_PSNR 25.732 — val_loss 0.0026621 — val_PSNR 26.372\r\n",
      "[07:23:49] Saved best model at step 5000\r\n",
      "[07:23:51] Progress step 5100/300000 — loss 0.0026578 — PSNR 25.799\r\n",
      "[07:23:53] Progress step 5200/300000 — loss 0.0026678 — PSNR 25.783\r\n",
      "[07:23:55] Progress step 5300/300000 — loss 0.0026734 — PSNR 25.773\r\n",
      "[07:23:58] Progress step 5400/300000 — loss 0.0026827 — PSNR 25.759\r\n",
      "[07:24:00] Progress step 5500/300000 — loss 0.0026837 — PSNR 25.757\r\n",
      "[07:24:02] Progress step 5600/300000 — loss 0.0027001 — PSNR 25.731\r\n",
      "[07:24:04] Progress step 5700/300000 — loss 0.0026953 — PSNR 25.737\r\n",
      "[07:24:06] Progress step 5800/300000 — loss 0.0026949 — PSNR 25.738\r\n",
      "[07:24:09] Progress step 5900/300000 — loss 0.0026872 — PSNR 25.750\r\n",
      "[07:24:11] Progress step 6000/300000 — loss 0.0026850 — PSNR 25.754\r\n",
      "[07:24:11] Eval @ 6000: train_loss 0.0026850 — train_PSNR 25.754 — val_loss 0.0032656 — val_PSNR 24.860\r\n",
      "[07:24:13] Progress step 6100/300000 — loss 0.0027300 — PSNR 25.687\r\n",
      "[07:24:15] Progress step 6200/300000 — loss 0.0027185 — PSNR 25.704\r\n",
      "[07:24:17] Progress step 6300/300000 — loss 0.0027213 — PSNR 25.698\r\n",
      "[07:24:19] Progress step 6400/300000 — loss 0.0027110 — PSNR 25.715\r\n",
      "[07:24:21] Progress step 6500/300000 — loss 0.0027224 — PSNR 25.697\r\n",
      "[07:24:23] Progress step 6600/300000 — loss 0.0027346 — PSNR 25.677\r\n",
      "[07:24:25] Progress step 6700/300000 — loss 0.0027296 — PSNR 25.686\r\n",
      "[07:24:27] Progress step 6800/300000 — loss 0.0027300 — PSNR 25.684\r\n",
      "[07:24:29] Progress step 6900/300000 — loss 0.0027329 — PSNR 25.680\r\n",
      "[07:24:31] Progress step 7000/300000 — loss 0.0027344 — PSNR 25.677\r\n",
      "[07:24:50] Eval @ 7000: train_loss 0.0027344 — train_PSNR 25.677 — val_loss 0.0026579 — val_PSNR 26.380\r\n",
      "[07:24:50] Saved best model at step 7000\r\n",
      "[07:24:52] Progress step 7100/300000 — loss 0.0027113 — PSNR 25.707\r\n",
      "[07:24:54] Progress step 7200/300000 — loss 0.0026906 — PSNR 25.741\r\n",
      "[07:24:56] Progress step 7300/300000 — loss 0.0026985 — PSNR 25.729\r\n",
      "[07:24:58] Progress step 7400/300000 — loss 0.0026903 — PSNR 25.745\r\n",
      "[07:25:00] Progress step 7500/300000 — loss 0.0026931 — PSNR 25.739\r\n",
      "[07:25:02] Progress step 7600/300000 — loss 0.0026892 — PSNR 25.747\r\n",
      "[07:25:04] Progress step 7700/300000 — loss 0.0026832 — PSNR 25.757\r\n",
      "[07:25:06] Progress step 7800/300000 — loss 0.0026837 — PSNR 25.756\r\n",
      "[07:25:08] Progress step 7900/300000 — loss 0.0026828 — PSNR 25.756\r\n",
      "[07:25:10] Progress step 8000/300000 — loss 0.0026788 — PSNR 25.762\r\n",
      "[07:25:10] Eval @ 8000: train_loss 0.0026788 — train_PSNR 25.762 — val_loss 0.0032748 — val_PSNR 24.848\r\n",
      "[07:25:12] Progress step 8100/300000 — loss 0.0026854 — PSNR 25.750\r\n",
      "[07:25:14] Progress step 8200/300000 — loss 0.0027182 — PSNR 25.700\r\n",
      "[07:25:16] Progress step 8300/300000 — loss 0.0027130 — PSNR 25.705\r\n",
      "[07:25:18] Progress step 8400/300000 — loss 0.0027078 — PSNR 25.713\r\n",
      "[07:25:20] Progress step 8500/300000 — loss 0.0027069 — PSNR 25.716\r\n",
      "[07:25:22] Progress step 8600/300000 — loss 0.0027171 — PSNR 25.701\r\n",
      "[07:25:24] Progress step 8700/300000 — loss 0.0027146 — PSNR 25.707\r\n",
      "[07:25:26] Progress step 8800/300000 — loss 0.0027099 — PSNR 25.714\r\n",
      "[07:25:27] Progress step 8900/300000 — loss 0.0027013 — PSNR 25.728\r\n",
      "[07:25:29] Progress step 9000/300000 — loss 0.0026970 — PSNR 25.734\r\n",
      "[07:25:48] Eval @ 9000: train_loss 0.0026970 — train_PSNR 25.734 — val_loss 0.0026551 — val_PSNR 26.386\r\n",
      "[07:25:48] Saved best model at step 9000\r\n",
      "[07:25:50] Progress step 9100/300000 — loss 0.0026864 — PSNR 25.747\r\n",
      "[07:25:52] Progress step 9200/300000 — loss 0.0027363 — PSNR 25.675\r\n",
      "[07:25:54] Progress step 9300/300000 — loss 0.0027261 — PSNR 25.688\r\n",
      "[07:25:56] Progress step 9400/300000 — loss 0.0027210 — PSNR 25.694\r\n",
      "[07:25:58] Progress step 9500/300000 — loss 0.0027241 — PSNR 25.691\r\n",
      "[07:25:59] Progress step 9600/300000 — loss 0.0027290 — PSNR 25.682\r\n",
      "[07:26:01] Progress step 9700/300000 — loss 0.0027269 — PSNR 25.685\r\n",
      "[07:26:03] Progress step 9800/300000 — loss 0.0027215 — PSNR 25.693\r\n",
      "[07:26:05] Progress step 9900/300000 — loss 0.0027117 — PSNR 25.708\r\n",
      "[07:26:07] Progress step 10000/300000 — loss 0.0027117 — PSNR 25.709\r\n",
      "[07:26:07] Eval @ 10000: train_loss 0.0027117 — train_PSNR 25.709 — val_loss 0.0032602 — val_PSNR 24.868\r\n",
      "[07:26:09] Progress step 10100/300000 — loss 0.0026389 — PSNR 25.819\r\n",
      "[07:26:11] Progress step 10200/300000 — loss 0.0026545 — PSNR 25.799\r\n",
      "[07:26:12] Progress step 10300/300000 — loss 0.0026790 — PSNR 25.761\r\n",
      "[07:26:14] Progress step 10400/300000 — loss 0.0026867 — PSNR 25.750\r\n",
      "[07:26:16] Progress step 10500/300000 — loss 0.0026980 — PSNR 25.731\r\n",
      "[07:26:18] Progress step 10600/300000 — loss 0.0027042 — PSNR 25.721\r\n",
      "[07:26:20] Progress step 10700/300000 — loss 0.0027027 — PSNR 25.722\r\n",
      "[07:26:22] Progress step 10800/300000 — loss 0.0027040 — PSNR 25.721\r\n",
      "[07:26:23] Progress step 10900/300000 — loss 0.0027052 — PSNR 25.717\r\n",
      "[07:26:25] Progress step 11000/300000 — loss 0.0026992 — PSNR 25.726\r\n",
      "[07:26:45] Eval @ 11000: train_loss 0.0026992 — train_PSNR 25.726 — val_loss 0.0026652 — val_PSNR 26.363\r\n",
      "[07:26:46] Progress step 11100/300000 — loss 0.0026822 — PSNR 25.747\r\n",
      "[07:26:48] Progress step 11200/300000 — loss 0.0026889 — PSNR 25.743\r\n",
      "[07:26:50] Progress step 11300/300000 — loss 0.0027075 — PSNR 25.715\r\n",
      "[07:26:52] Progress step 11400/300000 — loss 0.0027073 — PSNR 25.715\r\n",
      "[07:26:54] Progress step 11500/300000 — loss 0.0027064 — PSNR 25.715\r\n",
      "[07:26:56] Progress step 11600/300000 — loss 0.0026976 — PSNR 25.729\r\n",
      "[07:26:57] Progress step 11700/300000 — loss 0.0026861 — PSNR 25.749\r\n",
      "[07:26:59] Progress step 11800/300000 — loss 0.0026908 — PSNR 25.741\r\n",
      "[07:27:01] Progress step 11900/300000 — loss 0.0026988 — PSNR 25.729\r\n",
      "[07:27:03] Progress step 12000/300000 — loss 0.0026959 — PSNR 25.733\r\n",
      "[07:27:03] Eval @ 12000: train_loss 0.0026959 — train_PSNR 25.733 — val_loss 0.0032805 — val_PSNR 24.841\r\n",
      "[07:27:05] Progress step 12100/300000 — loss 0.0027039 — PSNR 25.724\r\n",
      "[07:27:06] Progress step 12200/300000 — loss 0.0026830 — PSNR 25.754\r\n",
      "[07:27:08] Progress step 12300/300000 — loss 0.0026585 — PSNR 25.795\r\n",
      "[07:27:10] Progress step 12400/300000 — loss 0.0026465 — PSNR 25.814\r\n",
      "[07:27:12] Progress step 12500/300000 — loss 0.0026609 — PSNR 25.789\r\n",
      "[07:27:14] Progress step 12600/300000 — loss 0.0026630 — PSNR 25.787\r\n",
      "[07:27:15] Progress step 12700/300000 — loss 0.0026750 — PSNR 25.768\r\n",
      "[07:27:17] Progress step 12800/300000 — loss 0.0026755 — PSNR 25.767\r\n",
      "[07:27:19] Progress step 12900/300000 — loss 0.0026798 — PSNR 25.760\r\n",
      "[07:27:21] Progress step 13000/300000 — loss 0.0026768 — PSNR 25.765\r\n",
      "[07:27:40] Eval @ 13000: train_loss 0.0026768 — train_PSNR 25.765 — val_loss 0.0026693 — val_PSNR 26.354\r\n",
      "[07:27:41] Progress step 13100/300000 — loss 0.0027210 — PSNR 25.697\r\n",
      "[07:27:43] Progress step 13200/300000 — loss 0.0027225 — PSNR 25.692\r\n",
      "[07:27:45] Progress step 13300/300000 — loss 0.0027175 — PSNR 25.700\r\n",
      "[07:27:47] Progress step 13400/300000 — loss 0.0027068 — PSNR 25.715\r\n",
      "[07:27:48] Progress step 13500/300000 — loss 0.0027042 — PSNR 25.720\r\n",
      "[07:27:50] Progress step 13600/300000 — loss 0.0027066 — PSNR 25.715\r\n",
      "[07:27:52] Progress step 13700/300000 — loss 0.0027062 — PSNR 25.715\r\n",
      "[07:27:54] Progress step 13800/300000 — loss 0.0027042 — PSNR 25.719\r\n",
      "[07:27:55] Progress step 13900/300000 — loss 0.0027084 — PSNR 25.712\r\n",
      "[07:27:57] Progress step 14000/300000 — loss 0.0027083 — PSNR 25.713\r\n",
      "[07:27:57] Eval @ 14000: train_loss 0.0027083 — train_PSNR 25.713 — val_loss 0.0032996 — val_PSNR 24.815\r\n",
      "[07:27:59] Progress step 14100/300000 — loss 0.0026948 — PSNR 25.741\r\n",
      "[07:28:01] Progress step 14200/300000 — loss 0.0027228 — PSNR 25.694\r\n",
      "[07:28:02] Progress step 14300/300000 — loss 0.0027272 — PSNR 25.685\r\n",
      "[07:28:04] Progress step 14400/300000 — loss 0.0027281 — PSNR 25.685\r\n",
      "[07:28:06] Progress step 14500/300000 — loss 0.0027285 — PSNR 25.684\r\n",
      "[07:28:07] Progress step 14600/300000 — loss 0.0027337 — PSNR 25.677\r\n",
      "[07:28:09] Progress step 14700/300000 — loss 0.0027275 — PSNR 25.686\r\n",
      "[07:28:11] Progress step 14800/300000 — loss 0.0027272 — PSNR 25.685\r\n",
      "[07:28:12] Progress step 14900/300000 — loss 0.0027193 — PSNR 25.698\r\n",
      "[07:28:14] Progress step 15000/300000 — loss 0.0027092 — PSNR 25.714\r\n",
      "[07:28:33] Eval @ 15000: train_loss 0.0027092 — train_PSNR 25.714 — val_loss 0.0027283 — val_PSNR 26.231\r\n",
      "[07:28:35] Progress step 15100/300000 — loss 0.0027372 — PSNR 25.678\r\n",
      "[07:28:36] Progress step 15200/300000 — loss 0.0027165 — PSNR 25.707\r\n",
      "[07:28:38] Progress step 15300/300000 — loss 0.0027029 — PSNR 25.728\r\n",
      "[07:28:40] Progress step 15400/300000 — loss 0.0027009 — PSNR 25.729\r\n",
      "[07:28:42] Progress step 15500/300000 — loss 0.0027100 — PSNR 25.712\r\n",
      "[07:28:43] Progress step 15600/300000 — loss 0.0027138 — PSNR 25.707\r\n",
      "[07:28:45] Progress step 15700/300000 — loss 0.0027216 — PSNR 25.696\r\n",
      "[07:28:47] Progress step 15800/300000 — loss 0.0027186 — PSNR 25.700\r\n",
      "[07:28:49] Progress step 15900/300000 — loss 0.0027200 — PSNR 25.697\r\n",
      "[07:28:50] Progress step 16000/300000 — loss 0.0027234 — PSNR 25.691\r\n",
      "[07:28:50] Eval @ 16000: train_loss 0.0027234 — train_PSNR 25.691 — val_loss 0.0032651 — val_PSNR 24.861\r\n",
      "[07:28:52] Progress step 16100/300000 — loss 0.0026756 — PSNR 25.774\r\n",
      "[07:28:54] Progress step 16200/300000 — loss 0.0026568 — PSNR 25.801\r\n",
      "[07:28:55] Progress step 16300/300000 — loss 0.0026716 — PSNR 25.778\r\n",
      "[07:28:57] Progress step 16400/300000 — loss 0.0026879 — PSNR 25.751\r\n",
      "[07:28:59] Progress step 16500/300000 — loss 0.0026928 — PSNR 25.743\r\n",
      "[07:29:01] Progress step 16600/300000 — loss 0.0026887 — PSNR 25.750\r\n",
      "[07:29:02] Progress step 16700/300000 — loss 0.0026864 — PSNR 25.753\r\n",
      "[07:29:04] Progress step 16800/300000 — loss 0.0026816 — PSNR 25.760\r\n",
      "[07:29:06] Progress step 16900/300000 — loss 0.0026767 — PSNR 25.768\r\n",
      "[07:29:07] Progress step 17000/300000 — loss 0.0026746 — PSNR 25.771\r\n",
      "[07:29:26] Eval @ 17000: train_loss 0.0026746 — train_PSNR 25.771 — val_loss 0.0026551 — val_PSNR 26.384\r\n",
      "[07:29:28] Progress step 17100/300000 — loss 0.0026926 — PSNR 25.732\r\n",
      "[07:29:30] Progress step 17200/300000 — loss 0.0027064 — PSNR 25.720\r\n",
      "[07:29:31] Progress step 17300/300000 — loss 0.0026981 — PSNR 25.734\r\n",
      "[07:29:33] Progress step 17400/300000 — loss 0.0026941 — PSNR 25.740\r\n",
      "[07:29:35] Progress step 17500/300000 — loss 0.0026851 — PSNR 25.755\r\n",
      "[07:29:36] Progress step 17600/300000 — loss 0.0026849 — PSNR 25.754\r\n",
      "[07:29:38] Progress step 17700/300000 — loss 0.0026933 — PSNR 25.741\r\n",
      "[07:29:40] Progress step 17800/300000 — loss 0.0026855 — PSNR 25.753\r\n",
      "[07:29:42] Progress step 17900/300000 — loss 0.0026853 — PSNR 25.753\r\n",
      "[07:29:43] Progress step 18000/300000 — loss 0.0026877 — PSNR 25.749\r\n",
      "[07:29:43] Eval @ 18000: train_loss 0.0026877 — train_PSNR 25.749 — val_loss 0.0032991 — val_PSNR 24.816\r\n",
      "[07:29:45] Progress step 18100/300000 — loss 0.0027160 — PSNR 25.697\r\n",
      "[07:29:47] Progress step 18200/300000 — loss 0.0026885 — PSNR 25.745\r\n",
      "[07:29:48] Progress step 18300/300000 — loss 0.0027199 — PSNR 25.697\r\n",
      "[07:29:50] Progress step 18400/300000 — loss 0.0027049 — PSNR 25.723\r\n",
      "[07:29:52] Progress step 18500/300000 — loss 0.0026966 — PSNR 25.734\r\n",
      "[07:29:54] Progress step 18600/300000 — loss 0.0026911 — PSNR 25.742\r\n",
      "[07:29:55] Progress step 18700/300000 — loss 0.0026895 — PSNR 25.744\r\n",
      "[07:29:57] Progress step 18800/300000 — loss 0.0026852 — PSNR 25.750\r\n",
      "[07:29:59] Progress step 18900/300000 — loss 0.0026899 — PSNR 25.743\r\n",
      "[07:30:00] Progress step 19000/300000 — loss 0.0026887 — PSNR 25.745\r\n",
      "[07:30:19] Eval @ 19000: train_loss 0.0026887 — train_PSNR 25.745 — val_loss 0.0026738 — val_PSNR 26.344\r\n",
      "[07:30:21] Progress step 19100/300000 — loss 0.0026842 — PSNR 25.752\r\n",
      "[07:30:23] Progress step 19200/300000 — loss 0.0026849 — PSNR 25.756\r\n",
      "[07:30:24] Progress step 19300/300000 — loss 0.0026948 — PSNR 25.739\r\n",
      "[07:30:26] Progress step 19400/300000 — loss 0.0026901 — PSNR 25.745\r\n",
      "[07:30:28] Progress step 19500/300000 — loss 0.0026986 — PSNR 25.731\r\n",
      "[07:30:29] Progress step 19600/300000 — loss 0.0026913 — PSNR 25.743\r\n",
      "[07:30:31] Progress step 19700/300000 — loss 0.0027000 — PSNR 25.729\r\n",
      "[07:30:33] Progress step 19800/300000 — loss 0.0026972 — PSNR 25.734\r\n",
      "[07:30:35] Progress step 19900/300000 — loss 0.0026969 — PSNR 25.735\r\n",
      "[07:30:36] Progress step 20000/300000 — loss 0.0026977 — PSNR 25.735\r\n",
      "[07:30:36] Eval @ 20000: train_loss 0.0026977 — train_PSNR 25.735 — val_loss 0.0032627 — val_PSNR 24.864\r\n",
      "[07:30:38] Progress step 20100/300000 — loss 0.0027213 — PSNR 25.693\r\n",
      "[07:30:40] Progress step 20200/300000 — loss 0.0026853 — PSNR 25.751\r\n",
      "[07:30:41] Progress step 20300/300000 — loss 0.0026943 — PSNR 25.735\r\n",
      "[07:30:43] Progress step 20400/300000 — loss 0.0026933 — PSNR 25.735\r\n",
      "[07:30:45] Progress step 20500/300000 — loss 0.0026927 — PSNR 25.739\r\n",
      "[07:30:46] Progress step 20600/300000 — loss 0.0026998 — PSNR 25.728\r\n",
      "[07:30:48] Progress step 20700/300000 — loss 0.0027037 — PSNR 25.724\r\n",
      "[07:30:50] Progress step 20800/300000 — loss 0.0027011 — PSNR 25.727\r\n",
      "[07:30:51] Progress step 20900/300000 — loss 0.0027044 — PSNR 25.722\r\n",
      "[07:30:53] Progress step 21000/300000 — loss 0.0027007 — PSNR 25.727\r\n",
      "[07:31:12] Eval @ 21000: train_loss 0.0027007 — train_PSNR 25.727 — val_loss 0.0026505 — val_PSNR 26.393\r\n",
      "[07:31:12] Saved best model at step 21000\r\n",
      "[07:31:14] Progress step 21100/300000 — loss 0.0026724 — PSNR 25.774\r\n",
      "[07:31:15] Progress step 21200/300000 — loss 0.0026551 — PSNR 25.803\r\n",
      "[07:31:17] Progress step 21300/300000 — loss 0.0026772 — PSNR 25.766\r\n",
      "[07:31:19] Progress step 21400/300000 — loss 0.0026668 — PSNR 25.781\r\n",
      "[07:31:20] Progress step 21500/300000 — loss 0.0026837 — PSNR 25.754\r\n",
      "[07:31:22] Progress step 21600/300000 — loss 0.0026863 — PSNR 25.750\r\n",
      "[07:31:24] Progress step 21700/300000 — loss 0.0026990 — PSNR 25.731\r\n",
      "[07:31:25] Progress step 21800/300000 — loss 0.0027003 — PSNR 25.729\r\n",
      "[07:31:27] Progress step 21900/300000 — loss 0.0026962 — PSNR 25.736\r\n",
      "[07:31:29] Progress step 22000/300000 — loss 0.0026933 — PSNR 25.740\r\n",
      "[07:31:29] Eval @ 22000: train_loss 0.0026933 — train_PSNR 25.740 — val_loss 0.0032645 — val_PSNR 24.862\r\n",
      "[07:31:31] Progress step 22100/300000 — loss 0.0026314 — PSNR 25.837\r\n",
      "[07:31:32] Progress step 22200/300000 — loss 0.0026799 — PSNR 25.756\r\n",
      "[07:31:34] Progress step 22300/300000 — loss 0.0026682 — PSNR 25.778\r\n",
      "[07:31:36] Progress step 22400/300000 — loss 0.0026826 — PSNR 25.756\r\n",
      "[07:31:37] Progress step 22500/300000 — loss 0.0026854 — PSNR 25.752\r\n",
      "[07:31:39] Progress step 22600/300000 — loss 0.0026924 — PSNR 25.741\r\n",
      "[07:31:41] Progress step 22700/300000 — loss 0.0026965 — PSNR 25.733\r\n",
      "[07:31:42] Progress step 22800/300000 — loss 0.0026958 — PSNR 25.733\r\n",
      "[07:31:44] Progress step 22900/300000 — loss 0.0026950 — PSNR 25.735\r\n",
      "[07:31:46] Progress step 23000/300000 — loss 0.0026975 — PSNR 25.730\r\n",
      "[07:32:04] Eval @ 23000: train_loss 0.0026975 — train_PSNR 25.730 — val_loss 0.0026511 — val_PSNR 26.391\r\n",
      "[07:32:06] Progress step 23100/300000 — loss 0.0025670 — PSNR 25.955\r\n",
      "[07:32:08] Progress step 23200/300000 — loss 0.0026323 — PSNR 25.844\r\n",
      "[07:32:10] Progress step 23300/300000 — loss 0.0026477 — PSNR 25.814\r\n",
      "[07:32:11] Progress step 23400/300000 — loss 0.0026521 — PSNR 25.805\r\n",
      "[07:32:13] Progress step 23500/300000 — loss 0.0026539 — PSNR 25.802\r\n",
      "[07:32:15] Progress step 23600/300000 — loss 0.0026589 — PSNR 25.795\r\n",
      "[07:32:16] Progress step 23700/300000 — loss 0.0026609 — PSNR 25.793\r\n",
      "[07:32:18] Progress step 23800/300000 — loss 0.0026616 — PSNR 25.791\r\n",
      "[07:32:20] Progress step 23900/300000 — loss 0.0026624 — PSNR 25.790\r\n",
      "[07:32:21] Progress step 24000/300000 — loss 0.0026662 — PSNR 25.783\r\n",
      "[07:32:21] Eval @ 24000: train_loss 0.0026662 — train_PSNR 25.783 — val_loss 0.0032802 — val_PSNR 24.841\r\n",
      "[07:32:23] Progress step 24100/300000 — loss 0.0027053 — PSNR 25.715\r\n",
      "[07:32:25] Progress step 24200/300000 — loss 0.0026614 — PSNR 25.790\r\n",
      "[07:32:26] Progress step 24300/300000 — loss 0.0026670 — PSNR 25.777\r\n",
      "[07:32:28] Progress step 24400/300000 — loss 0.0026706 — PSNR 25.771\r\n",
      "[07:32:30] Progress step 24500/300000 — loss 0.0026696 — PSNR 25.775\r\n",
      "[07:32:31] Progress step 24600/300000 — loss 0.0026729 — PSNR 25.770\r\n",
      "[07:32:33] Progress step 24700/300000 — loss 0.0026853 — PSNR 25.750\r\n",
      "[07:32:35] Progress step 24800/300000 — loss 0.0026830 — PSNR 25.754\r\n",
      "[07:32:36] Progress step 24900/300000 — loss 0.0026802 — PSNR 25.758\r\n",
      "[07:32:38] Progress step 25000/300000 — loss 0.0026903 — PSNR 25.742\r\n",
      "[07:32:57] Eval @ 25000: train_loss 0.0026903 — train_PSNR 25.742 — val_loss 0.0026492 — val_PSNR 26.395\r\n",
      "[07:32:57] Saved best model at step 25000\r\n",
      "[07:32:58] Progress step 25100/300000 — loss 0.0027504 — PSNR 25.655\r\n",
      "[07:33:00] Progress step 25200/300000 — loss 0.0026676 — PSNR 25.782\r\n",
      "[07:33:02] Progress step 25300/300000 — loss 0.0026582 — PSNR 25.799\r\n",
      "[07:33:03] Progress step 25400/300000 — loss 0.0026526 — PSNR 25.807\r\n",
      "[07:33:05] Progress step 25500/300000 — loss 0.0026756 — PSNR 25.771\r\n",
      "[07:33:07] Progress step 25600/300000 — loss 0.0026779 — PSNR 25.768\r\n",
      "[07:33:08] Progress step 25700/300000 — loss 0.0026782 — PSNR 25.767\r\n",
      "[07:33:10] Progress step 25800/300000 — loss 0.0026906 — PSNR 25.745\r\n",
      "[07:33:12] Progress step 25900/300000 — loss 0.0026903 — PSNR 25.746\r\n",
      "[07:33:13] Progress step 26000/300000 — loss 0.0026985 — PSNR 25.733\r\n",
      "[07:33:13] Eval @ 26000: train_loss 0.0026985 — train_PSNR 25.733 — val_loss 0.0033584 — val_PSNR 24.739\r\n",
      "[07:33:15] Progress step 26100/300000 — loss 0.0026980 — PSNR 25.728\r\n",
      "[07:33:17] Progress step 26200/300000 — loss 0.0027125 — PSNR 25.706\r\n",
      "[07:33:18] Progress step 26300/300000 — loss 0.0027232 — PSNR 25.687\r\n",
      "[07:33:20] Progress step 26400/300000 — loss 0.0026978 — PSNR 25.729\r\n",
      "[07:33:22] Progress step 26500/300000 — loss 0.0027010 — PSNR 25.725\r\n",
      "[07:33:23] Progress step 26600/300000 — loss 0.0027030 — PSNR 25.722\r\n",
      "[07:33:25] Progress step 26700/300000 — loss 0.0027090 — PSNR 25.712\r\n",
      "[07:33:27] Progress step 26800/300000 — loss 0.0027136 — PSNR 25.704\r\n",
      "[07:33:28] Progress step 26900/300000 — loss 0.0027133 — PSNR 25.704\r\n",
      "[07:33:30] Progress step 27000/300000 — loss 0.0027116 — PSNR 25.708\r\n",
      "[07:33:49] Eval @ 27000: train_loss 0.0027116 — train_PSNR 25.708 — val_loss 0.0026489 — val_PSNR 26.396\r\n",
      "[07:33:49] Saved best model at step 27000\r\n",
      "[07:33:51] Progress step 27100/300000 — loss 0.0026845 — PSNR 25.748\r\n",
      "[07:33:52] Progress step 27200/300000 — loss 0.0026865 — PSNR 25.751\r\n",
      "[07:33:54] Progress step 27300/300000 — loss 0.0027138 — PSNR 25.707\r\n",
      "[07:33:56] Progress step 27400/300000 — loss 0.0027112 — PSNR 25.710\r\n",
      "[07:33:57] Progress step 27500/300000 — loss 0.0027093 — PSNR 25.716\r\n",
      "[07:33:59] Progress step 27600/300000 — loss 0.0027187 — PSNR 25.700\r\n",
      "[07:34:01] Progress step 27700/300000 — loss 0.0027129 — PSNR 25.710\r\n",
      "[07:34:02] Progress step 27800/300000 — loss 0.0027045 — PSNR 25.723\r\n",
      "[07:34:04] Progress step 27900/300000 — loss 0.0027016 — PSNR 25.727\r\n",
      "[07:34:06] Progress step 28000/300000 — loss 0.0027050 — PSNR 25.721\r\n",
      "[07:34:06] Eval @ 28000: train_loss 0.0027050 — train_PSNR 25.721 — val_loss 0.0032723 — val_PSNR 24.852\r\n",
      "[07:34:07] Progress step 28100/300000 — loss 0.0026907 — PSNR 25.746\r\n",
      "[07:34:09] Progress step 28200/300000 — loss 0.0027068 — PSNR 25.718\r\n",
      "[07:34:11] Progress step 28300/300000 — loss 0.0027079 — PSNR 25.714\r\n",
      "[07:34:12] Progress step 28400/300000 — loss 0.0027122 — PSNR 25.706\r\n",
      "[07:34:14] Progress step 28500/300000 — loss 0.0026950 — PSNR 25.734\r\n",
      "[07:34:16] Progress step 28600/300000 — loss 0.0026939 — PSNR 25.735\r\n",
      "[07:34:17] Progress step 28700/300000 — loss 0.0026976 — PSNR 25.731\r\n",
      "[07:34:19] Progress step 28800/300000 — loss 0.0026974 — PSNR 25.731\r\n",
      "[07:34:20] Progress step 28900/300000 — loss 0.0026910 — PSNR 25.742\r\n",
      "[07:34:22] Progress step 29000/300000 — loss 0.0026853 — PSNR 25.751\r\n",
      "[07:34:41] Eval @ 29000: train_loss 0.0026853 — train_PSNR 25.751 — val_loss 0.0026488 — val_PSNR 26.396\r\n",
      "[07:34:41] Saved best model at step 29000\r\n",
      "[07:34:43] Progress step 29100/300000 — loss 0.0027175 — PSNR 25.719\r\n",
      "[07:34:44] Progress step 29200/300000 — loss 0.0027155 — PSNR 25.715\r\n",
      "[07:34:46] Progress step 29300/300000 — loss 0.0027073 — PSNR 25.729\r\n",
      "[07:34:47] Progress step 29400/300000 — loss 0.0027095 — PSNR 25.724\r\n",
      "[07:34:49] Progress step 29500/300000 — loss 0.0027130 — PSNR 25.715\r\n",
      "[07:34:51] Progress step 29600/300000 — loss 0.0027096 — PSNR 25.721\r\n",
      "[07:34:52] Progress step 29700/300000 — loss 0.0027008 — PSNR 25.734\r\n",
      "[07:34:54] Progress step 29800/300000 — loss 0.0027022 — PSNR 25.731\r\n",
      "[07:34:56] Progress step 29900/300000 — loss 0.0026990 — PSNR 25.736\r\n",
      "[07:34:57] Progress step 30000/300000 — loss 0.0026991 — PSNR 25.735\r\n",
      "[07:34:57] Eval @ 30000: train_loss 0.0026991 — train_PSNR 25.735 — val_loss 0.0033198 — val_PSNR 24.789\r\n",
      "[07:34:59] Progress step 30100/300000 — loss 0.0026569 — PSNR 25.791\r\n",
      "[07:35:01] Progress step 30200/300000 — loss 0.0026873 — PSNR 25.742\r\n",
      "[07:35:02] Progress step 30300/300000 — loss 0.0027002 — PSNR 25.725\r\n",
      "[07:35:04] Progress step 30400/300000 — loss 0.0027013 — PSNR 25.728\r\n",
      "[07:35:06] Progress step 30500/300000 — loss 0.0027060 — PSNR 25.720\r\n",
      "[07:35:07] Progress step 30600/300000 — loss 0.0027008 — PSNR 25.727\r\n",
      "[07:35:09] Progress step 30700/300000 — loss 0.0026953 — PSNR 25.735\r\n",
      "[07:35:11] Progress step 30800/300000 — loss 0.0026944 — PSNR 25.736\r\n",
      "[07:35:12] Progress step 30900/300000 — loss 0.0027022 — PSNR 25.724\r\n",
      "[07:35:14] Progress step 31000/300000 — loss 0.0027009 — PSNR 25.726\r\n",
      "[07:35:33] Eval @ 31000: train_loss 0.0027009 — train_PSNR 25.726 — val_loss 0.0026488 — val_PSNR 26.396\r\n",
      "[07:35:33] Saved best model at step 31000\r\n",
      "[07:35:34] Progress step 31100/300000 — loss 0.0027238 — PSNR 25.698\r\n",
      "[07:35:36] Progress step 31200/300000 — loss 0.0027231 — PSNR 25.694\r\n",
      "[07:35:38] Progress step 31300/300000 — loss 0.0027014 — PSNR 25.727\r\n",
      "[07:35:39] Progress step 31400/300000 — loss 0.0026969 — PSNR 25.735\r\n",
      "[07:35:41] Progress step 31500/300000 — loss 0.0026929 — PSNR 25.740\r\n",
      "[07:35:43] Progress step 31600/300000 — loss 0.0026843 — PSNR 25.754\r\n",
      "[07:35:44] Progress step 31700/300000 — loss 0.0026788 — PSNR 25.763\r\n",
      "[07:35:46] Progress step 31800/300000 — loss 0.0026749 — PSNR 25.770\r\n",
      "[07:35:48] Progress step 31900/300000 — loss 0.0026787 — PSNR 25.765\r\n",
      "[07:35:49] Progress step 32000/300000 — loss 0.0026743 — PSNR 25.772\r\n",
      "[07:35:49] Eval @ 32000: train_loss 0.0026743 — train_PSNR 25.772 — val_loss 0.0032807 — val_PSNR 24.840\r\n",
      "[07:35:51] Progress step 32100/300000 — loss 0.0027285 — PSNR 25.671\r\n",
      "[07:35:53] Progress step 32200/300000 — loss 0.0026951 — PSNR 25.727\r\n",
      "[07:35:54] Progress step 32300/300000 — loss 0.0026719 — PSNR 25.766\r\n",
      "[07:35:56] Progress step 32400/300000 — loss 0.0026952 — PSNR 25.731\r\n",
      "[07:35:58] Progress step 32500/300000 — loss 0.0026956 — PSNR 25.732\r\n",
      "[07:35:59] Progress step 32600/300000 — loss 0.0026925 — PSNR 25.739\r\n",
      "[07:36:01] Progress step 32700/300000 — loss 0.0026915 — PSNR 25.741\r\n",
      "[07:36:02] Progress step 32800/300000 — loss 0.0026854 — PSNR 25.752\r\n",
      "[07:36:04] Progress step 32900/300000 — loss 0.0026908 — PSNR 25.743\r\n",
      "[07:36:06] Progress step 33000/300000 — loss 0.0026899 — PSNR 25.745\r\n",
      "[07:36:24] Eval @ 33000: train_loss 0.0026899 — train_PSNR 25.745 — val_loss 0.0026656 — val_PSNR 26.359\r\n",
      "[07:36:26] Progress step 33100/300000 — loss 0.0027033 — PSNR 25.724\r\n",
      "[07:36:28] Progress step 33200/300000 — loss 0.0026973 — PSNR 25.729\r\n",
      "[07:36:29] Progress step 33300/300000 — loss 0.0026981 — PSNR 25.728\r\n",
      "[07:36:31] Progress step 33400/300000 — loss 0.0027074 — PSNR 25.712\r\n",
      "[07:36:33] Progress step 33500/300000 — loss 0.0027215 — PSNR 25.691\r\n",
      "[07:36:34] Progress step 33600/300000 — loss 0.0027180 — PSNR 25.696\r\n",
      "[07:36:36] Progress step 33700/300000 — loss 0.0027113 — PSNR 25.708\r\n",
      "[07:36:37] Progress step 33800/300000 — loss 0.0027069 — PSNR 25.714\r\n",
      "[07:36:39] Progress step 33900/300000 — loss 0.0027027 — PSNR 25.721\r\n",
      "[07:36:41] Progress step 34000/300000 — loss 0.0026958 — PSNR 25.732\r\n",
      "[07:36:41] Eval @ 34000: train_loss 0.0026958 — train_PSNR 25.732 — val_loss 0.0032736 — val_PSNR 24.850\r\n",
      "[07:36:42] Progress step 34100/300000 — loss 0.0026608 — PSNR 25.792\r\n",
      "[07:36:44] Progress step 34200/300000 — loss 0.0026915 — PSNR 25.738\r\n",
      "[07:36:46] Progress step 34300/300000 — loss 0.0026807 — PSNR 25.760\r\n",
      "[07:36:47] Progress step 34400/300000 — loss 0.0026844 — PSNR 25.755\r\n",
      "[07:36:49] Progress step 34500/300000 — loss 0.0026886 — PSNR 25.747\r\n",
      "[07:36:50] Progress step 34600/300000 — loss 0.0026932 — PSNR 25.740\r\n",
      "[07:36:52] Progress step 34700/300000 — loss 0.0027069 — PSNR 25.718\r\n",
      "[07:36:54] Progress step 34800/300000 — loss 0.0027092 — PSNR 25.714\r\n",
      "[07:36:55] Progress step 34900/300000 — loss 0.0027117 — PSNR 25.710\r\n",
      "[07:36:57] Progress step 35000/300000 — loss 0.0027069 — PSNR 25.717\r\n",
      "[07:37:16] Eval @ 35000: train_loss 0.0027069 — train_PSNR 25.717 — val_loss 0.0026607 — val_PSNR 26.370\r\n",
      "[07:37:17] Progress step 35100/300000 — loss 0.0027348 — PSNR 25.676\r\n",
      "[07:37:19] Progress step 35200/300000 — loss 0.0027203 — PSNR 25.695\r\n",
      "[07:37:21] Progress step 35300/300000 — loss 0.0027164 — PSNR 25.698\r\n",
      "[07:37:22] Progress step 35400/300000 — loss 0.0027174 — PSNR 25.698\r\n",
      "[07:37:24] Progress step 35500/300000 — loss 0.0026931 — PSNR 25.738\r\n",
      "[07:37:26] Progress step 35600/300000 — loss 0.0026906 — PSNR 25.742\r\n",
      "[07:37:27] Progress step 35700/300000 — loss 0.0026917 — PSNR 25.740\r\n",
      "[07:37:29] Progress step 35800/300000 — loss 0.0026914 — PSNR 25.740\r\n",
      "[07:37:31] Progress step 35900/300000 — loss 0.0026917 — PSNR 25.740\r\n",
      "[07:37:32] Progress step 36000/300000 — loss 0.0026946 — PSNR 25.736\r\n",
      "[07:37:32] Eval @ 36000: train_loss 0.0026946 — train_PSNR 25.736 — val_loss 0.0032891 — val_PSNR 24.829\r\n",
      "[07:37:34] Progress step 36100/300000 — loss 0.0027389 — PSNR 25.656\r\n",
      "[07:37:36] Progress step 36200/300000 — loss 0.0027184 — PSNR 25.689\r\n",
      "[07:37:37] Progress step 36300/300000 — loss 0.0027073 — PSNR 25.709\r\n",
      "[07:37:39] Progress step 36400/300000 — loss 0.0027095 — PSNR 25.707\r\n",
      "[07:37:40] Progress step 36500/300000 — loss 0.0027000 — PSNR 25.725\r\n",
      "[07:37:42] Progress step 36600/300000 — loss 0.0026973 — PSNR 25.728\r\n",
      "[07:37:44] Progress step 36700/300000 — loss 0.0026952 — PSNR 25.732\r\n",
      "[07:37:45] Progress step 36800/300000 — loss 0.0026961 — PSNR 25.732\r\n",
      "[07:37:47] Progress step 36900/300000 — loss 0.0026937 — PSNR 25.736\r\n",
      "[07:37:49] Progress step 37000/300000 — loss 0.0026981 — PSNR 25.728\r\n",
      "[07:38:07] Eval @ 37000: train_loss 0.0026981 — train_PSNR 25.728 — val_loss 0.0026475 — val_PSNR 26.398\r\n",
      "[07:38:07] Saved best model at step 37000\r\n",
      "[07:38:09] Progress step 37100/300000 — loss 0.0027055 — PSNR 25.722\r\n",
      "[07:38:11] Progress step 37200/300000 — loss 0.0026893 — PSNR 25.743\r\n",
      "[07:38:12] Progress step 37300/300000 — loss 0.0026818 — PSNR 25.756\r\n",
      "[07:38:14] Progress step 37400/300000 — loss 0.0026897 — PSNR 25.742\r\n",
      "[07:38:16] Progress step 37500/300000 — loss 0.0026994 — PSNR 25.727\r\n",
      "[07:38:17] Progress step 37600/300000 — loss 0.0026997 — PSNR 25.727\r\n",
      "[07:38:19] Progress step 37700/300000 — loss 0.0027036 — PSNR 25.721\r\n",
      "[07:38:21] Progress step 37800/300000 — loss 0.0026986 — PSNR 25.728\r\n",
      "[07:38:22] Progress step 37900/300000 — loss 0.0026963 — PSNR 25.733\r\n",
      "[07:38:24] Progress step 38000/300000 — loss 0.0026939 — PSNR 25.737\r\n",
      "[07:38:24] Eval @ 38000: train_loss 0.0026939 — train_PSNR 25.737 — val_loss 0.0032789 — val_PSNR 24.843\r\n",
      "[07:38:26] Progress step 38100/300000 — loss 0.0026837 — PSNR 25.748\r\n",
      "[07:38:27] Progress step 38200/300000 — loss 0.0027125 — PSNR 25.704\r\n",
      "[07:38:29] Progress step 38300/300000 — loss 0.0026968 — PSNR 25.731\r\n",
      "[07:38:31] Progress step 38400/300000 — loss 0.0027003 — PSNR 25.726\r\n",
      "[07:38:32] Progress step 38500/300000 — loss 0.0026998 — PSNR 25.728\r\n",
      "[07:38:34] Progress step 38600/300000 — loss 0.0027045 — PSNR 25.719\r\n",
      "[07:38:35] Progress step 38700/300000 — loss 0.0027009 — PSNR 25.725\r\n",
      "[07:38:37] Progress step 38800/300000 — loss 0.0027093 — PSNR 25.713\r\n",
      "[07:38:39] Progress step 38900/300000 — loss 0.0027023 — PSNR 25.724\r\n",
      "[07:38:40] Progress step 39000/300000 — loss 0.0027035 — PSNR 25.722\r\n",
      "[07:38:59] Eval @ 39000: train_loss 0.0027035 — train_PSNR 25.722 — val_loss 0.0026474 — val_PSNR 26.398\r\n",
      "[07:38:59] Saved best model at step 39000\r\n",
      "[07:39:01] Progress step 39100/300000 — loss 0.0026760 — PSNR 25.758\r\n",
      "[07:39:02] Progress step 39200/300000 — loss 0.0026902 — PSNR 25.737\r\n",
      "[07:39:04] Progress step 39300/300000 — loss 0.0026822 — PSNR 25.751\r\n",
      "[07:39:06] Progress step 39400/300000 — loss 0.0026929 — PSNR 25.733\r\n",
      "[07:39:07] Progress step 39500/300000 — loss 0.0026869 — PSNR 25.743\r\n",
      "[07:39:09] Progress step 39600/300000 — loss 0.0026799 — PSNR 25.754\r\n",
      "[07:39:11] Progress step 39700/300000 — loss 0.0026869 — PSNR 25.743\r\n",
      "[07:39:12] Progress step 39800/300000 — loss 0.0026902 — PSNR 25.739\r\n",
      "[07:39:14] Progress step 39900/300000 — loss 0.0026913 — PSNR 25.738\r\n",
      "[07:39:15] Progress step 40000/300000 — loss 0.0026927 — PSNR 25.736\r\n",
      "[07:39:15] Eval @ 40000: train_loss 0.0026927 — train_PSNR 25.736 — val_loss 0.0032826 — val_PSNR 24.838\r\n",
      "[07:39:17] Progress step 40100/300000 — loss 0.0026900 — PSNR 25.748\r\n",
      "[07:39:19] Progress step 40200/300000 — loss 0.0026650 — PSNR 25.782\r\n",
      "[07:39:20] Progress step 40300/300000 — loss 0.0026626 — PSNR 25.784\r\n",
      "[07:39:22] Progress step 40400/300000 — loss 0.0026632 — PSNR 25.782\r\n",
      "[07:39:24] Progress step 40500/300000 — loss 0.0026674 — PSNR 25.775\r\n",
      "[07:39:25] Progress step 40600/300000 — loss 0.0026690 — PSNR 25.771\r\n",
      "[07:39:27] Progress step 40700/300000 — loss 0.0026750 — PSNR 25.765\r\n",
      "[07:39:29] Progress step 40800/300000 — loss 0.0026774 — PSNR 25.761\r\n",
      "[07:39:30] Progress step 40900/300000 — loss 0.0026841 — PSNR 25.751\r\n",
      "[07:39:32] Progress step 41000/300000 — loss 0.0026786 — PSNR 25.760\r\n",
      "[07:39:50] Eval @ 41000: train_loss 0.0026786 — train_PSNR 25.760 — val_loss 0.0026513 — val_PSNR 26.390\r\n",
      "[07:39:52] Progress step 41100/300000 — loss 0.0026896 — PSNR 25.743\r\n",
      "[07:39:54] Progress step 41200/300000 — loss 0.0026869 — PSNR 25.748\r\n",
      "[07:39:55] Progress step 41300/300000 — loss 0.0026949 — PSNR 25.737\r\n",
      "[07:39:57] Progress step 41400/300000 — loss 0.0026909 — PSNR 25.743\r\n",
      "[07:39:59] Progress step 41500/300000 — loss 0.0026750 — PSNR 25.770\r\n",
      "[07:40:00] Progress step 41600/300000 — loss 0.0026871 — PSNR 25.751\r\n",
      "[07:40:02] Progress step 41700/300000 — loss 0.0026892 — PSNR 25.747\r\n",
      "[07:40:04] Progress step 41800/300000 — loss 0.0027004 — PSNR 25.731\r\n",
      "[07:40:05] Progress step 41900/300000 — loss 0.0026998 — PSNR 25.732\r\n",
      "[07:40:07] Progress step 42000/300000 — loss 0.0026932 — PSNR 25.742\r\n",
      "[07:40:07] Eval @ 42000: train_loss 0.0026932 — train_PSNR 25.742 — val_loss 0.0033135 — val_PSNR 24.797\r\n",
      "[07:40:08] Progress step 42100/300000 — loss 0.0026765 — PSNR 25.756\r\n",
      "[07:40:10] Progress step 42200/300000 — loss 0.0026798 — PSNR 25.754\r\n",
      "[07:40:12] Progress step 42300/300000 — loss 0.0027021 — PSNR 25.727\r\n",
      "[07:40:13] Progress step 42400/300000 — loss 0.0027087 — PSNR 25.715\r\n",
      "[07:40:15] Progress step 42500/300000 — loss 0.0026936 — PSNR 25.738\r\n",
      "[07:40:17] Progress step 42600/300000 — loss 0.0026872 — PSNR 25.749\r\n",
      "[07:40:18] Progress step 42700/300000 — loss 0.0026860 — PSNR 25.749\r\n",
      "[07:40:20] Progress step 42800/300000 — loss 0.0026919 — PSNR 25.740\r\n",
      "[07:40:21] Progress step 42900/300000 — loss 0.0026881 — PSNR 25.747\r\n",
      "[07:40:23] Progress step 43000/300000 — loss 0.0026823 — PSNR 25.757\r\n",
      "[07:40:42] Eval @ 43000: train_loss 0.0026823 — train_PSNR 25.757 — val_loss 0.0026484 — val_PSNR 26.396\r\n",
      "[07:40:44] Progress step 43100/300000 — loss 0.0026909 — PSNR 25.739\r\n",
      "[07:40:45] Progress step 43200/300000 — loss 0.0026936 — PSNR 25.734\r\n",
      "[07:40:47] Progress step 43300/300000 — loss 0.0027039 — PSNR 25.721\r\n",
      "[07:40:48] Progress step 43400/300000 — loss 0.0027048 — PSNR 25.721\r\n",
      "[07:40:50] Progress step 43500/300000 — loss 0.0026847 — PSNR 25.752\r\n",
      "[07:40:52] Progress step 43600/300000 — loss 0.0026836 — PSNR 25.754\r\n",
      "[07:40:53] Progress step 43700/300000 — loss 0.0026802 — PSNR 25.759\r\n",
      "[07:40:55] Progress step 43800/300000 — loss 0.0026744 — PSNR 25.768\r\n",
      "[07:40:56] Progress step 43900/300000 — loss 0.0026704 — PSNR 25.775\r\n",
      "[07:40:58] Progress step 44000/300000 — loss 0.0026737 — PSNR 25.769\r\n",
      "[07:40:58] Eval @ 44000: train_loss 0.0026737 — train_PSNR 25.769 — val_loss 0.0032724 — val_PSNR 24.851\r\n",
      "[07:41:00] Progress step 44100/300000 — loss 0.0026235 — PSNR 25.853\r\n",
      "[07:41:01] Progress step 44200/300000 — loss 0.0026594 — PSNR 25.791\r\n",
      "[07:41:03] Progress step 44300/300000 — loss 0.0026500 — PSNR 25.809\r\n",
      "[07:41:05] Progress step 44400/300000 — loss 0.0026725 — PSNR 25.771\r\n",
      "[07:41:06] Progress step 44500/300000 — loss 0.0026596 — PSNR 25.793\r\n",
      "[07:41:08] Progress step 44600/300000 — loss 0.0026628 — PSNR 25.790\r\n",
      "[07:41:09] Progress step 44700/300000 — loss 0.0026681 — PSNR 25.782\r\n",
      "[07:41:11] Progress step 44800/300000 — loss 0.0026708 — PSNR 25.776\r\n",
      "[07:41:13] Progress step 44900/300000 — loss 0.0026710 — PSNR 25.775\r\n",
      "[07:41:14] Progress step 45000/300000 — loss 0.0026754 — PSNR 25.768\r\n",
      "[07:41:33] Eval @ 45000: train_loss 0.0026754 — train_PSNR 25.768 — val_loss 0.0026493 — val_PSNR 26.394\r\n",
      "[07:41:35] Progress step 45100/300000 — loss 0.0027585 — PSNR 25.646\r\n",
      "[07:41:36] Progress step 45200/300000 — loss 0.0027054 — PSNR 25.724\r\n",
      "[07:41:38] Progress step 45300/300000 — loss 0.0026901 — PSNR 25.749\r\n",
      "[07:41:40] Progress step 45400/300000 — loss 0.0026856 — PSNR 25.754\r\n",
      "[07:41:41] Progress step 45500/300000 — loss 0.0026847 — PSNR 25.756\r\n",
      "[07:41:43] Progress step 45600/300000 — loss 0.0026817 — PSNR 25.759\r\n",
      "[07:41:44] Progress step 45700/300000 — loss 0.0026729 — PSNR 25.773\r\n",
      "[07:41:46] Progress step 45800/300000 — loss 0.0026795 — PSNR 25.763\r\n",
      "[07:41:48] Progress step 45900/300000 — loss 0.0026808 — PSNR 25.760\r\n",
      "[07:41:49] Progress step 46000/300000 — loss 0.0026841 — PSNR 25.753\r\n",
      "[07:41:49] Eval @ 46000: train_loss 0.0026841 — train_PSNR 25.753 — val_loss 0.0032777 — val_PSNR 24.844\r\n",
      "[07:41:51] Progress step 46100/300000 — loss 0.0026804 — PSNR 25.749\r\n",
      "[07:41:53] Progress step 46200/300000 — loss 0.0026605 — PSNR 25.789\r\n",
      "[07:41:54] Progress step 46300/300000 — loss 0.0026750 — PSNR 25.764\r\n",
      "[07:41:56] Progress step 46400/300000 — loss 0.0026646 — PSNR 25.778\r\n",
      "[07:41:58] Progress step 46500/300000 — loss 0.0026838 — PSNR 25.749\r\n",
      "[07:41:59] Progress step 46600/300000 — loss 0.0026835 — PSNR 25.750\r\n",
      "[07:42:01] Progress step 46700/300000 — loss 0.0026899 — PSNR 25.741\r\n",
      "[07:42:02] Progress step 46800/300000 — loss 0.0026903 — PSNR 25.740\r\n",
      "[07:42:04] Progress step 46900/300000 — loss 0.0026890 — PSNR 25.743\r\n",
      "[07:42:06] Progress step 47000/300000 — loss 0.0026871 — PSNR 25.746\r\n",
      "[07:42:25] Eval @ 47000: train_loss 0.0026871 — train_PSNR 25.746 — val_loss 0.0026503 — val_PSNR 26.392\r\n",
      "[07:42:26] Progress step 47100/300000 — loss 0.0027403 — PSNR 25.659\r\n",
      "[07:42:28] Progress step 47200/300000 — loss 0.0027002 — PSNR 25.722\r\n",
      "[07:42:30] Progress step 47300/300000 — loss 0.0026973 — PSNR 25.728\r\n",
      "[07:42:31] Progress step 47400/300000 — loss 0.0027056 — PSNR 25.716\r\n",
      "[07:42:33] Progress step 47500/300000 — loss 0.0027081 — PSNR 25.713\r\n",
      "[07:42:35] Progress step 47600/300000 — loss 0.0027087 — PSNR 25.711\r\n",
      "[07:42:36] Progress step 47700/300000 — loss 0.0027114 — PSNR 25.706\r\n",
      "[07:42:38] Progress step 47800/300000 — loss 0.0027078 — PSNR 25.713\r\n",
      "[07:42:39] Progress step 47900/300000 — loss 0.0027075 — PSNR 25.713\r\n",
      "[07:42:41] Progress step 48000/300000 — loss 0.0027069 — PSNR 25.714\r\n",
      "[07:42:41] Eval @ 48000: train_loss 0.0027069 — train_PSNR 25.714 — val_loss 0.0032716 — val_PSNR 24.852\r\n",
      "[07:42:43] Progress step 48100/300000 — loss 0.0026737 — PSNR 25.780\r\n",
      "[07:42:44] Progress step 48200/300000 — loss 0.0026975 — PSNR 25.740\r\n",
      "[07:42:46] Progress step 48300/300000 — loss 0.0026974 — PSNR 25.739\r\n",
      "[07:42:48] Progress step 48400/300000 — loss 0.0027067 — PSNR 25.724\r\n",
      "[07:42:49] Progress step 48500/300000 — loss 0.0026971 — PSNR 25.737\r\n",
      "[07:42:51] Progress step 48600/300000 — loss 0.0026924 — PSNR 25.742\r\n",
      "[07:42:52] Progress step 48700/300000 — loss 0.0027015 — PSNR 25.728\r\n",
      "[07:42:54] Progress step 48800/300000 — loss 0.0026967 — PSNR 25.734\r\n",
      "[07:42:56] Progress step 48900/300000 — loss 0.0026978 — PSNR 25.733\r\n",
      "[07:42:57] Progress step 49000/300000 — loss 0.0026967 — PSNR 25.733\r\n",
      "[07:43:16] Eval @ 49000: train_loss 0.0026967 — train_PSNR 25.733 — val_loss 0.0026470 — val_PSNR 26.399\r\n",
      "[07:43:16] Saved best model at step 49000\r\n",
      "[07:43:18] Progress step 49100/300000 — loss 0.0026832 — PSNR 25.750\r\n",
      "[07:43:19] Progress step 49200/300000 — loss 0.0026979 — PSNR 25.731\r\n",
      "[07:43:21] Progress step 49300/300000 — loss 0.0027039 — PSNR 25.719\r\n",
      "[07:43:23] Progress step 49400/300000 — loss 0.0027040 — PSNR 25.721\r\n",
      "[07:43:24] Progress step 49500/300000 — loss 0.0026917 — PSNR 25.742\r\n",
      "[07:43:26] Progress step 49600/300000 — loss 0.0026965 — PSNR 25.734\r\n",
      "[07:43:28] Progress step 49700/300000 — loss 0.0026957 — PSNR 25.735\r\n",
      "[07:43:29] Progress step 49800/300000 — loss 0.0026948 — PSNR 25.735\r\n",
      "[07:43:31] Progress step 49900/300000 — loss 0.0026905 — PSNR 25.742\r\n",
      "[07:43:33] Progress step 50000/300000 — loss 0.0026943 — PSNR 25.735\r\n",
      "[07:43:33] Eval @ 50000: train_loss 0.0026943 — train_PSNR 25.735 — val_loss 0.0032829 — val_PSNR 24.837\r\n",
      "[07:43:34] Progress step 50100/300000 — loss 0.0026766 — PSNR 25.768\r\n",
      "[07:43:36] Progress step 50200/300000 — loss 0.0026944 — PSNR 25.742\r\n",
      "[07:43:38] Progress step 50300/300000 — loss 0.0027142 — PSNR 25.708\r\n",
      "[07:43:39] Progress step 50400/300000 — loss 0.0027187 — PSNR 25.699\r\n",
      "[07:43:41] Progress step 50500/300000 — loss 0.0026965 — PSNR 25.736\r\n",
      "[07:43:43] Progress step 50600/300000 — loss 0.0026954 — PSNR 25.740\r\n",
      "[07:43:44] Progress step 50700/300000 — loss 0.0026961 — PSNR 25.739\r\n",
      "[07:43:46] Progress step 50800/300000 — loss 0.0026963 — PSNR 25.737\r\n",
      "[07:43:47] Progress step 50900/300000 — loss 0.0026981 — PSNR 25.734\r\n",
      "[07:43:49] Progress step 51000/300000 — loss 0.0026905 — PSNR 25.747\r\n",
      "[07:44:08] Eval @ 51000: train_loss 0.0026905 — train_PSNR 25.747 — val_loss 0.0026469 — val_PSNR 26.399\r\n",
      "[07:44:08] Saved best model at step 51000\r\n",
      "[07:44:10] Progress step 51100/300000 — loss 0.0027084 — PSNR 25.722\r\n",
      "[07:44:11] Progress step 51200/300000 — loss 0.0026714 — PSNR 25.780\r\n",
      "[07:44:13] Progress step 51300/300000 — loss 0.0026656 — PSNR 25.783\r\n",
      "[07:44:15] Progress step 51400/300000 — loss 0.0026659 — PSNR 25.783\r\n",
      "[07:44:16] Progress step 51500/300000 — loss 0.0026671 — PSNR 25.780\r\n",
      "[07:44:18] Progress step 51600/300000 — loss 0.0026615 — PSNR 25.789\r\n",
      "[07:44:20] Progress step 51700/300000 — loss 0.0026686 — PSNR 25.777\r\n",
      "[07:44:21] Progress step 51800/300000 — loss 0.0026713 — PSNR 25.774\r\n",
      "[07:44:23] Progress step 51900/300000 — loss 0.0026757 — PSNR 25.768\r\n",
      "[07:44:24] Progress step 52000/300000 — loss 0.0026706 — PSNR 25.776\r\n",
      "[07:44:25] Eval @ 52000: train_loss 0.0026706 — train_PSNR 25.776 — val_loss 0.0032878 — val_PSNR 24.831\r\n",
      "[07:44:26] Progress step 52100/300000 — loss 0.0026745 — PSNR 25.764\r\n",
      "[07:44:28] Progress step 52200/300000 — loss 0.0027364 — PSNR 25.663\r\n",
      "[07:44:29] Progress step 52300/300000 — loss 0.0027295 — PSNR 25.673\r\n",
      "[07:44:31] Progress step 52400/300000 — loss 0.0027128 — PSNR 25.699\r\n",
      "[07:44:33] Progress step 52500/300000 — loss 0.0027118 — PSNR 25.703\r\n",
      "[07:44:34] Progress step 52600/300000 — loss 0.0027071 — PSNR 25.712\r\n",
      "[07:44:36] Progress step 52700/300000 — loss 0.0027055 — PSNR 25.715\r\n",
      "[07:44:38] Progress step 52800/300000 — loss 0.0027003 — PSNR 25.724\r\n",
      "[07:44:39] Progress step 52900/300000 — loss 0.0027047 — PSNR 25.717\r\n",
      "[07:44:41] Progress step 53000/300000 — loss 0.0027062 — PSNR 25.715\r\n",
      "[07:45:00] Eval @ 53000: train_loss 0.0027062 — train_PSNR 25.715 — val_loss 0.0026472 — val_PSNR 26.398\r\n",
      "[07:45:01] Progress step 53100/300000 — loss 0.0027565 — PSNR 25.640\r\n",
      "[07:45:03] Progress step 53200/300000 — loss 0.0027337 — PSNR 25.680\r\n",
      "[07:45:05] Progress step 53300/300000 — loss 0.0027243 — PSNR 25.694\r\n",
      "[07:45:06] Progress step 53400/300000 — loss 0.0027145 — PSNR 25.710\r\n",
      "[07:45:08] Progress step 53500/300000 — loss 0.0027096 — PSNR 25.717\r\n",
      "[07:45:10] Progress step 53600/300000 — loss 0.0026998 — PSNR 25.733\r\n",
      "[07:45:11] Progress step 53700/300000 — loss 0.0027022 — PSNR 25.728\r\n",
      "[07:45:13] Progress step 53800/300000 — loss 0.0027041 — PSNR 25.724\r\n",
      "[07:45:14] Progress step 53900/300000 — loss 0.0027032 — PSNR 25.726\r\n",
      "[07:45:16] Progress step 54000/300000 — loss 0.0027001 — PSNR 25.730\r\n",
      "[07:45:16] Eval @ 54000: train_loss 0.0027001 — train_PSNR 25.730 — val_loss 0.0032733 — val_PSNR 24.850\r\n",
      "[07:45:18] Progress step 54100/300000 — loss 0.0026546 — PSNR 25.807\r\n",
      "[07:45:19] Progress step 54200/300000 — loss 0.0026820 — PSNR 25.762\r\n",
      "[07:45:21] Progress step 54300/300000 — loss 0.0027082 — PSNR 25.720\r\n",
      "[07:45:23] Progress step 54400/300000 — loss 0.0027295 — PSNR 25.684\r\n",
      "[07:45:24] Progress step 54500/300000 — loss 0.0027183 — PSNR 25.701\r\n",
      "[07:45:26] Progress step 54600/300000 — loss 0.0027183 — PSNR 25.700\r\n",
      "[07:45:27] Progress step 54700/300000 — loss 0.0027168 — PSNR 25.703\r\n",
      "[07:45:29] Progress step 54800/300000 — loss 0.0027091 — PSNR 25.716\r\n",
      "[07:45:31] Progress step 54900/300000 — loss 0.0027107 — PSNR 25.713\r\n",
      "[07:45:32] Progress step 55000/300000 — loss 0.0027105 — PSNR 25.713\r\n",
      "[07:45:51] Eval @ 55000: train_loss 0.0027105 — train_PSNR 25.713 — val_loss 0.0026480 — val_PSNR 26.397\r\n",
      "[07:45:53] Progress step 55100/300000 — loss 0.0027408 — PSNR 25.670\r\n",
      "[07:45:54] Progress step 55200/300000 — loss 0.0027081 — PSNR 25.718\r\n",
      "[07:45:56] Progress step 55300/300000 — loss 0.0027054 — PSNR 25.722\r\n",
      "[07:45:58] Progress step 55400/300000 — loss 0.0027150 — PSNR 25.705\r\n",
      "[07:45:59] Progress step 55500/300000 — loss 0.0027012 — PSNR 25.726\r\n",
      "[07:46:01] Progress step 55600/300000 — loss 0.0027181 — PSNR 25.699\r\n",
      "[07:46:02] Progress step 55700/300000 — loss 0.0027085 — PSNR 25.715\r\n",
      "[07:46:04] Progress step 55800/300000 — loss 0.0027101 — PSNR 25.712\r\n",
      "[07:46:06] Progress step 55900/300000 — loss 0.0027047 — PSNR 25.721\r\n",
      "[07:46:07] Progress step 56000/300000 — loss 0.0027020 — PSNR 25.725\r\n",
      "[07:46:07] Eval @ 56000: train_loss 0.0027020 — train_PSNR 25.725 — val_loss 0.0032753 — val_PSNR 24.847\r\n",
      "[07:46:09] Progress step 56100/300000 — loss 0.0026817 — PSNR 25.752\r\n",
      "[07:46:11] Progress step 56200/300000 — loss 0.0027109 — PSNR 25.706\r\n",
      "[07:46:12] Progress step 56300/300000 — loss 0.0027024 — PSNR 25.720\r\n",
      "[07:46:14] Progress step 56400/300000 — loss 0.0027011 — PSNR 25.724\r\n",
      "[07:46:15] Progress step 56500/300000 — loss 0.0027042 — PSNR 25.720\r\n",
      "[07:46:17] Progress step 56600/300000 — loss 0.0026999 — PSNR 25.727\r\n",
      "[07:46:19] Progress step 56700/300000 — loss 0.0026962 — PSNR 25.733\r\n",
      "[07:46:20] Progress step 56800/300000 — loss 0.0026906 — PSNR 25.742\r\n",
      "[07:46:22] Progress step 56900/300000 — loss 0.0026880 — PSNR 25.746\r\n",
      "[07:46:23] Progress step 57000/300000 — loss 0.0026847 — PSNR 25.753\r\n",
      "[07:46:42] Eval @ 57000: train_loss 0.0026847 — train_PSNR 25.753 — val_loss 0.0026468 — val_PSNR 26.399\r\n",
      "[07:46:42] Saved best model at step 57000\r\n",
      "[07:46:44] Progress step 57100/300000 — loss 0.0027229 — PSNR 25.681\r\n",
      "[07:46:45] Progress step 57200/300000 — loss 0.0027003 — PSNR 25.723\r\n",
      "[07:46:47] Progress step 57300/300000 — loss 0.0026892 — PSNR 25.741\r\n",
      "[07:46:49] Progress step 57400/300000 — loss 0.0027014 — PSNR 25.723\r\n",
      "[07:46:50] Progress step 57500/300000 — loss 0.0026908 — PSNR 25.740\r\n",
      "[07:46:52] Progress step 57600/300000 — loss 0.0026871 — PSNR 25.745\r\n",
      "[07:46:54] Progress step 57700/300000 — loss 0.0026858 — PSNR 25.747\r\n",
      "[07:46:55] Progress step 57800/300000 — loss 0.0026852 — PSNR 25.749\r\n",
      "[07:46:57] Progress step 57900/300000 — loss 0.0026873 — PSNR 25.746\r\n",
      "[07:46:58] Progress step 58000/300000 — loss 0.0026833 — PSNR 25.753\r\n",
      "[07:46:58] Eval @ 58000: train_loss 0.0026833 — train_PSNR 25.753 — val_loss 0.0032786 — val_PSNR 24.843\r\n",
      "[07:47:00] Progress step 58100/300000 — loss 0.0027076 — PSNR 25.716\r\n",
      "[07:47:02] Progress step 58200/300000 — loss 0.0027001 — PSNR 25.726\r\n",
      "[07:47:03] Progress step 58300/300000 — loss 0.0026922 — PSNR 25.735\r\n",
      "[07:47:05] Progress step 58400/300000 — loss 0.0026873 — PSNR 25.744\r\n",
      "[07:47:06] Progress step 58500/300000 — loss 0.0026886 — PSNR 25.744\r\n",
      "[07:47:08] Progress step 58600/300000 — loss 0.0026891 — PSNR 25.745\r\n",
      "[07:47:10] Progress step 58700/300000 — loss 0.0026801 — PSNR 25.761\r\n",
      "[07:47:11] Progress step 58800/300000 — loss 0.0026797 — PSNR 25.761\r\n",
      "[07:47:13] Progress step 58900/300000 — loss 0.0026801 — PSNR 25.761\r\n",
      "[07:47:14] Progress step 59000/300000 — loss 0.0026826 — PSNR 25.756\r\n",
      "[07:47:33] Eval @ 59000: train_loss 0.0026826 — train_PSNR 25.756 — val_loss 0.0026471 — val_PSNR 26.398\r\n",
      "[07:47:35] Progress step 59100/300000 — loss 0.0026048 — PSNR 25.887\r\n",
      "[07:47:37] Progress step 59200/300000 — loss 0.0026567 — PSNR 25.797\r\n",
      "[07:47:38] Progress step 59300/300000 — loss 0.0026666 — PSNR 25.779\r\n",
      "[07:47:40] Progress step 59400/300000 — loss 0.0026724 — PSNR 25.769\r\n",
      "[07:47:42] Progress step 59500/300000 — loss 0.0026815 — PSNR 25.754\r\n",
      "[07:47:43] Progress step 59600/300000 — loss 0.0026869 — PSNR 25.747\r\n",
      "[07:47:45] Progress step 59700/300000 — loss 0.0026804 — PSNR 25.758\r\n",
      "[07:47:46] Progress step 59800/300000 — loss 0.0026902 — PSNR 25.744\r\n",
      "[07:47:48] Progress step 59900/300000 — loss 0.0026910 — PSNR 25.743\r\n",
      "[07:47:50] Progress step 60000/300000 — loss 0.0026910 — PSNR 25.744\r\n",
      "[07:47:50] Eval @ 60000: train_loss 0.0026910 — train_PSNR 25.744 — val_loss 0.0033049 — val_PSNR 24.808\r\n",
      "[07:47:51] Progress step 60100/300000 — loss 0.0026827 — PSNR 25.751\r\n",
      "[07:47:53] Progress step 60200/300000 — loss 0.0027033 — PSNR 25.719\r\n",
      "[07:47:54] Progress step 60300/300000 — loss 0.0027102 — PSNR 25.707\r\n",
      "[07:47:56] Progress step 60400/300000 — loss 0.0027089 — PSNR 25.710\r\n",
      "[07:47:58] Progress step 60500/300000 — loss 0.0026912 — PSNR 25.740\r\n",
      "[07:47:59] Progress step 60600/300000 — loss 0.0026763 — PSNR 25.765\r\n",
      "[07:48:01] Progress step 60700/300000 — loss 0.0026717 — PSNR 25.771\r\n",
      "[07:48:02] Progress step 60800/300000 — loss 0.0026739 — PSNR 25.768\r\n",
      "[07:48:04] Progress step 60900/300000 — loss 0.0026760 — PSNR 25.765\r\n",
      "[07:48:06] Progress step 61000/300000 — loss 0.0026730 — PSNR 25.769\r\n",
      "[07:48:24] Eval @ 61000: train_loss 0.0026730 — train_PSNR 25.769 — val_loss 0.0026475 — val_PSNR 26.398\r\n",
      "[07:48:26] Progress step 61100/300000 — loss 0.0026516 — PSNR 25.805\r\n",
      "[07:48:28] Progress step 61200/300000 — loss 0.0026602 — PSNR 25.787\r\n",
      "[07:48:29] Progress step 61300/300000 — loss 0.0026591 — PSNR 25.790\r\n",
      "[07:48:31] Progress step 61400/300000 — loss 0.0026593 — PSNR 25.792\r\n",
      "[07:48:33] Progress step 61500/300000 — loss 0.0026649 — PSNR 25.782\r\n",
      "[07:48:34] Progress step 61600/300000 — loss 0.0026805 — PSNR 25.757\r\n",
      "[07:48:36] Progress step 61700/300000 — loss 0.0026811 — PSNR 25.757\r\n",
      "[07:48:37] Progress step 61800/300000 — loss 0.0026807 — PSNR 25.758\r\n",
      "[07:48:39] Progress step 61900/300000 — loss 0.0026794 — PSNR 25.761\r\n",
      "[07:48:41] Progress step 62000/300000 — loss 0.0026785 — PSNR 25.762\r\n",
      "[07:48:41] Eval @ 62000: train_loss 0.0026785 — train_PSNR 25.762 — val_loss 0.0032814 — val_PSNR 24.839\r\n",
      "[07:48:42] Progress step 62100/300000 — loss 0.0027015 — PSNR 25.718\r\n",
      "[07:48:44] Progress step 62200/300000 — loss 0.0026989 — PSNR 25.727\r\n",
      "[07:48:45] Progress step 62300/300000 — loss 0.0026736 — PSNR 25.768\r\n",
      "[07:48:47] Progress step 62400/300000 — loss 0.0026750 — PSNR 25.766\r\n",
      "[07:48:49] Progress step 62500/300000 — loss 0.0026953 — PSNR 25.738\r\n",
      "[07:48:50] Progress step 62600/300000 — loss 0.0027018 — PSNR 25.727\r\n",
      "[07:48:52] Progress step 62700/300000 — loss 0.0027039 — PSNR 25.724\r\n",
      "[07:48:53] Progress step 62800/300000 — loss 0.0026941 — PSNR 25.739\r\n",
      "[07:48:55] Progress step 62900/300000 — loss 0.0026895 — PSNR 25.746\r\n",
      "[07:48:57] Progress step 63000/300000 — loss 0.0026924 — PSNR 25.741\r\n",
      "[07:49:15] Eval @ 63000: train_loss 0.0026924 — train_PSNR 25.741 — val_loss 0.0026466 — val_PSNR 26.399\r\n",
      "[07:49:15] Saved best model at step 63000\r\n",
      "[07:49:17] Progress step 63100/300000 — loss 0.0027497 — PSNR 25.663\r\n",
      "[07:49:19] Progress step 63200/300000 — loss 0.0027095 — PSNR 25.724\r\n",
      "[07:49:20] Progress step 63300/300000 — loss 0.0027187 — PSNR 25.705\r\n",
      "[07:49:22] Progress step 63400/300000 — loss 0.0027186 — PSNR 25.705\r\n",
      "[07:49:23] Progress step 63500/300000 — loss 0.0027178 — PSNR 25.705\r\n",
      "[07:49:25] Progress step 63600/300000 — loss 0.0027079 — PSNR 25.719\r\n",
      "[07:49:27] Progress step 63700/300000 — loss 0.0026978 — PSNR 25.734\r\n",
      "[07:49:28] Progress step 63800/300000 — loss 0.0026901 — PSNR 25.746\r\n",
      "[07:49:30] Progress step 63900/300000 — loss 0.0026873 — PSNR 25.750\r\n",
      "[07:49:31] Progress step 64000/300000 — loss 0.0026881 — PSNR 25.749\r\n",
      "[07:49:31] Eval @ 64000: train_loss 0.0026881 — train_PSNR 25.749 — val_loss 0.0032821 — val_PSNR 24.838\r\n",
      "[07:49:33] Progress step 64100/300000 — loss 0.0026266 — PSNR 25.853\r\n",
      "[07:49:35] Progress step 64200/300000 — loss 0.0026444 — PSNR 25.823\r\n",
      "[07:49:36] Progress step 64300/300000 — loss 0.0026700 — PSNR 25.780\r\n",
      "[07:49:38] Progress step 64400/300000 — loss 0.0026828 — PSNR 25.755\r\n",
      "[07:49:39] Progress step 64500/300000 — loss 0.0026833 — PSNR 25.755\r\n",
      "[07:49:41] Progress step 64600/300000 — loss 0.0026813 — PSNR 25.757\r\n",
      "[07:49:43] Progress step 64700/300000 — loss 0.0026820 — PSNR 25.756\r\n",
      "[07:49:44] Progress step 64800/300000 — loss 0.0026919 — PSNR 25.740\r\n",
      "[07:49:46] Progress step 64900/300000 — loss 0.0026970 — PSNR 25.732\r\n",
      "[07:49:47] Progress step 65000/300000 — loss 0.0026956 — PSNR 25.734\r\n",
      "[07:50:06] Eval @ 65000: train_loss 0.0026956 — train_PSNR 25.734 — val_loss 0.0026465 — val_PSNR 26.400\r\n",
      "[07:50:06] Saved best model at step 65000\r\n",
      "[07:50:08] Progress step 65100/300000 — loss 0.0026811 — PSNR 25.756\r\n",
      "[07:50:10] Progress step 65200/300000 — loss 0.0026936 — PSNR 25.732\r\n",
      "[07:50:11] Progress step 65300/300000 — loss 0.0026986 — PSNR 25.724\r\n",
      "[07:50:13] Progress step 65400/300000 — loss 0.0026884 — PSNR 25.741\r\n",
      "[07:50:14] Progress step 65500/300000 — loss 0.0026794 — PSNR 25.758\r\n",
      "[07:50:16] Progress step 65600/300000 — loss 0.0026743 — PSNR 25.767\r\n",
      "[07:50:18] Progress step 65700/300000 — loss 0.0026880 — PSNR 25.745\r\n",
      "[07:50:19] Progress step 65800/300000 — loss 0.0026916 — PSNR 25.739\r\n",
      "[07:50:21] Progress step 65900/300000 — loss 0.0026947 — PSNR 25.735\r\n",
      "[07:50:22] Progress step 66000/300000 — loss 0.0026963 — PSNR 25.732\r\n",
      "[07:50:22] Eval @ 66000: train_loss 0.0026963 — train_PSNR 25.732 — val_loss 0.0032721 — val_PSNR 24.852\r\n",
      "[07:50:24] Progress step 66100/300000 — loss 0.0027198 — PSNR 25.690\r\n",
      "[07:50:25] Progress step 66200/300000 — loss 0.0027052 — PSNR 25.715\r\n",
      "[07:50:27] Progress step 66300/300000 — loss 0.0026975 — PSNR 25.727\r\n",
      "[07:50:29] Progress step 66400/300000 — loss 0.0027115 — PSNR 25.707\r\n",
      "[07:50:30] Progress step 66500/300000 — loss 0.0026996 — PSNR 25.726\r\n",
      "[07:50:32] Progress step 66600/300000 — loss 0.0027044 — PSNR 25.719\r\n",
      "[07:50:33] Progress step 66700/300000 — loss 0.0027001 — PSNR 25.727\r\n",
      "[07:50:35] Progress step 66800/300000 — loss 0.0027048 — PSNR 25.720\r\n",
      "[07:50:37] Progress step 66900/300000 — loss 0.0027080 — PSNR 25.716\r\n",
      "[07:50:38] Progress step 67000/300000 — loss 0.0027103 — PSNR 25.712\r\n",
      "[07:50:57] Eval @ 67000: train_loss 0.0027103 — train_PSNR 25.712 — val_loss 0.0026470 — val_PSNR 26.399\r\n",
      "[07:50:58] Progress step 67100/300000 — loss 0.0026921 — PSNR 25.738\r\n",
      "[07:51:00] Progress step 67200/300000 — loss 0.0026994 — PSNR 25.726\r\n",
      "[07:51:02] Progress step 67300/300000 — loss 0.0026831 — PSNR 25.752\r\n",
      "[07:51:03] Progress step 67400/300000 — loss 0.0026892 — PSNR 25.744\r\n",
      "[07:51:05] Progress step 67500/300000 — loss 0.0026912 — PSNR 25.741\r\n",
      "[07:51:07] Progress step 67600/300000 — loss 0.0026906 — PSNR 25.743\r\n",
      "[07:51:08] Progress step 67700/300000 — loss 0.0026947 — PSNR 25.736\r\n",
      "[07:51:10] Progress step 67800/300000 — loss 0.0026938 — PSNR 25.738\r\n",
      "[07:51:11] Progress step 67900/300000 — loss 0.0026937 — PSNR 25.738\r\n",
      "[07:51:13] Progress step 68000/300000 — loss 0.0026980 — PSNR 25.732\r\n",
      "[07:51:13] Eval @ 68000: train_loss 0.0026980 — train_PSNR 25.732 — val_loss 0.0032731 — val_PSNR 24.850\r\n",
      "[07:51:15] Progress step 68100/300000 — loss 0.0026570 — PSNR 25.803\r\n",
      "[07:51:16] Progress step 68200/300000 — loss 0.0026547 — PSNR 25.803\r\n",
      "[07:51:18] Progress step 68300/300000 — loss 0.0026501 — PSNR 25.811\r\n",
      "[07:51:19] Progress step 68400/300000 — loss 0.0026647 — PSNR 25.787\r\n",
      "[07:51:21] Progress step 68500/300000 — loss 0.0026648 — PSNR 25.788\r\n",
      "[07:51:23] Progress step 68600/300000 — loss 0.0026644 — PSNR 25.787\r\n",
      "[07:51:24] Progress step 68700/300000 — loss 0.0026653 — PSNR 25.785\r\n",
      "[07:51:26] Progress step 68800/300000 — loss 0.0026695 — PSNR 25.778\r\n",
      "[07:51:28] Progress step 68900/300000 — loss 0.0026748 — PSNR 25.769\r\n",
      "[07:51:29] Progress step 69000/300000 — loss 0.0026759 — PSNR 25.767\r\n",
      "[07:51:48] Eval @ 69000: train_loss 0.0026759 — train_PSNR 25.767 — val_loss 0.0026510 — val_PSNR 26.390\r\n",
      "[07:51:50] Progress step 69100/300000 — loss 0.0027003 — PSNR 25.727\r\n",
      "[07:51:51] Progress step 69200/300000 — loss 0.0026985 — PSNR 25.730\r\n",
      "[07:51:53] Progress step 69300/300000 — loss 0.0026970 — PSNR 25.733\r\n",
      "[07:51:55] Progress step 69400/300000 — loss 0.0026852 — PSNR 25.752\r\n",
      "[07:51:56] Progress step 69500/300000 — loss 0.0026663 — PSNR 25.782\r\n",
      "[07:51:58] Progress step 69600/300000 — loss 0.0026700 — PSNR 25.776\r\n",
      "[07:51:59] Progress step 69700/300000 — loss 0.0026707 — PSNR 25.775\r\n",
      "[07:52:01] Progress step 69800/300000 — loss 0.0026703 — PSNR 25.775\r\n",
      "[07:52:03] Progress step 69900/300000 — loss 0.0026727 — PSNR 25.770\r\n",
      "[07:52:04] Progress step 70000/300000 — loss 0.0026759 — PSNR 25.765\r\n",
      "[07:52:04] Eval @ 70000: train_loss 0.0026759 — train_PSNR 25.765 — val_loss 0.0032719 — val_PSNR 24.852\r\n",
      "[07:52:06] Progress step 70100/300000 — loss 0.0026852 — PSNR 25.744\r\n",
      "[07:52:07] Progress step 70200/300000 — loss 0.0026957 — PSNR 25.732\r\n",
      "[07:52:09] Progress step 70300/300000 — loss 0.0027007 — PSNR 25.724\r\n",
      "[07:52:11] Progress step 70400/300000 — loss 0.0026871 — PSNR 25.746\r\n",
      "[07:52:12] Progress step 70500/300000 — loss 0.0026860 — PSNR 25.748\r\n",
      "[07:52:14] Progress step 70600/300000 — loss 0.0026929 — PSNR 25.737\r\n",
      "[07:52:15] Progress step 70700/300000 — loss 0.0026914 — PSNR 25.740\r\n",
      "[07:52:17] Progress step 70800/300000 — loss 0.0026898 — PSNR 25.742\r\n",
      "[07:52:19] Progress step 70900/300000 — loss 0.0026924 — PSNR 25.738\r\n",
      "[07:52:20] Progress step 71000/300000 — loss 0.0027001 — PSNR 25.726\r\n",
      "[07:52:39] Eval @ 71000: train_loss 0.0027001 — train_PSNR 25.726 — val_loss 0.0026498 — val_PSNR 26.392\r\n",
      "[07:52:41] Progress step 71100/300000 — loss 0.0027302 — PSNR 25.688\r\n",
      "[07:52:43] Progress step 71200/300000 — loss 0.0027216 — PSNR 25.699\r\n",
      "[07:52:44] Progress step 71300/300000 — loss 0.0027020 — PSNR 25.727\r\n",
      "[07:52:46] Progress step 71400/300000 — loss 0.0027020 — PSNR 25.726\r\n",
      "[07:52:47] Progress step 71500/300000 — loss 0.0026928 — PSNR 25.742\r\n",
      "[07:52:49] Progress step 71600/300000 — loss 0.0026917 — PSNR 25.743\r\n",
      "[07:52:51] Progress step 71700/300000 — loss 0.0026868 — PSNR 25.751\r\n",
      "[07:52:52] Progress step 71800/300000 — loss 0.0026836 — PSNR 25.755\r\n",
      "[07:52:54] Progress step 71900/300000 — loss 0.0026779 — PSNR 25.765\r\n",
      "[07:52:55] Progress step 72000/300000 — loss 0.0026746 — PSNR 25.772\r\n",
      "[07:52:55] Eval @ 72000: train_loss 0.0026746 — train_PSNR 25.772 — val_loss 0.0032904 — val_PSNR 24.828\r\n",
      "[07:52:57] Progress step 72100/300000 — loss 0.0027016 — PSNR 25.724\r\n",
      "[07:52:59] Progress step 72200/300000 — loss 0.0026816 — PSNR 25.755\r\n",
      "[07:53:00] Progress step 72300/300000 — loss 0.0026902 — PSNR 25.739\r\n",
      "[07:53:02] Progress step 72400/300000 — loss 0.0026945 — PSNR 25.734\r\n",
      "[07:53:03] Progress step 72500/300000 — loss 0.0026939 — PSNR 25.733\r\n",
      "[07:53:05] Progress step 72600/300000 — loss 0.0026835 — PSNR 25.752\r\n",
      "[07:53:07] Progress step 72700/300000 — loss 0.0026932 — PSNR 25.736\r\n",
      "[07:53:08] Progress step 72800/300000 — loss 0.0026892 — PSNR 25.744\r\n",
      "[07:53:10] Progress step 72900/300000 — loss 0.0026899 — PSNR 25.743\r\n",
      "[07:53:12] Progress step 73000/300000 — loss 0.0026848 — PSNR 25.751\r\n",
      "[07:53:30] Eval @ 73000: train_loss 0.0026848 — train_PSNR 25.751 — val_loss 0.0026482 — val_PSNR 26.396\r\n",
      "[07:53:32] Progress step 73100/300000 — loss 0.0026534 — PSNR 25.797\r\n",
      "[07:53:34] Progress step 73200/300000 — loss 0.0027068 — PSNR 25.716\r\n",
      "[07:53:35] Progress step 73300/300000 — loss 0.0026878 — PSNR 25.745\r\n",
      "[07:53:37] Progress step 73400/300000 — loss 0.0026848 — PSNR 25.750\r\n",
      "[07:53:38] Progress step 73500/300000 — loss 0.0026881 — PSNR 25.746\r\n",
      "[07:53:40] Progress step 73600/300000 — loss 0.0026879 — PSNR 25.748\r\n",
      "[07:53:42] Progress step 73700/300000 — loss 0.0026922 — PSNR 25.741\r\n",
      "[07:53:43] Progress step 73800/300000 — loss 0.0026990 — PSNR 25.732\r\n",
      "[07:53:45] Progress step 73900/300000 — loss 0.0026967 — PSNR 25.735\r\n",
      "[07:53:47] Progress step 74000/300000 — loss 0.0026961 — PSNR 25.737\r\n",
      "[07:53:47] Eval @ 74000: train_loss 0.0026961 — train_PSNR 25.737 — val_loss 0.0032755 — val_PSNR 24.847\r\n",
      "[07:53:48] Progress step 74100/300000 — loss 0.0027100 — PSNR 25.709\r\n",
      "[07:53:50] Progress step 74200/300000 — loss 0.0027133 — PSNR 25.701\r\n",
      "[07:53:51] Progress step 74300/300000 — loss 0.0026911 — PSNR 25.739\r\n",
      "[07:53:53] Progress step 74400/300000 — loss 0.0026905 — PSNR 25.740\r\n",
      "[07:53:55] Progress step 74500/300000 — loss 0.0027050 — PSNR 25.717\r\n",
      "[07:53:56] Progress step 74600/300000 — loss 0.0027044 — PSNR 25.718\r\n",
      "[07:53:58] Progress step 74700/300000 — loss 0.0027004 — PSNR 25.725\r\n",
      "[07:53:59] Progress step 74800/300000 — loss 0.0026893 — PSNR 25.743\r\n",
      "[07:54:01] Progress step 74900/300000 — loss 0.0026869 — PSNR 25.746\r\n",
      "[07:54:03] Progress step 75000/300000 — loss 0.0026911 — PSNR 25.740\r\n",
      "[07:54:22] Eval @ 75000: train_loss 0.0026911 — train_PSNR 25.740 — val_loss 0.0026483 — val_PSNR 26.396\r\n",
      "[07:54:23] Progress step 75100/300000 — loss 0.0026838 — PSNR 25.763\r\n",
      "[07:54:25] Progress step 75200/300000 — loss 0.0027078 — PSNR 25.720\r\n",
      "[07:54:26] Progress step 75300/300000 — loss 0.0027053 — PSNR 25.722\r\n",
      "[07:54:28] Progress step 75400/300000 — loss 0.0027075 — PSNR 25.716\r\n",
      "[07:54:30] Progress step 75500/300000 — loss 0.0026965 — PSNR 25.733\r\n",
      "[07:54:31] Progress step 75600/300000 — loss 0.0026895 — PSNR 25.746\r\n",
      "[07:54:33] Progress step 75700/300000 — loss 0.0026826 — PSNR 25.756\r\n",
      "[07:54:35] Progress step 75800/300000 — loss 0.0026875 — PSNR 25.748\r\n",
      "[07:54:36] Progress step 75900/300000 — loss 0.0026858 — PSNR 25.749\r\n",
      "[07:54:38] Progress step 76000/300000 — loss 0.0026898 — PSNR 25.743\r\n",
      "[07:54:38] Eval @ 76000: train_loss 0.0026898 — train_PSNR 25.743 — val_loss 0.0032745 — val_PSNR 24.849\r\n",
      "[07:54:39] Progress step 76100/300000 — loss 0.0027388 — PSNR 25.667\r\n",
      "[07:54:41] Progress step 76200/300000 — loss 0.0027319 — PSNR 25.675\r\n",
      "[07:54:43] Progress step 76300/300000 — loss 0.0027186 — PSNR 25.697\r\n",
      "[07:54:44] Progress step 76400/300000 — loss 0.0027213 — PSNR 25.691\r\n",
      "[07:54:46] Progress step 76500/300000 — loss 0.0027086 — PSNR 25.711\r\n",
      "[07:54:48] Progress step 76600/300000 — loss 0.0027003 — PSNR 25.726\r\n",
      "[07:54:49] Progress step 76700/300000 — loss 0.0027039 — PSNR 25.720\r\n",
      "[07:54:51] Progress step 76800/300000 — loss 0.0027044 — PSNR 25.720\r\n",
      "[07:54:52] Progress step 76900/300000 — loss 0.0026980 — PSNR 25.730\r\n",
      "[07:54:54] Progress step 77000/300000 — loss 0.0026954 — PSNR 25.734\r\n",
      "[07:55:13] Eval @ 77000: train_loss 0.0026954 — train_PSNR 25.734 — val_loss 0.0026465 — val_PSNR 26.400\r\n",
      "[07:55:13] Saved best model at step 77000\r\n",
      "[07:55:14] Progress step 77100/300000 — loss 0.0026485 — PSNR 25.809\r\n",
      "[07:55:16] Progress step 77200/300000 — loss 0.0026765 — PSNR 25.762\r\n",
      "[07:55:18] Progress step 77300/300000 — loss 0.0026904 — PSNR 25.742\r\n",
      "[07:55:19] Progress step 77400/300000 — loss 0.0026935 — PSNR 25.739\r\n",
      "[07:55:21] Progress step 77500/300000 — loss 0.0026864 — PSNR 25.751\r\n",
      "[07:55:23] Progress step 77600/300000 — loss 0.0026872 — PSNR 25.749\r\n",
      "[07:55:24] Progress step 77700/300000 — loss 0.0026856 — PSNR 25.752\r\n",
      "[07:55:26] Progress step 77800/300000 — loss 0.0026892 — PSNR 25.746\r\n",
      "[07:55:27] Progress step 77900/300000 — loss 0.0026839 — PSNR 25.753\r\n",
      "[07:55:29] Progress step 78000/300000 — loss 0.0026892 — PSNR 25.744\r\n",
      "[07:55:29] Eval @ 78000: train_loss 0.0026892 — train_PSNR 25.744 — val_loss 0.0032815 — val_PSNR 24.839\r\n",
      "[07:55:31] Progress step 78100/300000 — loss 0.0027007 — PSNR 25.729\r\n",
      "[07:55:32] Progress step 78200/300000 — loss 0.0027049 — PSNR 25.722\r\n",
      "[07:55:34] Progress step 78300/300000 — loss 0.0027042 — PSNR 25.721\r\n",
      "[07:55:35] Progress step 78400/300000 — loss 0.0027123 — PSNR 25.706\r\n",
      "[07:55:37] Progress step 78500/300000 — loss 0.0027069 — PSNR 25.716\r\n",
      "[07:55:39] Progress step 78600/300000 — loss 0.0027120 — PSNR 25.708\r\n",
      "[07:55:40] Progress step 78700/300000 — loss 0.0026999 — PSNR 25.726\r\n",
      "[07:55:42] Progress step 78800/300000 — loss 0.0026934 — PSNR 25.737\r\n",
      "[07:55:43] Progress step 78900/300000 — loss 0.0026999 — PSNR 25.727\r\n",
      "[07:55:45] Progress step 79000/300000 — loss 0.0026944 — PSNR 25.736\r\n",
      "[07:56:04] Eval @ 79000: train_loss 0.0026944 — train_PSNR 25.736 — val_loss 0.0026469 — val_PSNR 26.399\r\n",
      "[07:56:06] Progress step 79100/300000 — loss 0.0026231 — PSNR 25.849\r\n",
      "[07:56:07] Progress step 79200/300000 — loss 0.0026323 — PSNR 25.831\r\n",
      "[07:56:09] Progress step 79300/300000 — loss 0.0026534 — PSNR 25.801\r\n",
      "[07:56:10] Progress step 79400/300000 — loss 0.0026700 — PSNR 25.773\r\n",
      "[07:56:12] Progress step 79500/300000 — loss 0.0026792 — PSNR 25.759\r\n",
      "[07:56:14] Progress step 79600/300000 — loss 0.0026794 — PSNR 25.759\r\n",
      "[07:56:15] Progress step 79700/300000 — loss 0.0026790 — PSNR 25.760\r\n",
      "[07:56:17] Progress step 79800/300000 — loss 0.0026833 — PSNR 25.752\r\n",
      "[07:56:18] Progress step 79900/300000 — loss 0.0026914 — PSNR 25.739\r\n",
      "[07:56:20] Progress step 80000/300000 — loss 0.0026945 — PSNR 25.734\r\n",
      "[07:56:20] Eval @ 80000: train_loss 0.0026945 — train_PSNR 25.734 — val_loss 0.0032893 — val_PSNR 24.829\r\n",
      "[07:56:22] Progress step 80100/300000 — loss 0.0026687 — PSNR 25.782\r\n",
      "[07:56:23] Progress step 80200/300000 — loss 0.0026480 — PSNR 25.813\r\n",
      "[07:56:25] Progress step 80300/300000 — loss 0.0026676 — PSNR 25.782\r\n",
      "[07:56:26] Progress step 80400/300000 — loss 0.0026645 — PSNR 25.786\r\n",
      "[07:56:28] Progress step 80500/300000 — loss 0.0026710 — PSNR 25.773\r\n",
      "[07:56:30] Progress step 80600/300000 — loss 0.0026799 — PSNR 25.760\r\n",
      "[07:56:31] Progress step 80700/300000 — loss 0.0026831 — PSNR 25.755\r\n",
      "[07:56:33] Progress step 80800/300000 — loss 0.0026773 — PSNR 25.766\r\n",
      "[07:56:34] Progress step 80900/300000 — loss 0.0026774 — PSNR 25.765\r\n",
      "[07:56:36] Progress step 81000/300000 — loss 0.0026747 — PSNR 25.770\r\n",
      "[07:56:55] Eval @ 81000: train_loss 0.0026747 — train_PSNR 25.770 — val_loss 0.0026496 — val_PSNR 26.393\r\n",
      "[07:56:57] Progress step 81100/300000 — loss 0.0027567 — PSNR 25.651\r\n",
      "[07:56:58] Progress step 81200/300000 — loss 0.0027278 — PSNR 25.696\r\n",
      "[07:57:00] Progress step 81300/300000 — loss 0.0027150 — PSNR 25.711\r\n",
      "[07:57:02] Progress step 81400/300000 — loss 0.0026788 — PSNR 25.769\r\n",
      "[07:57:03] Progress step 81500/300000 — loss 0.0026802 — PSNR 25.765\r\n",
      "[07:57:05] Progress step 81600/300000 — loss 0.0026779 — PSNR 25.768\r\n",
      "[07:57:06] Progress step 81700/300000 — loss 0.0026739 — PSNR 25.775\r\n",
      "[07:57:08] Progress step 81800/300000 — loss 0.0026776 — PSNR 25.768\r\n",
      "[07:57:10] Progress step 81900/300000 — loss 0.0026820 — PSNR 25.760\r\n",
      "[07:57:11] Progress step 82000/300000 — loss 0.0026807 — PSNR 25.762\r\n",
      "[07:57:11] Eval @ 82000: train_loss 0.0026807 — train_PSNR 25.762 — val_loss 0.0032731 — val_PSNR 24.850\r\n",
      "[07:57:13] Progress step 82100/300000 — loss 0.0027414 — PSNR 25.678\r\n",
      "[07:57:14] Progress step 82200/300000 — loss 0.0026877 — PSNR 25.758\r\n",
      "[07:57:16] Progress step 82300/300000 — loss 0.0026880 — PSNR 25.754\r\n",
      "[07:57:18] Progress step 82400/300000 — loss 0.0026760 — PSNR 25.774\r\n",
      "[07:57:19] Progress step 82500/300000 — loss 0.0026736 — PSNR 25.777\r\n",
      "[07:57:21] Progress step 82600/300000 — loss 0.0026669 — PSNR 25.786\r\n",
      "[07:57:22] Progress step 82700/300000 — loss 0.0026700 — PSNR 25.780\r\n",
      "[07:57:24] Progress step 82800/300000 — loss 0.0026797 — PSNR 25.764\r\n",
      "[07:57:26] Progress step 82900/300000 — loss 0.0026854 — PSNR 25.754\r\n",
      "[07:57:27] Progress step 83000/300000 — loss 0.0026892 — PSNR 25.746\r\n",
      "[07:57:46] Eval @ 83000: train_loss 0.0026892 — train_PSNR 25.746 — val_loss 0.0026471 — val_PSNR 26.398\r\n",
      "[07:57:48] Progress step 83100/300000 — loss 0.0027361 — PSNR 25.662\r\n",
      "[07:57:49] Progress step 83200/300000 — loss 0.0026860 — PSNR 25.748\r\n",
      "[07:57:51] Progress step 83300/300000 — loss 0.0026854 — PSNR 25.748\r\n",
      "[07:57:53] Progress step 83400/300000 — loss 0.0026937 — PSNR 25.734\r\n",
      "[07:57:54] Progress step 83500/300000 — loss 0.0026809 — PSNR 25.753\r\n",
      "[07:57:56] Progress step 83600/300000 — loss 0.0026920 — PSNR 25.740\r\n",
      "[07:57:58] Progress step 83700/300000 — loss 0.0026859 — PSNR 25.750\r\n",
      "[07:57:59] Progress step 83800/300000 — loss 0.0026804 — PSNR 25.760\r\n",
      "[07:58:01] Progress step 83900/300000 — loss 0.0026805 — PSNR 25.759\r\n",
      "[07:58:02] Progress step 84000/300000 — loss 0.0026858 — PSNR 25.751\r\n",
      "[07:58:02] Eval @ 84000: train_loss 0.0026858 — train_PSNR 25.751 — val_loss 0.0032927 — val_PSNR 24.824\r\n",
      "[07:58:04] Progress step 84100/300000 — loss 0.0026602 — PSNR 25.795\r\n",
      "[07:58:06] Progress step 84200/300000 — loss 0.0026866 — PSNR 25.750\r\n",
      "[07:58:07] Progress step 84300/300000 — loss 0.0026713 — PSNR 25.774\r\n",
      "[07:58:09] Progress step 84400/300000 — loss 0.0026785 — PSNR 25.762\r\n",
      "[07:58:11] Progress step 84500/300000 — loss 0.0026826 — PSNR 25.754\r\n",
      "[07:58:12] Progress step 84600/300000 — loss 0.0026883 — PSNR 25.745\r\n",
      "[07:58:14] Progress step 84700/300000 — loss 0.0026870 — PSNR 25.747\r\n",
      "[07:58:15] Progress step 84800/300000 — loss 0.0026853 — PSNR 25.749\r\n",
      "[07:58:17] Progress step 84900/300000 — loss 0.0026859 — PSNR 25.748\r\n",
      "[07:58:19] Progress step 85000/300000 — loss 0.0026877 — PSNR 25.746\r\n",
      "[07:58:37] Eval @ 85000: train_loss 0.0026877 — train_PSNR 25.746 — val_loss 0.0026478 — val_PSNR 26.397\r\n",
      "[07:58:39] Progress step 85100/300000 — loss 0.0027053 — PSNR 25.724\r\n",
      "[07:58:41] Progress step 85200/300000 — loss 0.0026947 — PSNR 25.738\r\n",
      "[07:58:42] Progress step 85300/300000 — loss 0.0026883 — PSNR 25.749\r\n",
      "[07:58:44] Progress step 85400/300000 — loss 0.0026996 — PSNR 25.730\r\n",
      "[07:58:46] Progress step 85500/300000 — loss 0.0026881 — PSNR 25.749\r\n",
      "[07:58:47] Progress step 85600/300000 — loss 0.0026967 — PSNR 25.733\r\n",
      "[07:58:49] Progress step 85700/300000 — loss 0.0026992 — PSNR 25.729\r\n",
      "[07:58:50] Progress step 85800/300000 — loss 0.0026910 — PSNR 25.743\r\n",
      "[07:58:52] Progress step 85900/300000 — loss 0.0026878 — PSNR 25.748\r\n",
      "[07:58:54] Progress step 86000/300000 — loss 0.0026839 — PSNR 25.754\r\n",
      "[07:58:54] Eval @ 86000: train_loss 0.0026839 — train_PSNR 25.754 — val_loss 0.0032677 — val_PSNR 24.858\r\n",
      "[07:58:55] Progress step 86100/300000 — loss 0.0026467 — PSNR 25.803\r\n",
      "[07:58:57] Progress step 86200/300000 — loss 0.0026604 — PSNR 25.792\r\n",
      "[07:58:58] Progress step 86300/300000 — loss 0.0026746 — PSNR 25.773\r\n",
      "[07:59:00] Progress step 86400/300000 — loss 0.0026632 — PSNR 25.792\r\n",
      "[07:59:02] Progress step 86500/300000 — loss 0.0026820 — PSNR 25.761\r\n",
      "[07:59:03] Progress step 86600/300000 — loss 0.0026854 — PSNR 25.754\r\n",
      "[07:59:05] Progress step 86700/300000 — loss 0.0026832 — PSNR 25.756\r\n",
      "[07:59:06] Progress step 86800/300000 — loss 0.0026843 — PSNR 25.754\r\n",
      "[07:59:08] Progress step 86900/300000 — loss 0.0026841 — PSNR 25.753\r\n",
      "[07:59:10] Progress step 87000/300000 — loss 0.0026817 — PSNR 25.757\r\n",
      "[07:59:28] Eval @ 87000: train_loss 0.0026817 — train_PSNR 25.757 — val_loss 0.0026533 — val_PSNR 26.385\r\n",
      "[07:59:30] Progress step 87100/300000 — loss 0.0026523 — PSNR 25.810\r\n",
      "[07:59:32] Progress step 87200/300000 — loss 0.0026621 — PSNR 25.792\r\n",
      "[07:59:33] Progress step 87300/300000 — loss 0.0026629 — PSNR 25.791\r\n",
      "[07:59:35] Progress step 87400/300000 — loss 0.0026599 — PSNR 25.794\r\n",
      "[07:59:37] Progress step 87500/300000 — loss 0.0026574 — PSNR 25.799\r\n",
      "[07:59:38] Progress step 87600/300000 — loss 0.0026584 — PSNR 25.797\r\n",
      "[07:59:40] Progress step 87700/300000 — loss 0.0026612 — PSNR 25.792\r\n",
      "[07:59:41] Progress step 87800/300000 — loss 0.0026600 — PSNR 25.793\r\n",
      "[07:59:43] Progress step 87900/300000 — loss 0.0026653 — PSNR 25.784\r\n",
      "[07:59:45] Progress step 88000/300000 — loss 0.0026678 — PSNR 25.780\r\n",
      "[07:59:45] Eval @ 88000: train_loss 0.0026678 — train_PSNR 25.780 — val_loss 0.0032711 — val_PSNR 24.853\r\n",
      "[07:59:46] Progress step 88100/300000 — loss 0.0027244 — PSNR 25.689\r\n",
      "[07:59:48] Progress step 88200/300000 — loss 0.0027020 — PSNR 25.724\r\n",
      "[07:59:49] Progress step 88300/300000 — loss 0.0026959 — PSNR 25.736\r\n",
      "[07:59:51] Progress step 88400/300000 — loss 0.0026908 — PSNR 25.745\r\n",
      "[07:59:53] Progress step 88500/300000 — loss 0.0026817 — PSNR 25.760\r\n",
      "[07:59:54] Progress step 88600/300000 — loss 0.0026981 — PSNR 25.732\r\n",
      "[07:59:56] Progress step 88700/300000 — loss 0.0026940 — PSNR 25.738\r\n",
      "[07:59:57] Progress step 88800/300000 — loss 0.0026944 — PSNR 25.738\r\n",
      "[07:59:59] Progress step 88900/300000 — loss 0.0026889 — PSNR 25.746\r\n",
      "[08:00:01] Progress step 89000/300000 — loss 0.0026902 — PSNR 25.743\r\n",
      "[08:00:19] Eval @ 89000: train_loss 0.0026902 — train_PSNR 25.743 — val_loss 0.0026468 — val_PSNR 26.399\r\n",
      "[08:00:21] Progress step 89100/300000 — loss 0.0026973 — PSNR 25.736\r\n",
      "[08:00:23] Progress step 89200/300000 — loss 0.0027059 — PSNR 25.720\r\n",
      "[08:00:24] Progress step 89300/300000 — loss 0.0027175 — PSNR 25.703\r\n",
      "[08:00:26] Progress step 89400/300000 — loss 0.0027120 — PSNR 25.712\r\n",
      "[08:00:27] Progress step 89500/300000 — loss 0.0026978 — PSNR 25.734\r\n",
      "[08:00:29] Progress step 89600/300000 — loss 0.0026855 — PSNR 25.755\r\n",
      "[08:00:31] Progress step 89700/300000 — loss 0.0026907 — PSNR 25.745\r\n",
      "[08:00:32] Progress step 89800/300000 — loss 0.0026947 — PSNR 25.738\r\n",
      "[08:00:34] Progress step 89900/300000 — loss 0.0026881 — PSNR 25.747\r\n",
      "[08:00:35] Progress step 90000/300000 — loss 0.0026853 — PSNR 25.752\r\n",
      "[08:00:35] Eval @ 90000: train_loss 0.0026853 — train_PSNR 25.752 — val_loss 0.0032714 — val_PSNR 24.853\r\n",
      "[08:00:37] Progress step 90100/300000 — loss 0.0027622 — PSNR 25.627\r\n",
      "[08:00:39] Progress step 90200/300000 — loss 0.0027530 — PSNR 25.637\r\n",
      "[08:00:40] Progress step 90300/300000 — loss 0.0027147 — PSNR 25.701\r\n",
      "[08:00:42] Progress step 90400/300000 — loss 0.0027164 — PSNR 25.699\r\n",
      "[08:00:43] Progress step 90500/300000 — loss 0.0027178 — PSNR 25.698\r\n",
      "[08:00:45] Progress step 90600/300000 — loss 0.0027122 — PSNR 25.706\r\n",
      "[08:00:47] Progress step 90700/300000 — loss 0.0027019 — PSNR 25.723\r\n",
      "[08:00:48] Progress step 90800/300000 — loss 0.0027030 — PSNR 25.722\r\n",
      "[08:00:50] Progress step 90900/300000 — loss 0.0027019 — PSNR 25.724\r\n",
      "[08:00:51] Progress step 91000/300000 — loss 0.0026973 — PSNR 25.732\r\n",
      "[08:01:10] Eval @ 91000: train_loss 0.0026973 — train_PSNR 25.732 — val_loss 0.0026576 — val_PSNR 26.376\r\n",
      "[08:01:12] Progress step 91100/300000 — loss 0.0026659 — PSNR 25.790\r\n",
      "[08:01:13] Progress step 91200/300000 — loss 0.0026805 — PSNR 25.766\r\n",
      "[08:01:15] Progress step 91300/300000 — loss 0.0026849 — PSNR 25.751\r\n",
      "[08:01:17] Progress step 91400/300000 — loss 0.0026876 — PSNR 25.748\r\n",
      "[08:01:18] Progress step 91500/300000 — loss 0.0027083 — PSNR 25.715\r\n",
      "[08:01:20] Progress step 91600/300000 — loss 0.0027009 — PSNR 25.728\r\n",
      "[08:01:22] Progress step 91700/300000 — loss 0.0026899 — PSNR 25.745\r\n",
      "[08:01:23] Progress step 91800/300000 — loss 0.0026879 — PSNR 25.748\r\n",
      "[08:01:25] Progress step 91900/300000 — loss 0.0026885 — PSNR 25.747\r\n",
      "[08:01:26] Progress step 92000/300000 — loss 0.0026806 — PSNR 25.759\r\n",
      "[08:01:26] Eval @ 92000: train_loss 0.0026806 — train_PSNR 25.759 — val_loss 0.0032715 — val_PSNR 24.852\r\n",
      "[08:01:28] Progress step 92100/300000 — loss 0.0027076 — PSNR 25.726\r\n",
      "[08:01:30] Progress step 92200/300000 — loss 0.0026890 — PSNR 25.749\r\n",
      "[08:01:31] Progress step 92300/300000 — loss 0.0026759 — PSNR 25.766\r\n",
      "[08:01:33] Progress step 92400/300000 — loss 0.0026977 — PSNR 25.732\r\n",
      "[08:01:34] Progress step 92500/300000 — loss 0.0027018 — PSNR 25.726\r\n",
      "[08:01:36] Progress step 92600/300000 — loss 0.0027122 — PSNR 25.710\r\n",
      "[08:01:38] Progress step 92700/300000 — loss 0.0027101 — PSNR 25.712\r\n",
      "[08:01:39] Progress step 92800/300000 — loss 0.0027059 — PSNR 25.718\r\n",
      "[08:01:41] Progress step 92900/300000 — loss 0.0026954 — PSNR 25.734\r\n",
      "[08:01:43] Progress step 93000/300000 — loss 0.0027060 — PSNR 25.717\r\n",
      "[08:02:01] Eval @ 93000: train_loss 0.0027060 — train_PSNR 25.717 — val_loss 0.0026470 — val_PSNR 26.398\r\n",
      "[08:02:03] Progress step 93100/300000 — loss 0.0026369 — PSNR 25.844\r\n",
      "[08:02:05] Progress step 93200/300000 — loss 0.0026627 — PSNR 25.797\r\n",
      "[08:02:06] Progress step 93300/300000 — loss 0.0026641 — PSNR 25.791\r\n",
      "[08:02:08] Progress step 93400/300000 — loss 0.0026600 — PSNR 25.796\r\n",
      "[08:02:09] Progress step 93500/300000 — loss 0.0026577 — PSNR 25.798\r\n",
      "[08:02:11] Progress step 93600/300000 — loss 0.0026616 — PSNR 25.791\r\n",
      "[08:02:13] Progress step 93700/300000 — loss 0.0026688 — PSNR 25.779\r\n",
      "[08:02:14] Progress step 93800/300000 — loss 0.0026674 — PSNR 25.781\r\n",
      "[08:02:16] Progress step 93900/300000 — loss 0.0026730 — PSNR 25.771\r\n",
      "[08:02:17] Progress step 94000/300000 — loss 0.0026691 — PSNR 25.777\r\n",
      "[08:02:17] Eval @ 94000: train_loss 0.0026691 — train_PSNR 25.777 — val_loss 0.0032825 — val_PSNR 24.838\r\n",
      "[08:02:19] Progress step 94100/300000 — loss 0.0026723 — PSNR 25.773\r\n",
      "[08:02:21] Progress step 94200/300000 — loss 0.0026653 — PSNR 25.786\r\n",
      "[08:02:22] Progress step 94300/300000 — loss 0.0026970 — PSNR 25.736\r\n",
      "[08:02:24] Progress step 94400/300000 — loss 0.0026966 — PSNR 25.735\r\n",
      "[08:02:25] Progress step 94500/300000 — loss 0.0027058 — PSNR 25.721\r\n",
      "[08:02:27] Progress step 94600/300000 — loss 0.0026967 — PSNR 25.735\r\n",
      "[08:02:29] Progress step 94700/300000 — loss 0.0026940 — PSNR 25.739\r\n",
      "[08:02:30] Progress step 94800/300000 — loss 0.0026945 — PSNR 25.738\r\n",
      "[08:02:32] Progress step 94900/300000 — loss 0.0026987 — PSNR 25.731\r\n",
      "[08:02:34] Progress step 95000/300000 — loss 0.0026970 — PSNR 25.734\r\n",
      "[08:02:52] Eval @ 95000: train_loss 0.0026970 — train_PSNR 25.734 — val_loss 0.0026481 — val_PSNR 26.396\r\n",
      "[08:02:54] Progress step 95100/300000 — loss 0.0026270 — PSNR 25.836\r\n",
      "[08:02:56] Progress step 95200/300000 — loss 0.0026706 — PSNR 25.770\r\n",
      "[08:02:57] Progress step 95300/300000 — loss 0.0026859 — PSNR 25.749\r\n",
      "[08:02:59] Progress step 95400/300000 — loss 0.0026878 — PSNR 25.744\r\n",
      "[08:03:00] Progress step 95500/300000 — loss 0.0026912 — PSNR 25.741\r\n",
      "[08:03:02] Progress step 95600/300000 — loss 0.0026965 — PSNR 25.732\r\n",
      "[08:03:04] Progress step 95700/300000 — loss 0.0026913 — PSNR 25.740\r\n",
      "[08:03:05] Progress step 95800/300000 — loss 0.0026838 — PSNR 25.752\r\n",
      "[08:03:07] Progress step 95900/300000 — loss 0.0026816 — PSNR 25.756\r\n",
      "[08:03:08] Progress step 96000/300000 — loss 0.0026849 — PSNR 25.752\r\n",
      "[08:03:08] Eval @ 96000: train_loss 0.0026849 — train_PSNR 25.752 — val_loss 0.0032749 — val_PSNR 24.848\r\n",
      "[08:03:10] Progress step 96100/300000 — loss 0.0026996 — PSNR 25.730\r\n",
      "[08:03:12] Progress step 96200/300000 — loss 0.0027100 — PSNR 25.712\r\n",
      "[08:03:13] Progress step 96300/300000 — loss 0.0026885 — PSNR 25.747\r\n",
      "[08:03:15] Progress step 96400/300000 — loss 0.0026935 — PSNR 25.739\r\n",
      "[08:03:16] Progress step 96500/300000 — loss 0.0026843 — PSNR 25.754\r\n",
      "[08:03:18] Progress step 96600/300000 — loss 0.0026729 — PSNR 25.772\r\n",
      "[08:03:20] Progress step 96700/300000 — loss 0.0026782 — PSNR 25.764\r\n",
      "[08:03:21] Progress step 96800/300000 — loss 0.0026771 — PSNR 25.765\r\n",
      "[08:03:23] Progress step 96900/300000 — loss 0.0026790 — PSNR 25.761\r\n",
      "[08:03:24] Progress step 97000/300000 — loss 0.0026823 — PSNR 25.757\r\n",
      "[08:03:43] Eval @ 97000: train_loss 0.0026823 — train_PSNR 25.757 — val_loss 0.0026511 — val_PSNR 26.390\r\n",
      "[08:03:45] Progress step 97100/300000 — loss 0.0026316 — PSNR 25.842\r\n",
      "[08:03:46] Progress step 97200/300000 — loss 0.0026760 — PSNR 25.770\r\n",
      "[08:03:48] Progress step 97300/300000 — loss 0.0026657 — PSNR 25.787\r\n",
      "[08:03:50] Progress step 97400/300000 — loss 0.0026689 — PSNR 25.783\r\n",
      "[08:03:51] Progress step 97500/300000 — loss 0.0026694 — PSNR 25.782\r\n",
      "[08:03:53] Progress step 97600/300000 — loss 0.0026707 — PSNR 25.779\r\n",
      "[08:03:54] Progress step 97700/300000 — loss 0.0026718 — PSNR 25.778\r\n",
      "[08:03:56] Progress step 97800/300000 — loss 0.0026717 — PSNR 25.776\r\n",
      "[08:03:58] Progress step 97900/300000 — loss 0.0026721 — PSNR 25.775\r\n",
      "[08:03:59] Progress step 98000/300000 — loss 0.0026767 — PSNR 25.767\r\n",
      "[08:03:59] Eval @ 98000: train_loss 0.0026767 — train_PSNR 25.767 — val_loss 0.0032735 — val_PSNR 24.850\r\n",
      "[08:04:01] Progress step 98100/300000 — loss 0.0026390 — PSNR 25.824\r\n",
      "[08:04:02] Progress step 98200/300000 — loss 0.0026750 — PSNR 25.762\r\n",
      "[08:04:04] Progress step 98300/300000 — loss 0.0026830 — PSNR 25.752\r\n",
      "[08:04:06] Progress step 98400/300000 — loss 0.0027037 — PSNR 25.718\r\n",
      "[08:04:07] Progress step 98500/300000 — loss 0.0027014 — PSNR 25.724\r\n",
      "[08:04:09] Progress step 98600/300000 — loss 0.0027057 — PSNR 25.718\r\n",
      "[08:04:10] Progress step 98700/300000 — loss 0.0027038 — PSNR 25.722\r\n",
      "[08:04:12] Progress step 98800/300000 — loss 0.0027065 — PSNR 25.718\r\n",
      "[08:04:14] Progress step 98900/300000 — loss 0.0027101 — PSNR 25.712\r\n",
      "[08:04:15] Progress step 99000/300000 — loss 0.0027068 — PSNR 25.718\r\n",
      "[08:04:34] Eval @ 99000: train_loss 0.0027068 — train_PSNR 25.718 — val_loss 0.0026465 — val_PSNR 26.400\r\n",
      "[08:04:34] Saved best model at step 99000\r\n",
      "[08:04:36] Progress step 99100/300000 — loss 0.0027386 — PSNR 25.670\r\n",
      "[08:04:37] Progress step 99200/300000 — loss 0.0027106 — PSNR 25.714\r\n",
      "[08:04:39] Progress step 99300/300000 — loss 0.0026893 — PSNR 25.746\r\n",
      "[08:04:40] Progress step 99400/300000 — loss 0.0026789 — PSNR 25.763\r\n",
      "[08:04:42] Progress step 99500/300000 — loss 0.0026741 — PSNR 25.769\r\n",
      "[08:04:44] Progress step 99600/300000 — loss 0.0026802 — PSNR 25.758\r\n",
      "[08:04:45] Progress step 99700/300000 — loss 0.0026778 — PSNR 25.762\r\n",
      "[08:04:47] Progress step 99800/300000 — loss 0.0026765 — PSNR 25.764\r\n",
      "[08:04:48] Progress step 99900/300000 — loss 0.0026770 — PSNR 25.764\r\n",
      "[08:04:50] Progress step 100000/300000 — loss 0.0026695 — PSNR 25.777\r\n",
      "[08:04:50] Eval @ 100000: train_loss 0.0026695 — train_PSNR 25.777 — val_loss 0.0032894 — val_PSNR 24.829\r\n",
      "[08:04:52] Progress step 100100/300000 — loss 0.0027282 — PSNR 25.672\r\n",
      "[08:04:53] Progress step 100200/300000 — loss 0.0027033 — PSNR 25.712\r\n",
      "[08:04:55] Progress step 100300/300000 — loss 0.0026974 — PSNR 25.725\r\n",
      "[08:04:57] Progress step 100400/300000 — loss 0.0026982 — PSNR 25.725\r\n",
      "[08:04:58] Progress step 100500/300000 — loss 0.0026882 — PSNR 25.741\r\n",
      "[08:05:00] Progress step 100600/300000 — loss 0.0026900 — PSNR 25.739\r\n",
      "[08:05:01] Progress step 100700/300000 — loss 0.0026921 — PSNR 25.737\r\n",
      "[08:05:03] Progress step 100800/300000 — loss 0.0026873 — PSNR 25.745\r\n",
      "[08:05:04] Progress step 100900/300000 — loss 0.0026838 — PSNR 25.751\r\n",
      "[08:05:06] Progress step 101000/300000 — loss 0.0026827 — PSNR 25.753\r\n",
      "[08:05:25] Eval @ 101000: train_loss 0.0026827 — train_PSNR 25.753 — val_loss 0.0026483 — val_PSNR 26.396\r\n",
      "[08:05:26] Progress step 101100/300000 — loss 0.0026240 — PSNR 25.848\r\n",
      "[08:05:28] Progress step 101200/300000 — loss 0.0026104 — PSNR 25.873\r\n",
      "[08:05:30] Progress step 101300/300000 — loss 0.0026488 — PSNR 25.811\r\n",
      "[08:05:31] Progress step 101400/300000 — loss 0.0026636 — PSNR 25.786\r\n",
      "[08:05:33] Progress step 101500/300000 — loss 0.0026643 — PSNR 25.785\r\n",
      "[08:05:34] Progress step 101600/300000 — loss 0.0026706 — PSNR 25.775\r\n",
      "[08:05:36] Progress step 101700/300000 — loss 0.0026768 — PSNR 25.765\r\n",
      "[08:05:38] Progress step 101800/300000 — loss 0.0026890 — PSNR 25.746\r\n",
      "[08:05:39] Progress step 101900/300000 — loss 0.0026860 — PSNR 25.751\r\n",
      "[08:05:41] Progress step 102000/300000 — loss 0.0026827 — PSNR 25.757\r\n",
      "[08:05:41] Eval @ 102000: train_loss 0.0026827 — train_PSNR 25.757 — val_loss 0.0032718 — val_PSNR 24.852\r\n",
      "[08:05:43] Progress step 102100/300000 — loss 0.0026683 — PSNR 25.774\r\n",
      "[08:05:44] Progress step 102200/300000 — loss 0.0026834 — PSNR 25.756\r\n",
      "[08:05:46] Progress step 102300/300000 — loss 0.0026802 — PSNR 25.757\r\n",
      "[08:05:47] Progress step 102400/300000 — loss 0.0026705 — PSNR 25.775\r\n",
      "[08:05:49] Progress step 102500/300000 — loss 0.0026749 — PSNR 25.768\r\n",
      "[08:05:50] Progress step 102600/300000 — loss 0.0026764 — PSNR 25.765\r\n",
      "[08:05:52] Progress step 102700/300000 — loss 0.0026754 — PSNR 25.767\r\n",
      "[08:05:54] Progress step 102800/300000 — loss 0.0026746 — PSNR 25.769\r\n",
      "[08:05:55] Progress step 102900/300000 — loss 0.0026749 — PSNR 25.767\r\n",
      "[08:05:57] Progress step 103000/300000 — loss 0.0026751 — PSNR 25.767\r\n",
      "[08:06:16] Eval @ 103000: train_loss 0.0026751 — train_PSNR 25.767 — val_loss 0.0026466 — val_PSNR 26.399\r\n",
      "[08:06:17] Progress step 103100/300000 — loss 0.0026802 — PSNR 25.753\r\n",
      "[08:06:19] Progress step 103200/300000 — loss 0.0026480 — PSNR 25.807\r\n",
      "[08:06:20] Progress step 103300/300000 — loss 0.0026460 — PSNR 25.811\r\n",
      "[08:06:22] Progress step 103400/300000 — loss 0.0026531 — PSNR 25.799\r\n",
      "[08:06:24] Progress step 103500/300000 — loss 0.0026539 — PSNR 25.798\r\n",
      "[08:06:25] Progress step 103600/300000 — loss 0.0026581 — PSNR 25.791\r\n",
      "[08:06:27] Progress step 103700/300000 — loss 0.0026662 — PSNR 25.780\r\n",
      "[08:06:28] Progress step 103800/300000 — loss 0.0026732 — PSNR 25.768\r\n",
      "[08:06:30] Progress step 103900/300000 — loss 0.0026794 — PSNR 25.758\r\n",
      "[08:06:32] Progress step 104000/300000 — loss 0.0026862 — PSNR 25.747\r\n",
      "[08:06:32] Eval @ 104000: train_loss 0.0026862 — train_PSNR 25.747 — val_loss 0.0032702 — val_PSNR 24.854\r\n",
      "[08:06:33] Progress step 104100/300000 — loss 0.0027212 — PSNR 25.684\r\n",
      "[08:06:35] Progress step 104200/300000 — loss 0.0026949 — PSNR 25.730\r\n",
      "[08:06:36] Progress step 104300/300000 — loss 0.0027014 — PSNR 25.720\r\n",
      "[08:06:38] Progress step 104400/300000 — loss 0.0027053 — PSNR 25.716\r\n",
      "[08:06:40] Progress step 104500/300000 — loss 0.0027084 — PSNR 25.710\r\n",
      "[08:06:41] Progress step 104600/300000 — loss 0.0026988 — PSNR 25.726\r\n",
      "[08:06:43] Progress step 104700/300000 — loss 0.0026961 — PSNR 25.731\r\n",
      "[08:06:44] Progress step 104800/300000 — loss 0.0026916 — PSNR 25.739\r\n",
      "[08:06:46] Progress step 104900/300000 — loss 0.0026919 — PSNR 25.739\r\n",
      "[08:06:48] Progress step 105000/300000 — loss 0.0026863 — PSNR 25.748\r\n",
      "[08:07:06] Eval @ 105000: train_loss 0.0026863 — train_PSNR 25.748 — val_loss 0.0026464 — val_PSNR 26.400\r\n",
      "[08:07:06] Saved best model at step 105000\r\n",
      "[08:07:08] Progress step 105100/300000 — loss 0.0026748 — PSNR 25.768\r\n",
      "[08:07:10] Progress step 105200/300000 — loss 0.0026832 — PSNR 25.753\r\n",
      "[08:07:11] Progress step 105300/300000 — loss 0.0026793 — PSNR 25.760\r\n",
      "[08:07:13] Progress step 105400/300000 — loss 0.0026821 — PSNR 25.756\r\n",
      "[08:07:14] Progress step 105500/300000 — loss 0.0026707 — PSNR 25.776\r\n",
      "[08:07:16] Progress step 105600/300000 — loss 0.0026718 — PSNR 25.774\r\n",
      "[08:07:18] Progress step 105700/300000 — loss 0.0026753 — PSNR 25.768\r\n",
      "[08:07:19] Progress step 105800/300000 — loss 0.0026805 — PSNR 25.759\r\n",
      "[08:07:21] Progress step 105900/300000 — loss 0.0026840 — PSNR 25.754\r\n",
      "[08:07:22] Progress step 106000/300000 — loss 0.0026913 — PSNR 25.743\r\n",
      "[08:07:22] Eval @ 106000: train_loss 0.0026913 — train_PSNR 25.743 — val_loss 0.0032749 — val_PSNR 24.848\r\n",
      "[08:07:24] Progress step 106100/300000 — loss 0.0027126 — PSNR 25.697\r\n",
      "[08:07:26] Progress step 106200/300000 — loss 0.0026842 — PSNR 25.747\r\n",
      "[08:07:27] Progress step 106300/300000 — loss 0.0027094 — PSNR 25.707\r\n",
      "[08:07:29] Progress step 106400/300000 — loss 0.0026913 — PSNR 25.738\r\n",
      "[08:07:30] Progress step 106500/300000 — loss 0.0026929 — PSNR 25.735\r\n",
      "[08:07:32] Progress step 106600/300000 — loss 0.0026877 — PSNR 25.745\r\n",
      "[08:07:34] Progress step 106700/300000 — loss 0.0026928 — PSNR 25.738\r\n",
      "[08:07:35] Progress step 106800/300000 — loss 0.0026939 — PSNR 25.736\r\n",
      "[08:07:37] Progress step 106900/300000 — loss 0.0026886 — PSNR 25.744\r\n",
      "[08:07:38] Progress step 107000/300000 — loss 0.0026884 — PSNR 25.745\r\n",
      "[08:07:57] Eval @ 107000: train_loss 0.0026884 — train_PSNR 25.745 — val_loss 0.0026496 — val_PSNR 26.393\r\n",
      "[08:07:59] Progress step 107100/300000 — loss 0.0027281 — PSNR 25.683\r\n",
      "[08:08:00] Progress step 107200/300000 — loss 0.0027167 — PSNR 25.702\r\n",
      "[08:08:02] Progress step 107300/300000 — loss 0.0027099 — PSNR 25.710\r\n",
      "[08:08:04] Progress step 107400/300000 — loss 0.0027242 — PSNR 25.687\r\n",
      "[08:08:05] Progress step 107500/300000 — loss 0.0027116 — PSNR 25.707\r\n",
      "[08:08:07] Progress step 107600/300000 — loss 0.0026945 — PSNR 25.734\r\n",
      "[08:08:08] Progress step 107700/300000 — loss 0.0027018 — PSNR 25.723\r\n",
      "[08:08:10] Progress step 107800/300000 — loss 0.0026998 — PSNR 25.726\r\n",
      "[08:08:12] Progress step 107900/300000 — loss 0.0026905 — PSNR 25.741\r\n",
      "[08:08:13] Progress step 108000/300000 — loss 0.0026900 — PSNR 25.743\r\n",
      "[08:08:13] Eval @ 108000: train_loss 0.0026900 — train_PSNR 25.743 — val_loss 0.0033013 — val_PSNR 24.813\r\n",
      "[08:08:15] Progress step 108100/300000 — loss 0.0027075 — PSNR 25.711\r\n",
      "[08:08:16] Progress step 108200/300000 — loss 0.0027005 — PSNR 25.725\r\n",
      "[08:08:18] Progress step 108300/300000 — loss 0.0027106 — PSNR 25.713\r\n",
      "[08:08:20] Progress step 108400/300000 — loss 0.0026866 — PSNR 25.750\r\n",
      "[08:08:21] Progress step 108500/300000 — loss 0.0026812 — PSNR 25.757\r\n",
      "[08:08:23] Progress step 108600/300000 — loss 0.0026761 — PSNR 25.766\r\n",
      "[08:08:24] Progress step 108700/300000 — loss 0.0026805 — PSNR 25.759\r\n",
      "[08:08:26] Progress step 108800/300000 — loss 0.0026787 — PSNR 25.760\r\n",
      "[08:08:28] Progress step 108900/300000 — loss 0.0026758 — PSNR 25.766\r\n",
      "[08:08:29] Progress step 109000/300000 — loss 0.0026779 — PSNR 25.763\r\n",
      "[08:08:48] Eval @ 109000: train_loss 0.0026779 — train_PSNR 25.763 — val_loss 0.0026468 — val_PSNR 26.399\r\n",
      "[08:08:50] Progress step 109100/300000 — loss 0.0026784 — PSNR 25.764\r\n",
      "[08:08:51] Progress step 109200/300000 — loss 0.0026801 — PSNR 25.759\r\n",
      "[08:08:53] Progress step 109300/300000 — loss 0.0026907 — PSNR 25.741\r\n",
      "[08:08:54] Progress step 109400/300000 — loss 0.0026963 — PSNR 25.732\r\n",
      "[08:08:56] Progress step 109500/300000 — loss 0.0026872 — PSNR 25.747\r\n",
      "[08:08:58] Progress step 109600/300000 — loss 0.0026863 — PSNR 25.749\r\n",
      "[08:08:59] Progress step 109700/300000 — loss 0.0026959 — PSNR 25.735\r\n",
      "[08:09:01] Progress step 109800/300000 — loss 0.0026905 — PSNR 25.744\r\n",
      "[08:09:02] Progress step 109900/300000 — loss 0.0026872 — PSNR 25.750\r\n",
      "[08:09:04] Progress step 110000/300000 — loss 0.0026883 — PSNR 25.748\r\n",
      "[08:09:04] Eval @ 110000: train_loss 0.0026883 — train_PSNR 25.748 — val_loss 0.0032995 — val_PSNR 24.815\r\n",
      "[08:09:06] Progress step 110100/300000 — loss 0.0027043 — PSNR 25.712\r\n",
      "[08:09:07] Progress step 110200/300000 — loss 0.0026931 — PSNR 25.732\r\n",
      "[08:09:09] Progress step 110300/300000 — loss 0.0026867 — PSNR 25.745\r\n",
      "[08:09:10] Progress step 110400/300000 — loss 0.0026820 — PSNR 25.752\r\n",
      "[08:09:12] Progress step 110500/300000 — loss 0.0026771 — PSNR 25.762\r\n",
      "[08:09:14] Progress step 110600/300000 — loss 0.0026741 — PSNR 25.767\r\n",
      "[08:09:15] Progress step 110700/300000 — loss 0.0026758 — PSNR 25.764\r\n",
      "[08:09:17] Progress step 110800/300000 — loss 0.0026737 — PSNR 25.769\r\n",
      "[08:09:18] Progress step 110900/300000 — loss 0.0026825 — PSNR 25.754\r\n",
      "[08:09:20] Progress step 111000/300000 — loss 0.0026797 — PSNR 25.759\r\n",
      "[08:09:39] Eval @ 111000: train_loss 0.0026797 — train_PSNR 25.759 — val_loss 0.0026463 — val_PSNR 26.400\r\n",
      "[08:09:39] Saved best model at step 111000\r\n",
      "[08:09:40] Progress step 111100/300000 — loss 0.0027014 — PSNR 25.719\r\n",
      "[08:09:42] Progress step 111200/300000 — loss 0.0026686 — PSNR 25.772\r\n",
      "[08:09:43] Progress step 111300/300000 — loss 0.0026730 — PSNR 25.769\r\n",
      "[08:09:45] Progress step 111400/300000 — loss 0.0026706 — PSNR 25.776\r\n",
      "[08:09:47] Progress step 111500/300000 — loss 0.0026781 — PSNR 25.764\r\n",
      "[08:09:48] Progress step 111600/300000 — loss 0.0026731 — PSNR 25.770\r\n",
      "[08:09:50] Progress step 111700/300000 — loss 0.0026704 — PSNR 25.775\r\n",
      "[08:09:51] Progress step 111800/300000 — loss 0.0026701 — PSNR 25.776\r\n",
      "[08:09:53] Progress step 111900/300000 — loss 0.0026669 — PSNR 25.781\r\n",
      "[08:09:55] Progress step 112000/300000 — loss 0.0026665 — PSNR 25.781\r\n",
      "[08:09:55] Eval @ 112000: train_loss 0.0026665 — train_PSNR 25.781 — val_loss 0.0032818 — val_PSNR 24.839\r\n",
      "[08:09:56] Progress step 112100/300000 — loss 0.0027642 — PSNR 25.624\r\n",
      "[08:09:58] Progress step 112200/300000 — loss 0.0027315 — PSNR 25.678\r\n",
      "[08:09:59] Progress step 112300/300000 — loss 0.0027103 — PSNR 25.711\r\n",
      "[08:10:01] Progress step 112400/300000 — loss 0.0026999 — PSNR 25.727\r\n",
      "[08:10:03] Progress step 112500/300000 — loss 0.0026992 — PSNR 25.728\r\n",
      "[08:10:04] Progress step 112600/300000 — loss 0.0026998 — PSNR 25.726\r\n",
      "[08:10:06] Progress step 112700/300000 — loss 0.0027059 — PSNR 25.716\r\n",
      "[08:10:07] Progress step 112800/300000 — loss 0.0027020 — PSNR 25.722\r\n",
      "[08:10:09] Progress step 112900/300000 — loss 0.0026974 — PSNR 25.730\r\n",
      "[08:10:11] Progress step 113000/300000 — loss 0.0026987 — PSNR 25.728\r\n",
      "[08:10:29] Eval @ 113000: train_loss 0.0026987 — train_PSNR 25.728 — val_loss 0.0026589 — val_PSNR 26.373\r\n",
      "[08:10:31] Progress step 113100/300000 — loss 0.0027100 — PSNR 25.706\r\n",
      "[08:10:33] Progress step 113200/300000 — loss 0.0026874 — PSNR 25.743\r\n",
      "[08:10:34] Progress step 113300/300000 — loss 0.0026753 — PSNR 25.762\r\n",
      "[08:10:36] Progress step 113400/300000 — loss 0.0026780 — PSNR 25.760\r\n",
      "[08:10:37] Progress step 113500/300000 — loss 0.0026719 — PSNR 25.771\r\n",
      "[08:10:39] Progress step 113600/300000 — loss 0.0026733 — PSNR 25.772\r\n",
      "[08:10:41] Progress step 113700/300000 — loss 0.0026723 — PSNR 25.772\r\n",
      "[08:10:42] Progress step 113800/300000 — loss 0.0026763 — PSNR 25.765\r\n",
      "[08:10:44] Progress step 113900/300000 — loss 0.0026763 — PSNR 25.766\r\n",
      "[08:10:45] Progress step 114000/300000 — loss 0.0026804 — PSNR 25.760\r\n",
      "[08:10:45] Eval @ 114000: train_loss 0.0026804 — train_PSNR 25.760 — val_loss 0.0033078 — val_PSNR 24.805\r\n",
      "[08:10:47] Progress step 114100/300000 — loss 0.0026607 — PSNR 25.784\r\n",
      "[08:10:48] Progress step 114200/300000 — loss 0.0026674 — PSNR 25.777\r\n",
      "[08:10:50] Progress step 114300/300000 — loss 0.0026772 — PSNR 25.760\r\n",
      "[08:10:52] Progress step 114400/300000 — loss 0.0026771 — PSNR 25.759\r\n",
      "[08:10:53] Progress step 114500/300000 — loss 0.0026839 — PSNR 25.750\r\n",
      "[08:10:55] Progress step 114600/300000 — loss 0.0026923 — PSNR 25.738\r\n",
      "[08:10:56] Progress step 114700/300000 — loss 0.0026968 — PSNR 25.730\r\n",
      "[08:10:58] Progress step 114800/300000 — loss 0.0026985 — PSNR 25.728\r\n",
      "[08:11:00] Progress step 114900/300000 — loss 0.0026914 — PSNR 25.739\r\n",
      "[08:11:01] Progress step 115000/300000 — loss 0.0026901 — PSNR 25.740\r\n",
      "[08:11:20] Eval @ 115000: train_loss 0.0026901 — train_PSNR 25.740 — val_loss 0.0026527 — val_PSNR 26.386\r\n",
      "[08:11:21] Progress step 115100/300000 — loss 0.0026469 — PSNR 25.820\r\n",
      "[08:11:23] Progress step 115200/300000 — loss 0.0026595 — PSNR 25.792\r\n",
      "[08:11:25] Progress step 115300/300000 — loss 0.0026617 — PSNR 25.789\r\n",
      "[08:11:26] Progress step 115400/300000 — loss 0.0026621 — PSNR 25.789\r\n",
      "[08:11:28] Progress step 115500/300000 — loss 0.0026599 — PSNR 25.792\r\n",
      "[08:11:29] Progress step 115600/300000 — loss 0.0026598 — PSNR 25.792\r\n",
      "[08:11:31] Progress step 115700/300000 — loss 0.0026664 — PSNR 25.782\r\n",
      "[08:11:33] Progress step 115800/300000 — loss 0.0026592 — PSNR 25.794\r\n",
      "[08:11:34] Progress step 115900/300000 — loss 0.0026570 — PSNR 25.798\r\n",
      "[08:11:36] Progress step 116000/300000 — loss 0.0026633 — PSNR 25.788\r\n",
      "[08:11:36] Eval @ 116000: train_loss 0.0026633 — train_PSNR 25.788 — val_loss 0.0032905 — val_PSNR 24.827\r\n",
      "[08:11:37] Progress step 116100/300000 — loss 0.0027315 — PSNR 25.676\r\n",
      "[08:11:39] Progress step 116200/300000 — loss 0.0027135 — PSNR 25.708\r\n",
      "[08:11:41] Progress step 116300/300000 — loss 0.0026939 — PSNR 25.734\r\n",
      "[08:11:42] Progress step 116400/300000 — loss 0.0026849 — PSNR 25.751\r\n",
      "[08:11:44] Progress step 116500/300000 — loss 0.0026789 — PSNR 25.761\r\n",
      "[08:11:45] Progress step 116600/300000 — loss 0.0026871 — PSNR 25.746\r\n",
      "[08:11:47] Progress step 116700/300000 — loss 0.0026943 — PSNR 25.734\r\n",
      "[08:11:49] Progress step 116800/300000 — loss 0.0026859 — PSNR 25.748\r\n",
      "[08:11:50] Progress step 116900/300000 — loss 0.0026877 — PSNR 25.745\r\n",
      "[08:11:52] Progress step 117000/300000 — loss 0.0026847 — PSNR 25.750\r\n",
      "[08:12:10] Eval @ 117000: train_loss 0.0026847 — train_PSNR 25.750 — val_loss 0.0026462 — val_PSNR 26.400\r\n",
      "[08:12:10] Saved best model at step 117000\r\n",
      "[08:12:12] Progress step 117100/300000 — loss 0.0026538 — PSNR 25.805\r\n",
      "[08:12:14] Progress step 117200/300000 — loss 0.0026448 — PSNR 25.814\r\n",
      "[08:12:15] Progress step 117300/300000 — loss 0.0026649 — PSNR 25.782\r\n",
      "[08:12:17] Progress step 117400/300000 — loss 0.0026592 — PSNR 25.790\r\n",
      "[08:12:18] Progress step 117500/300000 — loss 0.0026604 — PSNR 25.788\r\n",
      "[08:12:20] Progress step 117600/300000 — loss 0.0026741 — PSNR 25.766\r\n",
      "[08:12:21] Progress step 117700/300000 — loss 0.0026771 — PSNR 25.761\r\n",
      "[08:12:23] Progress step 117800/300000 — loss 0.0026782 — PSNR 25.760\r\n",
      "[08:12:25] Progress step 117900/300000 — loss 0.0026743 — PSNR 25.768\r\n",
      "[08:12:26] Progress step 118000/300000 — loss 0.0026833 — PSNR 25.755\r\n",
      "[08:12:26] Eval @ 118000: train_loss 0.0026833 — train_PSNR 25.755 — val_loss 0.0032753 — val_PSNR 24.847\r\n",
      "[08:12:28] Progress step 118100/300000 — loss 0.0026502 — PSNR 25.811\r\n",
      "[08:12:29] Progress step 118200/300000 — loss 0.0026389 — PSNR 25.827\r\n",
      "[08:12:31] Progress step 118300/300000 — loss 0.0026660 — PSNR 25.783\r\n",
      "[08:12:33] Progress step 118400/300000 — loss 0.0026634 — PSNR 25.787\r\n",
      "[08:12:34] Progress step 118500/300000 — loss 0.0026873 — PSNR 25.748\r\n",
      "[08:12:36] Progress step 118600/300000 — loss 0.0026973 — PSNR 25.734\r\n",
      "[08:12:37] Progress step 118700/300000 — loss 0.0027001 — PSNR 25.728\r\n",
      "[08:12:39] Progress step 118800/300000 — loss 0.0026979 — PSNR 25.731\r\n",
      "[08:12:41] Progress step 118900/300000 — loss 0.0026983 — PSNR 25.730\r\n",
      "[08:12:42] Progress step 119000/300000 — loss 0.0026957 — PSNR 25.735\r\n",
      "[08:13:01] Eval @ 119000: train_loss 0.0026957 — train_PSNR 25.735 — val_loss 0.0026463 — val_PSNR 26.400\r\n",
      "[08:13:03] Progress step 119100/300000 — loss 0.0026269 — PSNR 25.850\r\n",
      "[08:13:04] Progress step 119200/300000 — loss 0.0026301 — PSNR 25.843\r\n",
      "[08:13:06] Progress step 119300/300000 — loss 0.0026526 — PSNR 25.806\r\n",
      "[08:13:07] Progress step 119400/300000 — loss 0.0026541 — PSNR 25.804\r\n",
      "[08:13:09] Progress step 119500/300000 — loss 0.0026581 — PSNR 25.796\r\n",
      "[08:13:11] Progress step 119600/300000 — loss 0.0026637 — PSNR 25.787\r\n",
      "[08:13:12] Progress step 119700/300000 — loss 0.0026658 — PSNR 25.784\r\n",
      "[08:13:14] Progress step 119800/300000 — loss 0.0026746 — PSNR 25.770\r\n",
      "[08:13:15] Progress step 119900/300000 — loss 0.0026776 — PSNR 25.767\r\n",
      "[08:13:17] Progress step 120000/300000 — loss 0.0026791 — PSNR 25.765\r\n",
      "[08:13:17] Eval @ 120000: train_loss 0.0026791 — train_PSNR 25.765 — val_loss 0.0032726 — val_PSNR 24.851\r\n",
      "[08:13:19] Progress step 120100/300000 — loss 0.0026753 — PSNR 25.765\r\n",
      "[08:13:20] Progress step 120200/300000 — loss 0.0026681 — PSNR 25.771\r\n",
      "[08:13:22] Progress step 120300/300000 — loss 0.0026605 — PSNR 25.787\r\n",
      "[08:13:23] Progress step 120400/300000 — loss 0.0026682 — PSNR 25.779\r\n",
      "[08:13:25] Progress step 120500/300000 — loss 0.0026660 — PSNR 25.785\r\n",
      "[08:13:27] Progress step 120600/300000 — loss 0.0026804 — PSNR 25.760\r\n",
      "[08:13:28] Progress step 120700/300000 — loss 0.0026785 — PSNR 25.762\r\n",
      "[08:13:30] Progress step 120800/300000 — loss 0.0026808 — PSNR 25.757\r\n",
      "[08:13:31] Progress step 120900/300000 — loss 0.0026847 — PSNR 25.750\r\n",
      "[08:13:33] Progress step 121000/300000 — loss 0.0026847 — PSNR 25.751\r\n",
      "[08:13:52] Eval @ 121000: train_loss 0.0026847 — train_PSNR 25.751 — val_loss 0.0026486 — val_PSNR 26.395\r\n",
      "[08:13:53] Progress step 121100/300000 — loss 0.0027045 — PSNR 25.721\r\n",
      "[08:13:55] Progress step 121200/300000 — loss 0.0026600 — PSNR 25.798\r\n",
      "[08:13:56] Progress step 121300/300000 — loss 0.0026632 — PSNR 25.790\r\n",
      "[08:13:58] Progress step 121400/300000 — loss 0.0026826 — PSNR 25.760\r\n",
      "[08:14:00] Progress step 121500/300000 — loss 0.0026970 — PSNR 25.736\r\n",
      "[08:14:01] Progress step 121600/300000 — loss 0.0027025 — PSNR 25.727\r\n",
      "[08:14:03] Progress step 121700/300000 — loss 0.0026942 — PSNR 25.740\r\n",
      "[08:14:04] Progress step 121800/300000 — loss 0.0026882 — PSNR 25.750\r\n",
      "[08:14:06] Progress step 121900/300000 — loss 0.0026878 — PSNR 25.750\r\n",
      "[08:14:08] Progress step 122000/300000 — loss 0.0026844 — PSNR 25.756\r\n",
      "[08:14:08] Eval @ 122000: train_loss 0.0026844 — train_PSNR 25.756 — val_loss 0.0033054 — val_PSNR 24.808\r\n",
      "[08:14:09] Progress step 122100/300000 — loss 0.0027227 — PSNR 25.696\r\n",
      "[08:14:11] Progress step 122200/300000 — loss 0.0026845 — PSNR 25.752\r\n",
      "[08:14:12] Progress step 122300/300000 — loss 0.0027079 — PSNR 25.716\r\n",
      "[08:14:14] Progress step 122400/300000 — loss 0.0027060 — PSNR 25.718\r\n",
      "[08:14:15] Progress step 122500/300000 — loss 0.0027050 — PSNR 25.719\r\n",
      "[08:14:17] Progress step 122600/300000 — loss 0.0027003 — PSNR 25.728\r\n",
      "[08:14:19] Progress step 122700/300000 — loss 0.0027032 — PSNR 25.723\r\n",
      "[08:14:20] Progress step 122800/300000 — loss 0.0027014 — PSNR 25.725\r\n",
      "[08:14:22] Progress step 122900/300000 — loss 0.0026994 — PSNR 25.728\r\n",
      "[08:14:24] Progress step 123000/300000 — loss 0.0026975 — PSNR 25.730\r\n",
      "[08:14:42] Eval @ 123000: train_loss 0.0026975 — train_PSNR 25.730 — val_loss 0.0026465 — val_PSNR 26.399\r\n",
      "[08:14:44] Progress step 123100/300000 — loss 0.0026537 — PSNR 25.807\r\n",
      "[08:14:45] Progress step 123200/300000 — loss 0.0026912 — PSNR 25.739\r\n",
      "[08:14:47] Progress step 123300/300000 — loss 0.0026885 — PSNR 25.745\r\n",
      "[08:14:49] Progress step 123400/300000 — loss 0.0026918 — PSNR 25.744\r\n",
      "[08:14:50] Progress step 123500/300000 — loss 0.0026746 — PSNR 25.770\r\n",
      "[08:14:52] Progress step 123600/300000 — loss 0.0026718 — PSNR 25.775\r\n",
      "[08:14:54] Progress step 123700/300000 — loss 0.0026705 — PSNR 25.778\r\n",
      "[08:14:55] Progress step 123800/300000 — loss 0.0026650 — PSNR 25.786\r\n",
      "[08:14:57] Progress step 123900/300000 — loss 0.0026585 — PSNR 25.796\r\n",
      "[08:14:58] Progress step 124000/300000 — loss 0.0026618 — PSNR 25.790\r\n",
      "[08:14:58] Eval @ 124000: train_loss 0.0026618 — train_PSNR 25.790 — val_loss 0.0032940 — val_PSNR 24.823\r\n",
      "[08:15:00] Progress step 124100/300000 — loss 0.0026679 — PSNR 25.779\r\n",
      "[08:15:02] Progress step 124200/300000 — loss 0.0026849 — PSNR 25.750\r\n",
      "[08:15:03] Progress step 124300/300000 — loss 0.0026763 — PSNR 25.764\r\n",
      "[08:15:05] Progress step 124400/300000 — loss 0.0026735 — PSNR 25.769\r\n",
      "[08:15:06] Progress step 124500/300000 — loss 0.0026790 — PSNR 25.760\r\n",
      "[08:15:08] Progress step 124600/300000 — loss 0.0026816 — PSNR 25.757\r\n",
      "[08:15:10] Progress step 124700/300000 — loss 0.0026762 — PSNR 25.765\r\n",
      "[08:15:11] Progress step 124800/300000 — loss 0.0026843 — PSNR 25.752\r\n",
      "[08:15:13] Progress step 124900/300000 — loss 0.0026817 — PSNR 25.755\r\n",
      "[08:15:14] Progress step 125000/300000 — loss 0.0026863 — PSNR 25.748\r\n",
      "[08:15:33] Eval @ 125000: train_loss 0.0026863 — train_PSNR 25.748 — val_loss 0.0026510 — val_PSNR 26.390\r\n",
      "[08:15:35] Progress step 125100/300000 — loss 0.0026976 — PSNR 25.738\r\n",
      "[08:15:36] Progress step 125200/300000 — loss 0.0026683 — PSNR 25.785\r\n",
      "[08:15:38] Progress step 125300/300000 — loss 0.0026838 — PSNR 25.760\r\n",
      "[08:15:39] Progress step 125400/300000 — loss 0.0026909 — PSNR 25.748\r\n",
      "[08:15:41] Progress step 125500/300000 — loss 0.0026881 — PSNR 25.750\r\n",
      "[08:15:43] Progress step 125600/300000 — loss 0.0026950 — PSNR 25.739\r\n",
      "[08:15:44] Progress step 125700/300000 — loss 0.0026960 — PSNR 25.736\r\n",
      "[08:15:46] Progress step 125800/300000 — loss 0.0026934 — PSNR 25.740\r\n",
      "[08:15:47] Progress step 125900/300000 — loss 0.0026947 — PSNR 25.737\r\n",
      "[08:15:49] Progress step 126000/300000 — loss 0.0026960 — PSNR 25.736\r\n",
      "[08:15:49] Eval @ 126000: train_loss 0.0026960 — train_PSNR 25.736 — val_loss 0.0032789 — val_PSNR 24.843\r\n",
      "[08:15:51] Progress step 126100/300000 — loss 0.0026935 — PSNR 25.740\r\n",
      "[08:15:52] Progress step 126200/300000 — loss 0.0026906 — PSNR 25.738\r\n",
      "[08:15:54] Progress step 126300/300000 — loss 0.0026794 — PSNR 25.757\r\n",
      "[08:15:55] Progress step 126400/300000 — loss 0.0026806 — PSNR 25.755\r\n",
      "[08:15:57] Progress step 126500/300000 — loss 0.0026863 — PSNR 25.748\r\n",
      "[08:15:59] Progress step 126600/300000 — loss 0.0026917 — PSNR 25.740\r\n",
      "[08:16:00] Progress step 126700/300000 — loss 0.0026880 — PSNR 25.747\r\n",
      "[08:16:02] Progress step 126800/300000 — loss 0.0026915 — PSNR 25.742\r\n",
      "[08:16:03] Progress step 126900/300000 — loss 0.0026920 — PSNR 25.741\r\n",
      "[08:16:05] Progress step 127000/300000 — loss 0.0026857 — PSNR 25.752\r\n",
      "[08:16:24] Eval @ 127000: train_loss 0.0026857 — train_PSNR 25.752 — val_loss 0.0026474 — val_PSNR 26.398\r\n",
      "[08:16:25] Progress step 127100/300000 — loss 0.0027277 — PSNR 25.687\r\n",
      "[08:16:27] Progress step 127200/300000 — loss 0.0027193 — PSNR 25.694\r\n",
      "[08:16:29] Progress step 127300/300000 — loss 0.0027118 — PSNR 25.706\r\n",
      "[08:16:30] Progress step 127400/300000 — loss 0.0026970 — PSNR 25.729\r\n",
      "[08:16:32] Progress step 127500/300000 — loss 0.0026767 — PSNR 25.763\r\n",
      "[08:16:33] Progress step 127600/300000 — loss 0.0026882 — PSNR 25.744\r\n",
      "[08:16:35] Progress step 127700/300000 — loss 0.0026901 — PSNR 25.743\r\n",
      "[08:16:37] Progress step 127800/300000 — loss 0.0026978 — PSNR 25.729\r\n",
      "[08:16:38] Progress step 127900/300000 — loss 0.0026913 — PSNR 25.740\r\n",
      "[08:16:40] Progress step 128000/300000 — loss 0.0026909 — PSNR 25.741\r\n",
      "[08:16:40] Eval @ 128000: train_loss 0.0026909 — train_PSNR 25.741 — val_loss 0.0032934 — val_PSNR 24.824\r\n",
      "[08:16:41] Progress step 128100/300000 — loss 0.0026614 — PSNR 25.801\r\n",
      "[08:16:43] Progress step 128200/300000 — loss 0.0026510 — PSNR 25.810\r\n",
      "[08:16:44] Progress step 128300/300000 — loss 0.0026781 — PSNR 25.768\r\n",
      "[08:16:46] Progress step 128400/300000 — loss 0.0026725 — PSNR 25.778\r\n",
      "[08:16:48] Progress step 128500/300000 — loss 0.0026734 — PSNR 25.773\r\n",
      "[08:16:49] Progress step 128600/300000 — loss 0.0026813 — PSNR 25.762\r\n",
      "[08:16:51] Progress step 128700/300000 — loss 0.0026915 — PSNR 25.748\r\n",
      "[08:16:52] Progress step 128800/300000 — loss 0.0026853 — PSNR 25.758\r\n",
      "[08:16:54] Progress step 128900/300000 — loss 0.0026791 — PSNR 25.767\r\n",
      "[08:16:56] Progress step 129000/300000 — loss 0.0026817 — PSNR 25.761\r\n",
      "[08:17:14] Eval @ 129000: train_loss 0.0026817 — train_PSNR 25.761 — val_loss 0.0026464 — val_PSNR 26.400\r\n",
      "[08:17:16] Progress step 129100/300000 — loss 0.0025826 — PSNR 25.924\r\n",
      "[08:17:18] Progress step 129200/300000 — loss 0.0026260 — PSNR 25.853\r\n",
      "[08:17:19] Progress step 129300/300000 — loss 0.0026385 — PSNR 25.829\r\n",
      "[08:17:21] Progress step 129400/300000 — loss 0.0026542 — PSNR 25.805\r\n",
      "[08:17:22] Progress step 129500/300000 — loss 0.0026638 — PSNR 25.788\r\n",
      "[08:17:24] Progress step 129600/300000 — loss 0.0026629 — PSNR 25.789\r\n",
      "[08:17:25] Progress step 129700/300000 — loss 0.0026771 — PSNR 25.766\r\n",
      "[08:17:27] Progress step 129800/300000 — loss 0.0026779 — PSNR 25.765\r\n",
      "[08:17:29] Progress step 129900/300000 — loss 0.0026751 — PSNR 25.768\r\n",
      "[08:17:30] Progress step 130000/300000 — loss 0.0026788 — PSNR 25.762\r\n",
      "[08:17:30] Eval @ 130000: train_loss 0.0026788 — train_PSNR 25.762 — val_loss 0.0032825 — val_PSNR 24.838\r\n",
      "[08:17:32] Progress step 130100/300000 — loss 0.0027208 — PSNR 25.704\r\n",
      "[08:17:33] Progress step 130200/300000 — loss 0.0027200 — PSNR 25.698\r\n",
      "[08:17:35] Progress step 130300/300000 — loss 0.0027184 — PSNR 25.698\r\n",
      "[08:17:37] Progress step 130400/300000 — loss 0.0027306 — PSNR 25.681\r\n",
      "[08:17:38] Progress step 130500/300000 — loss 0.0027217 — PSNR 25.694\r\n",
      "[08:17:40] Progress step 130600/300000 — loss 0.0027132 — PSNR 25.708\r\n",
      "[08:17:41] Progress step 130700/300000 — loss 0.0026975 — PSNR 25.733\r\n",
      "[08:17:43] Progress step 130800/300000 — loss 0.0027010 — PSNR 25.727\r\n",
      "[08:17:45] Progress step 130900/300000 — loss 0.0026965 — PSNR 25.735\r\n",
      "[08:17:46] Progress step 131000/300000 — loss 0.0026947 — PSNR 25.738\r\n",
      "[08:18:05] Eval @ 131000: train_loss 0.0026947 — train_PSNR 25.738 — val_loss 0.0026461 — val_PSNR 26.400\r\n",
      "[08:18:05] Saved best model at step 131000\r\n",
      "[08:18:06] Progress step 131100/300000 — loss 0.0027059 — PSNR 25.716\r\n",
      "[08:18:08] Progress step 131200/300000 — loss 0.0026844 — PSNR 25.756\r\n",
      "[08:18:10] Progress step 131300/300000 — loss 0.0026796 — PSNR 25.762\r\n",
      "[08:18:11] Progress step 131400/300000 — loss 0.0026776 — PSNR 25.764\r\n",
      "[08:18:13] Progress step 131500/300000 — loss 0.0026813 — PSNR 25.759\r\n",
      "[08:18:14] Progress step 131600/300000 — loss 0.0026775 — PSNR 25.764\r\n",
      "[08:18:16] Progress step 131700/300000 — loss 0.0026794 — PSNR 25.760\r\n",
      "[08:18:18] Progress step 131800/300000 — loss 0.0026771 — PSNR 25.766\r\n",
      "[08:18:19] Progress step 131900/300000 — loss 0.0026756 — PSNR 25.768\r\n",
      "[08:18:21] Progress step 132000/300000 — loss 0.0026753 — PSNR 25.770\r\n",
      "[08:18:21] Eval @ 132000: train_loss 0.0026753 — train_PSNR 25.770 — val_loss 0.0032856 — val_PSNR 24.834\r\n",
      "[08:18:22] Progress step 132100/300000 — loss 0.0026809 — PSNR 25.758\r\n",
      "[08:18:24] Progress step 132200/300000 — loss 0.0026961 — PSNR 25.730\r\n",
      "[08:18:26] Progress step 132300/300000 — loss 0.0026959 — PSNR 25.733\r\n",
      "[08:18:27] Progress step 132400/300000 — loss 0.0026854 — PSNR 25.748\r\n",
      "[08:18:29] Progress step 132500/300000 — loss 0.0026923 — PSNR 25.736\r\n",
      "[08:18:30] Progress step 132600/300000 — loss 0.0026918 — PSNR 25.740\r\n",
      "[08:18:32] Progress step 132700/300000 — loss 0.0026969 — PSNR 25.732\r\n",
      "[08:18:34] Progress step 132800/300000 — loss 0.0026995 — PSNR 25.728\r\n",
      "[08:18:35] Progress step 132900/300000 — loss 0.0026945 — PSNR 25.736\r\n",
      "[08:18:37] Progress step 133000/300000 — loss 0.0026917 — PSNR 25.741\r\n",
      "[08:18:56] Eval @ 133000: train_loss 0.0026917 — train_PSNR 25.741 — val_loss 0.0026496 — val_PSNR 26.393\r\n",
      "[08:18:57] Progress step 133100/300000 — loss 0.0026751 — PSNR 25.775\r\n",
      "[08:18:59] Progress step 133200/300000 — loss 0.0027017 — PSNR 25.733\r\n",
      "[08:19:00] Progress step 133300/300000 — loss 0.0026863 — PSNR 25.755\r\n",
      "[08:19:02] Progress step 133400/300000 — loss 0.0027086 — PSNR 25.717\r\n",
      "[08:19:04] Progress step 133500/300000 — loss 0.0027014 — PSNR 25.727\r\n",
      "[08:19:05] Progress step 133600/300000 — loss 0.0026941 — PSNR 25.738\r\n",
      "[08:19:07] Progress step 133700/300000 — loss 0.0026855 — PSNR 25.751\r\n",
      "[08:19:09] Progress step 133800/300000 — loss 0.0026828 — PSNR 25.755\r\n",
      "[08:19:10] Progress step 133900/300000 — loss 0.0026809 — PSNR 25.759\r\n",
      "[08:19:12] Progress step 134000/300000 — loss 0.0026848 — PSNR 25.753\r\n",
      "[08:19:12] Eval @ 134000: train_loss 0.0026848 — train_PSNR 25.753 — val_loss 0.0032789 — val_PSNR 24.843\r\n",
      "[08:19:13] Progress step 134100/300000 — loss 0.0027373 — PSNR 25.674\r\n",
      "[08:19:15] Progress step 134200/300000 — loss 0.0027148 — PSNR 25.707\r\n",
      "[08:19:17] Progress step 134300/300000 — loss 0.0026961 — PSNR 25.739\r\n",
      "[08:19:18] Progress step 134400/300000 — loss 0.0027128 — PSNR 25.713\r\n",
      "[08:19:20] Progress step 134500/300000 — loss 0.0027173 — PSNR 25.706\r\n",
      "[08:19:21] Progress step 134600/300000 — loss 0.0027149 — PSNR 25.708\r\n",
      "[08:19:23] Progress step 134700/300000 — loss 0.0027114 — PSNR 25.713\r\n",
      "[08:19:24] Progress step 134800/300000 — loss 0.0027117 — PSNR 25.713\r\n",
      "[08:19:26] Progress step 134900/300000 — loss 0.0027094 — PSNR 25.717\r\n",
      "[08:19:28] Progress step 135000/300000 — loss 0.0027094 — PSNR 25.716\r\n",
      "[08:19:46] Eval @ 135000: train_loss 0.0027094 — train_PSNR 25.716 — val_loss 0.0026484 — val_PSNR 26.395\r\n",
      "[08:19:48] Progress step 135100/300000 — loss 0.0027077 — PSNR 25.729\r\n",
      "[08:19:50] Progress step 135200/300000 — loss 0.0026868 — PSNR 25.762\r\n",
      "[08:19:51] Progress step 135300/300000 — loss 0.0026900 — PSNR 25.752\r\n",
      "[08:19:53] Progress step 135400/300000 — loss 0.0026881 — PSNR 25.754\r\n",
      "[08:19:54] Progress step 135500/300000 — loss 0.0026860 — PSNR 25.755\r\n",
      "[08:19:56] Progress step 135600/300000 — loss 0.0026895 — PSNR 25.749\r\n",
      "[08:19:58] Progress step 135700/300000 — loss 0.0026932 — PSNR 25.744\r\n",
      "[08:19:59] Progress step 135800/300000 — loss 0.0026954 — PSNR 25.740\r\n",
      "[08:20:01] Progress step 135900/300000 — loss 0.0027047 — PSNR 25.725\r\n",
      "[08:20:03] Progress step 136000/300000 — loss 0.0027025 — PSNR 25.728\r\n",
      "[08:20:03] Eval @ 136000: train_loss 0.0027025 — train_PSNR 25.728 — val_loss 0.0032769 — val_PSNR 24.845\r\n",
      "[08:20:04] Progress step 136100/300000 — loss 0.0026944 — PSNR 25.721\r\n",
      "[08:20:06] Progress step 136200/300000 — loss 0.0026570 — PSNR 25.798\r\n",
      "[08:20:07] Progress step 136300/300000 — loss 0.0026538 — PSNR 25.802\r\n",
      "[08:20:09] Progress step 136400/300000 — loss 0.0026659 — PSNR 25.782\r\n",
      "[08:20:11] Progress step 136500/300000 — loss 0.0026690 — PSNR 25.778\r\n",
      "[08:20:12] Progress step 136600/300000 — loss 0.0026758 — PSNR 25.766\r\n",
      "[08:20:14] Progress step 136700/300000 — loss 0.0026810 — PSNR 25.759\r\n",
      "[08:20:15] Progress step 136800/300000 — loss 0.0026769 — PSNR 25.764\r\n",
      "[08:20:17] Progress step 136900/300000 — loss 0.0026730 — PSNR 25.771\r\n",
      "[08:20:19] Progress step 137000/300000 — loss 0.0026740 — PSNR 25.769\r\n",
      "[08:20:37] Eval @ 137000: train_loss 0.0026740 — train_PSNR 25.769 — val_loss 0.0026470 — val_PSNR 26.398\r\n",
      "[08:20:39] Progress step 137100/300000 — loss 0.0027116 — PSNR 25.698\r\n",
      "[08:20:41] Progress step 137200/300000 — loss 0.0026965 — PSNR 25.728\r\n",
      "[08:20:42] Progress step 137300/300000 — loss 0.0026911 — PSNR 25.738\r\n",
      "[08:20:44] Progress step 137400/300000 — loss 0.0026955 — PSNR 25.732\r\n",
      "[08:20:45] Progress step 137500/300000 — loss 0.0026883 — PSNR 25.745\r\n",
      "[08:20:47] Progress step 137600/300000 — loss 0.0026914 — PSNR 25.742\r\n",
      "[08:20:49] Progress step 137700/300000 — loss 0.0026827 — PSNR 25.756\r\n",
      "[08:20:50] Progress step 137800/300000 — loss 0.0026857 — PSNR 25.750\r\n",
      "[08:20:52] Progress step 137900/300000 — loss 0.0026915 — PSNR 25.740\r\n",
      "[08:20:53] Progress step 138000/300000 — loss 0.0026916 — PSNR 25.740\r\n",
      "[08:20:53] Eval @ 138000: train_loss 0.0026916 — train_PSNR 25.740 — val_loss 0.0032906 — val_PSNR 24.827\r\n",
      "[08:20:55] Progress step 138100/300000 — loss 0.0027260 — PSNR 25.680\r\n",
      "[08:20:57] Progress step 138200/300000 — loss 0.0027091 — PSNR 25.712\r\n",
      "[08:20:58] Progress step 138300/300000 — loss 0.0027029 — PSNR 25.721\r\n",
      "[08:21:00] Progress step 138400/300000 — loss 0.0027082 — PSNR 25.713\r\n",
      "[08:21:01] Progress step 138500/300000 — loss 0.0027086 — PSNR 25.713\r\n",
      "[08:21:03] Progress step 138600/300000 — loss 0.0026989 — PSNR 25.729\r\n",
      "[08:21:05] Progress step 138700/300000 — loss 0.0026908 — PSNR 25.742\r\n",
      "[08:21:06] Progress step 138800/300000 — loss 0.0026935 — PSNR 25.737\r\n",
      "[08:21:08] Progress step 138900/300000 — loss 0.0026905 — PSNR 25.742\r\n",
      "[08:21:09] Progress step 139000/300000 — loss 0.0026837 — PSNR 25.753\r\n",
      "[08:21:28] Eval @ 139000: train_loss 0.0026837 — train_PSNR 25.753 — val_loss 0.0026495 — val_PSNR 26.393\r\n",
      "[08:21:30] Progress step 139100/300000 — loss 0.0026692 — PSNR 25.773\r\n",
      "[08:21:31] Progress step 139200/300000 — loss 0.0026640 — PSNR 25.786\r\n",
      "[08:21:33] Progress step 139300/300000 — loss 0.0026722 — PSNR 25.772\r\n",
      "[08:21:35] Progress step 139400/300000 — loss 0.0026820 — PSNR 25.755\r\n",
      "[08:21:36] Progress step 139500/300000 — loss 0.0026857 — PSNR 25.747\r\n",
      "[08:21:38] Progress step 139600/300000 — loss 0.0026908 — PSNR 25.739\r\n",
      "[08:21:39] Progress step 139700/300000 — loss 0.0026839 — PSNR 25.753\r\n",
      "[08:21:41] Progress step 139800/300000 — loss 0.0026786 — PSNR 25.761\r\n",
      "[08:21:43] Progress step 139900/300000 — loss 0.0026763 — PSNR 25.765\r\n",
      "[08:21:44] Progress step 140000/300000 — loss 0.0026779 — PSNR 25.762\r\n",
      "[08:21:44] Eval @ 140000: train_loss 0.0026779 — train_PSNR 25.762 — val_loss 0.0032784 — val_PSNR 24.843\r\n",
      "[08:21:46] Progress step 140100/300000 — loss 0.0026914 — PSNR 25.739\r\n",
      "[08:21:48] Progress step 140200/300000 — loss 0.0026774 — PSNR 25.762\r\n",
      "[08:21:49] Progress step 140300/300000 — loss 0.0026584 — PSNR 25.792\r\n",
      "[08:21:51] Progress step 140400/300000 — loss 0.0026668 — PSNR 25.777\r\n",
      "[08:21:52] Progress step 140500/300000 — loss 0.0026592 — PSNR 25.792\r\n",
      "[08:21:54] Progress step 140600/300000 — loss 0.0026651 — PSNR 25.783\r\n",
      "[08:21:55] Progress step 140700/300000 — loss 0.0026677 — PSNR 25.778\r\n",
      "[08:21:57] Progress step 140800/300000 — loss 0.0026631 — PSNR 25.785\r\n",
      "[08:21:59] Progress step 140900/300000 — loss 0.0026630 — PSNR 25.786\r\n",
      "[08:22:00] Progress step 141000/300000 — loss 0.0026629 — PSNR 25.787\r\n",
      "[08:22:19] Eval @ 141000: train_loss 0.0026629 — train_PSNR 25.787 — val_loss 0.0026477 — val_PSNR 26.397\r\n",
      "[08:22:21] Progress step 141100/300000 — loss 0.0026941 — PSNR 25.724\r\n",
      "[08:22:22] Progress step 141200/300000 — loss 0.0027034 — PSNR 25.715\r\n",
      "[08:22:24] Progress step 141300/300000 — loss 0.0026853 — PSNR 25.747\r\n",
      "[08:22:25] Progress step 141400/300000 — loss 0.0026801 — PSNR 25.758\r\n",
      "[08:22:27] Progress step 141500/300000 — loss 0.0026769 — PSNR 25.763\r\n",
      "[08:22:29] Progress step 141600/300000 — loss 0.0026811 — PSNR 25.759\r\n",
      "[08:22:30] Progress step 141700/300000 — loss 0.0026823 — PSNR 25.756\r\n",
      "[08:22:32] Progress step 141800/300000 — loss 0.0026849 — PSNR 25.752\r\n",
      "[08:22:33] Progress step 141900/300000 — loss 0.0026849 — PSNR 25.753\r\n",
      "[08:22:35] Progress step 142000/300000 — loss 0.0026821 — PSNR 25.757\r\n",
      "[08:22:35] Eval @ 142000: train_loss 0.0026821 — train_PSNR 25.757 — val_loss 0.0032846 — val_PSNR 24.835\r\n",
      "[08:22:37] Progress step 142100/300000 — loss 0.0026401 — PSNR 25.831\r\n",
      "[08:22:38] Progress step 142200/300000 — loss 0.0026660 — PSNR 25.783\r\n",
      "[08:22:40] Progress step 142300/300000 — loss 0.0026885 — PSNR 25.749\r\n",
      "[08:22:41] Progress step 142400/300000 — loss 0.0026957 — PSNR 25.735\r\n",
      "[08:22:43] Progress step 142500/300000 — loss 0.0026976 — PSNR 25.732\r\n",
      "[08:22:45] Progress step 142600/300000 — loss 0.0027005 — PSNR 25.728\r\n",
      "[08:22:46] Progress step 142700/300000 — loss 0.0026914 — PSNR 25.743\r\n",
      "[08:22:48] Progress step 142800/300000 — loss 0.0026951 — PSNR 25.737\r\n",
      "[08:22:50] Progress step 142900/300000 — loss 0.0026950 — PSNR 25.736\r\n",
      "[08:22:51] Progress step 143000/300000 — loss 0.0026945 — PSNR 25.737\r\n",
      "[08:23:10] Eval @ 143000: train_loss 0.0026945 — train_PSNR 25.737 — val_loss 0.0026464 — val_PSNR 26.400\r\n",
      "[08:23:12] Progress step 143100/300000 — loss 0.0026729 — PSNR 25.769\r\n",
      "[08:23:13] Progress step 143200/300000 — loss 0.0026659 — PSNR 25.783\r\n",
      "[08:23:15] Progress step 143300/300000 — loss 0.0026733 — PSNR 25.770\r\n",
      "[08:23:16] Progress step 143400/300000 — loss 0.0026779 — PSNR 25.762\r\n",
      "[08:23:18] Progress step 143500/300000 — loss 0.0026866 — PSNR 25.748\r\n",
      "[08:23:20] Progress step 143600/300000 — loss 0.0026837 — PSNR 25.753\r\n",
      "[08:23:21] Progress step 143700/300000 — loss 0.0026858 — PSNR 25.750\r\n",
      "[08:23:23] Progress step 143800/300000 — loss 0.0026792 — PSNR 25.760\r\n",
      "[08:23:25] Progress step 143900/300000 — loss 0.0026776 — PSNR 25.763\r\n",
      "[08:23:26] Progress step 144000/300000 — loss 0.0026797 — PSNR 25.759\r\n",
      "[08:23:26] Eval @ 144000: train_loss 0.0026797 — train_PSNR 25.759 — val_loss 0.0032959 — val_PSNR 24.820\r\n",
      "[08:23:28] Progress step 144100/300000 — loss 0.0026816 — PSNR 25.759\r\n",
      "[08:23:29] Progress step 144200/300000 — loss 0.0026831 — PSNR 25.758\r\n",
      "[08:23:31] Progress step 144300/300000 — loss 0.0026985 — PSNR 25.731\r\n",
      "[08:23:32] Progress step 144400/300000 — loss 0.0026973 — PSNR 25.733\r\n",
      "[08:23:34] Progress step 144500/300000 — loss 0.0026877 — PSNR 25.747\r\n",
      "[08:23:36] Progress step 144600/300000 — loss 0.0026946 — PSNR 25.736\r\n",
      "[08:23:37] Progress step 144700/300000 — loss 0.0026970 — PSNR 25.733\r\n",
      "[08:23:39] Progress step 144800/300000 — loss 0.0026978 — PSNR 25.732\r\n",
      "[08:23:40] Progress step 144900/300000 — loss 0.0026968 — PSNR 25.734\r\n",
      "[08:23:42] Progress step 145000/300000 — loss 0.0026958 — PSNR 25.736\r\n",
      "[08:24:01] Eval @ 145000: train_loss 0.0026958 — train_PSNR 25.736 — val_loss 0.0026461 — val_PSNR 26.400\r\n",
      "[08:24:01] Saved best model at step 145000\r\n",
      "[08:24:03] Progress step 145100/300000 — loss 0.0026553 — PSNR 25.805\r\n",
      "[08:24:04] Progress step 145200/300000 — loss 0.0026932 — PSNR 25.739\r\n",
      "[08:24:06] Progress step 145300/300000 — loss 0.0026879 — PSNR 25.746\r\n",
      "[08:24:07] Progress step 145400/300000 — loss 0.0026943 — PSNR 25.736\r\n",
      "[08:24:09] Progress step 145500/300000 — loss 0.0027038 — PSNR 25.720\r\n",
      "[08:24:11] Progress step 145600/300000 — loss 0.0027023 — PSNR 25.725\r\n",
      "[08:24:12] Progress step 145700/300000 — loss 0.0027030 — PSNR 25.724\r\n",
      "[08:24:14] Progress step 145800/300000 — loss 0.0026993 — PSNR 25.731\r\n",
      "[08:24:15] Progress step 145900/300000 — loss 0.0026958 — PSNR 25.736\r\n",
      "[08:24:17] Progress step 146000/300000 — loss 0.0026960 — PSNR 25.737\r\n",
      "[08:24:17] Eval @ 146000: train_loss 0.0026960 — train_PSNR 25.737 — val_loss 0.0032759 — val_PSNR 24.847\r\n",
      "[08:24:19] Progress step 146100/300000 — loss 0.0026969 — PSNR 25.735\r\n",
      "[08:24:20] Progress step 146200/300000 — loss 0.0026708 — PSNR 25.778\r\n",
      "[08:24:22] Progress step 146300/300000 — loss 0.0026899 — PSNR 25.749\r\n",
      "[08:24:23] Progress step 146400/300000 — loss 0.0026829 — PSNR 25.759\r\n",
      "[08:24:25] Progress step 146500/300000 — loss 0.0026722 — PSNR 25.775\r\n",
      "[08:24:27] Progress step 146600/300000 — loss 0.0026830 — PSNR 25.758\r\n",
      "[08:24:28] Progress step 146700/300000 — loss 0.0026846 — PSNR 25.755\r\n",
      "[08:24:30] Progress step 146800/300000 — loss 0.0026838 — PSNR 25.755\r\n",
      "[08:24:32] Progress step 146900/300000 — loss 0.0026858 — PSNR 25.751\r\n",
      "[08:24:33] Progress step 147000/300000 — loss 0.0026871 — PSNR 25.748\r\n",
      "[08:24:52] Eval @ 147000: train_loss 0.0026871 — train_PSNR 25.748 — val_loss 0.0026641 — val_PSNR 26.362\r\n",
      "[08:24:53] Progress step 147100/300000 — loss 0.0027074 — PSNR 25.719\r\n",
      "[08:24:55] Progress step 147200/300000 — loss 0.0026798 — PSNR 25.758\r\n",
      "[08:24:57] Progress step 147300/300000 — loss 0.0026856 — PSNR 25.753\r\n",
      "[08:24:58] Progress step 147400/300000 — loss 0.0026858 — PSNR 25.754\r\n",
      "[08:25:00] Progress step 147500/300000 — loss 0.0026949 — PSNR 25.740\r\n",
      "[08:25:01] Progress step 147600/300000 — loss 0.0026914 — PSNR 25.744\r\n",
      "[08:25:03] Progress step 147700/300000 — loss 0.0026865 — PSNR 25.751\r\n",
      "[08:25:05] Progress step 147800/300000 — loss 0.0026924 — PSNR 25.743\r\n",
      "[08:25:06] Progress step 147900/300000 — loss 0.0026873 — PSNR 25.751\r\n",
      "[08:25:08] Progress step 148000/300000 — loss 0.0026916 — PSNR 25.745\r\n",
      "[08:25:08] Eval @ 148000: train_loss 0.0026916 — train_PSNR 25.745 — val_loss 0.0032774 — val_PSNR 24.845\r\n",
      "[08:25:10] Progress step 148100/300000 — loss 0.0026570 — PSNR 25.805\r\n",
      "[08:25:11] Progress step 148200/300000 — loss 0.0026633 — PSNR 25.792\r\n",
      "[08:25:13] Progress step 148300/300000 — loss 0.0026676 — PSNR 25.787\r\n",
      "[08:25:14] Progress step 148400/300000 — loss 0.0026805 — PSNR 25.761\r\n",
      "[08:25:16] Progress step 148500/300000 — loss 0.0026808 — PSNR 25.761\r\n",
      "[08:25:17] Progress step 148600/300000 — loss 0.0026876 — PSNR 25.751\r\n",
      "[08:25:19] Progress step 148700/300000 — loss 0.0026769 — PSNR 25.768\r\n",
      "[08:25:21] Progress step 148800/300000 — loss 0.0026747 — PSNR 25.772\r\n",
      "[08:25:22] Progress step 148900/300000 — loss 0.0026760 — PSNR 25.769\r\n",
      "[08:25:24] Progress step 149000/300000 — loss 0.0026803 — PSNR 25.761\r\n",
      "[08:25:43] Eval @ 149000: train_loss 0.0026803 — train_PSNR 25.761 — val_loss 0.0026470 — val_PSNR 26.399\r\n",
      "[08:25:44] Progress step 149100/300000 — loss 0.0027033 — PSNR 25.720\r\n",
      "[08:25:46] Progress step 149200/300000 — loss 0.0027107 — PSNR 25.708\r\n",
      "[08:25:47] Progress step 149300/300000 — loss 0.0027124 — PSNR 25.703\r\n",
      "[08:25:49] Progress step 149400/300000 — loss 0.0027221 — PSNR 25.690\r\n",
      "[08:25:51] Progress step 149500/300000 — loss 0.0027031 — PSNR 25.721\r\n",
      "[08:25:52] Progress step 149600/300000 — loss 0.0026993 — PSNR 25.726\r\n",
      "[08:25:54] Progress step 149700/300000 — loss 0.0026872 — PSNR 25.746\r\n",
      "[08:25:55] Progress step 149800/300000 — loss 0.0026922 — PSNR 25.739\r\n",
      "[08:25:57] Progress step 149900/300000 — loss 0.0026859 — PSNR 25.748\r\n",
      "[08:25:59] Progress step 150000/300000 — loss 0.0026787 — PSNR 25.760\r\n",
      "[08:25:59] Eval @ 150000: train_loss 0.0026787 — train_PSNR 25.760 — val_loss 0.0032872 — val_PSNR 24.832\r\n",
      "[08:26:00] Progress step 150100/300000 — loss 0.0026838 — PSNR 25.756\r\n",
      "[08:26:02] Progress step 150200/300000 — loss 0.0026749 — PSNR 25.769\r\n",
      "[08:26:03] Progress step 150300/300000 — loss 0.0026804 — PSNR 25.762\r\n",
      "[08:26:05] Progress step 150400/300000 — loss 0.0026784 — PSNR 25.765\r\n",
      "[08:26:07] Progress step 150500/300000 — loss 0.0026904 — PSNR 25.745\r\n",
      "[08:26:08] Progress step 150600/300000 — loss 0.0026904 — PSNR 25.745\r\n",
      "[08:26:10] Progress step 150700/300000 — loss 0.0026810 — PSNR 25.758\r\n",
      "[08:26:11] Progress step 150800/300000 — loss 0.0026766 — PSNR 25.765\r\n",
      "[08:26:13] Progress step 150900/300000 — loss 0.0026733 — PSNR 25.770\r\n",
      "[08:26:15] Progress step 151000/300000 — loss 0.0026704 — PSNR 25.775\r\n",
      "[08:26:33] Eval @ 151000: train_loss 0.0026704 — train_PSNR 25.775 — val_loss 0.0026477 — val_PSNR 26.397\r\n",
      "[08:26:35] Progress step 151100/300000 — loss 0.0026893 — PSNR 25.740\r\n",
      "[08:26:37] Progress step 151200/300000 — loss 0.0026831 — PSNR 25.750\r\n",
      "[08:26:38] Progress step 151300/300000 — loss 0.0026852 — PSNR 25.747\r\n",
      "[08:26:40] Progress step 151400/300000 — loss 0.0027006 — PSNR 25.722\r\n",
      "[08:26:41] Progress step 151500/300000 — loss 0.0027024 — PSNR 25.720\r\n",
      "[08:26:43] Progress step 151600/300000 — loss 0.0027080 — PSNR 25.711\r\n",
      "[08:26:45] Progress step 151700/300000 — loss 0.0026983 — PSNR 25.728\r\n",
      "[08:26:46] Progress step 151800/300000 — loss 0.0027009 — PSNR 25.724\r\n",
      "[08:26:48] Progress step 151900/300000 — loss 0.0027002 — PSNR 25.726\r\n",
      "[08:26:49] Progress step 152000/300000 — loss 0.0026957 — PSNR 25.733\r\n",
      "[08:26:49] Eval @ 152000: train_loss 0.0026957 — train_PSNR 25.733 — val_loss 0.0032826 — val_PSNR 24.838\r\n",
      "[08:26:51] Progress step 152100/300000 — loss 0.0026691 — PSNR 25.786\r\n",
      "[08:26:53] Progress step 152200/300000 — loss 0.0026486 — PSNR 25.813\r\n",
      "[08:26:54] Progress step 152300/300000 — loss 0.0026573 — PSNR 25.795\r\n",
      "[08:26:56] Progress step 152400/300000 — loss 0.0026560 — PSNR 25.795\r\n",
      "[08:26:57] Progress step 152500/300000 — loss 0.0026609 — PSNR 25.787\r\n",
      "[08:26:59] Progress step 152600/300000 — loss 0.0026666 — PSNR 25.780\r\n",
      "[08:27:01] Progress step 152700/300000 — loss 0.0026715 — PSNR 25.772\r\n",
      "[08:27:02] Progress step 152800/300000 — loss 0.0026756 — PSNR 25.766\r\n",
      "[08:27:04] Progress step 152900/300000 — loss 0.0026786 — PSNR 25.761\r\n",
      "[08:27:05] Progress step 153000/300000 — loss 0.0026861 — PSNR 25.749\r\n",
      "[08:27:24] Eval @ 153000: train_loss 0.0026861 — train_PSNR 25.749 — val_loss 0.0026485 — val_PSNR 26.395\r\n",
      "[08:27:26] Progress step 153100/300000 — loss 0.0026401 — PSNR 25.819\r\n",
      "[08:27:27] Progress step 153200/300000 — loss 0.0027015 — PSNR 25.723\r\n",
      "[08:27:29] Progress step 153300/300000 — loss 0.0026824 — PSNR 25.754\r\n",
      "[08:27:30] Progress step 153400/300000 — loss 0.0026907 — PSNR 25.741\r\n",
      "[08:27:32] Progress step 153500/300000 — loss 0.0026813 — PSNR 25.756\r\n",
      "[08:27:34] Progress step 153600/300000 — loss 0.0026800 — PSNR 25.759\r\n",
      "[08:27:35] Progress step 153700/300000 — loss 0.0026801 — PSNR 25.759\r\n",
      "[08:27:37] Progress step 153800/300000 — loss 0.0026800 — PSNR 25.758\r\n",
      "[08:27:38] Progress step 153900/300000 — loss 0.0026766 — PSNR 25.763\r\n",
      "[08:27:40] Progress step 154000/300000 — loss 0.0026739 — PSNR 25.768\r\n",
      "[08:27:40] Eval @ 154000: train_loss 0.0026739 — train_PSNR 25.768 — val_loss 0.0032919 — val_PSNR 24.826\r\n",
      "[08:27:42] Progress step 154100/300000 — loss 0.0027210 — PSNR 25.691\r\n",
      "[08:27:43] Progress step 154200/300000 — loss 0.0026934 — PSNR 25.736\r\n",
      "[08:27:45] Progress step 154300/300000 — loss 0.0026645 — PSNR 25.781\r\n",
      "[08:27:46] Progress step 154400/300000 — loss 0.0026684 — PSNR 25.775\r\n",
      "[08:27:48] Progress step 154500/300000 — loss 0.0026714 — PSNR 25.770\r\n",
      "[08:27:50] Progress step 154600/300000 — loss 0.0026782 — PSNR 25.760\r\n",
      "[08:27:51] Progress step 154700/300000 — loss 0.0026757 — PSNR 25.763\r\n",
      "[08:27:53] Progress step 154800/300000 — loss 0.0026781 — PSNR 25.760\r\n",
      "[08:27:54] Progress step 154900/300000 — loss 0.0026792 — PSNR 25.759\r\n",
      "[08:27:56] Progress step 155000/300000 — loss 0.0026813 — PSNR 25.756\r\n",
      "[08:28:15] Eval @ 155000: train_loss 0.0026813 — train_PSNR 25.756 — val_loss 0.0026486 — val_PSNR 26.395\r\n",
      "[08:28:16] Progress step 155100/300000 — loss 0.0027202 — PSNR 25.698\r\n",
      "[08:28:18] Progress step 155200/300000 — loss 0.0027215 — PSNR 25.698\r\n",
      "[08:28:20] Progress step 155300/300000 — loss 0.0027304 — PSNR 25.685\r\n",
      "[08:28:21] Progress step 155400/300000 — loss 0.0027265 — PSNR 25.689\r\n",
      "[08:28:23] Progress step 155500/300000 — loss 0.0027348 — PSNR 25.674\r\n",
      "[08:28:24] Progress step 155600/300000 — loss 0.0027307 — PSNR 25.680\r\n",
      "[08:28:26] Progress step 155700/300000 — loss 0.0027199 — PSNR 25.697\r\n",
      "[08:28:28] Progress step 155800/300000 — loss 0.0027102 — PSNR 25.712\r\n",
      "[08:28:29] Progress step 155900/300000 — loss 0.0027136 — PSNR 25.708\r\n",
      "[08:28:31] Progress step 156000/300000 — loss 0.0027151 — PSNR 25.704\r\n",
      "[08:28:31] Eval @ 156000: train_loss 0.0027151 — train_PSNR 25.704 — val_loss 0.0032981 — val_PSNR 24.817\r\n",
      "[08:28:32] Progress step 156100/300000 — loss 0.0026943 — PSNR 25.738\r\n",
      "[08:28:34] Progress step 156200/300000 — loss 0.0027349 — PSNR 25.672\r\n",
      "[08:28:36] Progress step 156300/300000 — loss 0.0027549 — PSNR 25.641\r\n",
      "[08:28:37] Progress step 156400/300000 — loss 0.0027344 — PSNR 25.674\r\n",
      "[08:28:39] Progress step 156500/300000 — loss 0.0027153 — PSNR 25.705\r\n",
      "[08:28:40] Progress step 156600/300000 — loss 0.0027186 — PSNR 25.700\r\n",
      "[08:28:42] Progress step 156700/300000 — loss 0.0027127 — PSNR 25.708\r\n",
      "[08:28:43] Progress step 156800/300000 — loss 0.0027189 — PSNR 25.698\r\n",
      "[08:28:45] Progress step 156900/300000 — loss 0.0027164 — PSNR 25.702\r\n",
      "[08:28:47] Progress step 157000/300000 — loss 0.0027133 — PSNR 25.707\r\n",
      "[08:29:05] Eval @ 157000: train_loss 0.0027133 — train_PSNR 25.707 — val_loss 0.0026476 — val_PSNR 26.397\r\n",
      "[08:29:07] Progress step 157100/300000 — loss 0.0026930 — PSNR 25.742\r\n",
      "[08:29:09] Progress step 157200/300000 — loss 0.0026725 — PSNR 25.777\r\n",
      "[08:29:10] Progress step 157300/300000 — loss 0.0026736 — PSNR 25.771\r\n",
      "[08:29:12] Progress step 157400/300000 — loss 0.0026645 — PSNR 25.785\r\n",
      "[08:29:14] Progress step 157500/300000 — loss 0.0026748 — PSNR 25.769\r\n",
      "[08:29:15] Progress step 157600/300000 — loss 0.0026801 — PSNR 25.760\r\n",
      "[08:29:17] Progress step 157700/300000 — loss 0.0026774 — PSNR 25.765\r\n",
      "[08:29:18] Progress step 157800/300000 — loss 0.0026760 — PSNR 25.766\r\n",
      "[08:29:20] Progress step 157900/300000 — loss 0.0026774 — PSNR 25.763\r\n",
      "[08:29:22] Progress step 158000/300000 — loss 0.0026726 — PSNR 25.771\r\n",
      "[08:29:22] Eval @ 158000: train_loss 0.0026726 — train_PSNR 25.771 — val_loss 0.0032775 — val_PSNR 24.845\r\n",
      "[08:29:23] Progress step 158100/300000 — loss 0.0027168 — PSNR 25.696\r\n",
      "[08:29:25] Progress step 158200/300000 — loss 0.0027203 — PSNR 25.690\r\n",
      "[08:29:26] Progress step 158300/300000 — loss 0.0027221 — PSNR 25.690\r\n",
      "[08:29:28] Progress step 158400/300000 — loss 0.0027089 — PSNR 25.713\r\n",
      "[08:29:30] Progress step 158500/300000 — loss 0.0027056 — PSNR 25.719\r\n",
      "[08:29:31] Progress step 158600/300000 — loss 0.0027036 — PSNR 25.721\r\n",
      "[08:29:33] Progress step 158700/300000 — loss 0.0026989 — PSNR 25.728\r\n",
      "[08:29:34] Progress step 158800/300000 — loss 0.0026927 — PSNR 25.739\r\n",
      "[08:29:36] Progress step 158900/300000 — loss 0.0026906 — PSNR 25.742\r\n",
      "[08:29:38] Progress step 159000/300000 — loss 0.0026924 — PSNR 25.739\r\n",
      "[08:29:56] Eval @ 159000: train_loss 0.0026924 — train_PSNR 25.739 — val_loss 0.0026463 — val_PSNR 26.400\r\n",
      "[08:29:58] Progress step 159100/300000 — loss 0.0026436 — PSNR 25.818\r\n",
      "[08:30:00] Progress step 159200/300000 — loss 0.0026649 — PSNR 25.788\r\n",
      "[08:30:01] Progress step 159300/300000 — loss 0.0026782 — PSNR 25.766\r\n",
      "[08:30:03] Progress step 159400/300000 — loss 0.0026870 — PSNR 25.752\r\n",
      "[08:30:04] Progress step 159500/300000 — loss 0.0026914 — PSNR 25.743\r\n",
      "[08:30:06] Progress step 159600/300000 — loss 0.0026967 — PSNR 25.734\r\n",
      "[08:30:08] Progress step 159700/300000 — loss 0.0026931 — PSNR 25.740\r\n",
      "[08:30:09] Progress step 159800/300000 — loss 0.0026921 — PSNR 25.742\r\n",
      "[08:30:11] Progress step 159900/300000 — loss 0.0026991 — PSNR 25.731\r\n",
      "[08:30:13] Progress step 160000/300000 — loss 0.0026973 — PSNR 25.733\r\n",
      "[08:30:13] Eval @ 160000: train_loss 0.0026973 — train_PSNR 25.733 — val_loss 0.0032962 — val_PSNR 24.820\r\n",
      "[08:30:14] Progress step 160100/300000 — loss 0.0026731 — PSNR 25.771\r\n",
      "[08:30:16] Progress step 160200/300000 — loss 0.0026802 — PSNR 25.761\r\n",
      "[08:30:17] Progress step 160300/300000 — loss 0.0026843 — PSNR 25.753\r\n",
      "[08:30:19] Progress step 160400/300000 — loss 0.0026873 — PSNR 25.749\r\n",
      "[08:30:21] Progress step 160500/300000 — loss 0.0026864 — PSNR 25.751\r\n",
      "[08:30:22] Progress step 160600/300000 — loss 0.0026808 — PSNR 25.760\r\n",
      "[08:30:24] Progress step 160700/300000 — loss 0.0026693 — PSNR 25.777\r\n",
      "[08:30:25] Progress step 160800/300000 — loss 0.0026739 — PSNR 25.769\r\n",
      "[08:30:27] Progress step 160900/300000 — loss 0.0026705 — PSNR 25.774\r\n",
      "[08:30:29] Progress step 161000/300000 — loss 0.0026723 — PSNR 25.770\r\n",
      "[08:30:47] Eval @ 161000: train_loss 0.0026723 — train_PSNR 25.770 — val_loss 0.0026485 — val_PSNR 26.395\r\n",
      "[08:30:49] Progress step 161100/300000 — loss 0.0026843 — PSNR 25.746\r\n",
      "[08:30:51] Progress step 161200/300000 — loss 0.0027051 — PSNR 25.712\r\n",
      "[08:30:52] Progress step 161300/300000 — loss 0.0026853 — PSNR 25.750\r\n",
      "[08:30:54] Progress step 161400/300000 — loss 0.0026898 — PSNR 25.744\r\n",
      "[08:30:55] Progress step 161500/300000 — loss 0.0027008 — PSNR 25.726\r\n",
      "[08:30:57] Progress step 161600/300000 — loss 0.0027053 — PSNR 25.718\r\n",
      "[08:30:58] Progress step 161700/300000 — loss 0.0026945 — PSNR 25.736\r\n",
      "[08:31:00] Progress step 161800/300000 — loss 0.0026959 — PSNR 25.735\r\n",
      "[08:31:02] Progress step 161900/300000 — loss 0.0026946 — PSNR 25.737\r\n",
      "[08:31:03] Progress step 162000/300000 — loss 0.0026956 — PSNR 25.735\r\n",
      "[08:31:03] Eval @ 162000: train_loss 0.0026956 — train_PSNR 25.735 — val_loss 0.0032811 — val_PSNR 24.840\r\n",
      "[08:31:05] Progress step 162100/300000 — loss 0.0026682 — PSNR 25.777\r\n",
      "[08:31:06] Progress step 162200/300000 — loss 0.0026867 — PSNR 25.747\r\n",
      "[08:31:08] Progress step 162300/300000 — loss 0.0026925 — PSNR 25.738\r\n",
      "[08:31:10] Progress step 162400/300000 — loss 0.0026932 — PSNR 25.735\r\n",
      "[08:31:11] Progress step 162500/300000 — loss 0.0026872 — PSNR 25.745\r\n",
      "[08:31:13] Progress step 162600/300000 — loss 0.0026875 — PSNR 25.745\r\n",
      "[08:31:14] Progress step 162700/300000 — loss 0.0026810 — PSNR 25.754\r\n",
      "[08:31:16] Progress step 162800/300000 — loss 0.0026801 — PSNR 25.757\r\n",
      "[08:31:18] Progress step 162900/300000 — loss 0.0026843 — PSNR 25.751\r\n",
      "[08:31:19] Progress step 163000/300000 — loss 0.0026883 — PSNR 25.744\r\n",
      "[08:31:38] Eval @ 163000: train_loss 0.0026883 — train_PSNR 25.744 — val_loss 0.0026767 — val_PSNR 26.335\r\n",
      "[08:31:39] Progress step 163100/300000 — loss 0.0026511 — PSNR 25.813\r\n",
      "[08:31:41] Progress step 163200/300000 — loss 0.0026863 — PSNR 25.758\r\n",
      "[08:31:43] Progress step 163300/300000 — loss 0.0026797 — PSNR 25.765\r\n",
      "[08:31:44] Progress step 163400/300000 — loss 0.0026812 — PSNR 25.762\r\n",
      "[08:31:46] Progress step 163500/300000 — loss 0.0026925 — PSNR 25.741\r\n",
      "[08:31:48] Progress step 163600/300000 — loss 0.0026726 — PSNR 25.774\r\n",
      "[08:31:49] Progress step 163700/300000 — loss 0.0026707 — PSNR 25.778\r\n",
      "[08:31:51] Progress step 163800/300000 — loss 0.0026709 — PSNR 25.777\r\n",
      "[08:31:52] Progress step 163900/300000 — loss 0.0026733 — PSNR 25.773\r\n",
      "[08:31:54] Progress step 164000/300000 — loss 0.0026787 — PSNR 25.763\r\n",
      "[08:31:54] Eval @ 164000: train_loss 0.0026787 — train_PSNR 25.763 — val_loss 0.0032782 — val_PSNR 24.844\r\n",
      "[08:31:56] Progress step 164100/300000 — loss 0.0026449 — PSNR 25.822\r\n",
      "[08:31:57] Progress step 164200/300000 — loss 0.0026341 — PSNR 25.838\r\n",
      "[08:31:59] Progress step 164300/300000 — loss 0.0026600 — PSNR 25.793\r\n",
      "[08:32:00] Progress step 164400/300000 — loss 0.0026484 — PSNR 25.808\r\n",
      "[08:32:02] Progress step 164500/300000 — loss 0.0026613 — PSNR 25.788\r\n",
      "[08:32:04] Progress step 164600/300000 — loss 0.0026645 — PSNR 25.783\r\n",
      "[08:32:05] Progress step 164700/300000 — loss 0.0026742 — PSNR 25.769\r\n",
      "[08:32:07] Progress step 164800/300000 — loss 0.0026705 — PSNR 25.775\r\n",
      "[08:32:08] Progress step 164900/300000 — loss 0.0026768 — PSNR 25.766\r\n",
      "[08:32:10] Progress step 165000/300000 — loss 0.0026756 — PSNR 25.768\r\n",
      "[08:32:29] Eval @ 165000: train_loss 0.0026756 — train_PSNR 25.768 — val_loss 0.0026532 — val_PSNR 26.385\r\n",
      "[08:32:30] Progress step 165100/300000 — loss 0.0027014 — PSNR 25.735\r\n",
      "[08:32:32] Progress step 165200/300000 — loss 0.0027007 — PSNR 25.733\r\n",
      "[08:32:34] Progress step 165300/300000 — loss 0.0027009 — PSNR 25.733\r\n",
      "[08:32:35] Progress step 165400/300000 — loss 0.0027002 — PSNR 25.733\r\n",
      "[08:32:37] Progress step 165500/300000 — loss 0.0026937 — PSNR 25.743\r\n",
      "[08:32:39] Progress step 165600/300000 — loss 0.0026992 — PSNR 25.733\r\n",
      "[08:32:40] Progress step 165700/300000 — loss 0.0027020 — PSNR 25.728\r\n",
      "[08:32:42] Progress step 165800/300000 — loss 0.0027098 — PSNR 25.716\r\n",
      "[08:32:44] Progress step 165900/300000 — loss 0.0027062 — PSNR 25.721\r\n",
      "[08:32:45] Progress step 166000/300000 — loss 0.0027005 — PSNR 25.730\r\n",
      "[08:32:45] Eval @ 166000: train_loss 0.0027005 — train_PSNR 25.730 — val_loss 0.0032761 — val_PSNR 24.846\r\n",
      "[08:32:47] Progress step 166100/300000 — loss 0.0026399 — PSNR 25.831\r\n",
      "[08:32:48] Progress step 166200/300000 — loss 0.0026573 — PSNR 25.795\r\n",
      "[08:32:50] Progress step 166300/300000 — loss 0.0026925 — PSNR 25.739\r\n",
      "[08:32:52] Progress step 166400/300000 — loss 0.0027023 — PSNR 25.723\r\n",
      "[08:32:53] Progress step 166500/300000 — loss 0.0027051 — PSNR 25.717\r\n",
      "[08:32:55] Progress step 166600/300000 — loss 0.0026915 — PSNR 25.738\r\n",
      "[08:32:56] Progress step 166700/300000 — loss 0.0026883 — PSNR 25.743\r\n",
      "[08:32:58] Progress step 166800/300000 — loss 0.0026777 — PSNR 25.760\r\n",
      "[08:33:00] Progress step 166900/300000 — loss 0.0026850 — PSNR 25.748\r\n",
      "[08:33:01] Progress step 167000/300000 — loss 0.0026888 — PSNR 25.742\r\n",
      "[08:33:20] Eval @ 167000: train_loss 0.0026888 — train_PSNR 25.742 — val_loss 0.0026521 — val_PSNR 26.388\r\n",
      "[08:33:22] Progress step 167100/300000 — loss 0.0027053 — PSNR 25.725\r\n",
      "[08:33:23] Progress step 167200/300000 — loss 0.0026979 — PSNR 25.735\r\n",
      "[08:33:25] Progress step 167300/300000 — loss 0.0026933 — PSNR 25.738\r\n",
      "[08:33:26] Progress step 167400/300000 — loss 0.0026851 — PSNR 25.750\r\n",
      "[08:33:28] Progress step 167500/300000 — loss 0.0026845 — PSNR 25.750\r\n",
      "[08:33:30] Progress step 167600/300000 — loss 0.0026785 — PSNR 25.760\r\n",
      "[08:33:31] Progress step 167700/300000 — loss 0.0026802 — PSNR 25.758\r\n",
      "[08:33:33] Progress step 167800/300000 — loss 0.0026925 — PSNR 25.740\r\n",
      "[08:33:34] Progress step 167900/300000 — loss 0.0026887 — PSNR 25.746\r\n",
      "[08:33:36] Progress step 168000/300000 — loss 0.0026910 — PSNR 25.743\r\n",
      "[08:33:36] Eval @ 168000: train_loss 0.0026910 — train_PSNR 25.743 — val_loss 0.0032971 — val_PSNR 24.819\r\n",
      "[08:33:37] Progress step 168100/300000 — loss 0.0026976 — PSNR 25.727\r\n",
      "[08:33:39] Progress step 168200/300000 — loss 0.0027096 — PSNR 25.708\r\n",
      "[08:33:41] Progress step 168300/300000 — loss 0.0026804 — PSNR 25.755\r\n",
      "[08:33:42] Progress step 168400/300000 — loss 0.0026902 — PSNR 25.740\r\n",
      "[08:33:44] Progress step 168500/300000 — loss 0.0026892 — PSNR 25.743\r\n",
      "[08:33:45] Progress step 168600/300000 — loss 0.0027003 — PSNR 25.727\r\n",
      "[08:33:47] Progress step 168700/300000 — loss 0.0026956 — PSNR 25.735\r\n",
      "[08:33:49] Progress step 168800/300000 — loss 0.0026886 — PSNR 25.746\r\n",
      "[08:33:50] Progress step 168900/300000 — loss 0.0026826 — PSNR 25.755\r\n",
      "[08:33:52] Progress step 169000/300000 — loss 0.0026803 — PSNR 25.758\r\n",
      "[08:34:11] Eval @ 169000: train_loss 0.0026803 — train_PSNR 25.758 — val_loss 0.0026468 — val_PSNR 26.399\r\n",
      "[08:34:12] Progress step 169100/300000 — loss 0.0026664 — PSNR 25.792\r\n",
      "[08:34:14] Progress step 169200/300000 — loss 0.0026867 — PSNR 25.757\r\n",
      "[08:34:15] Progress step 169300/300000 — loss 0.0026689 — PSNR 25.782\r\n",
      "[08:34:17] Progress step 169400/300000 — loss 0.0026781 — PSNR 25.765\r\n",
      "[08:34:19] Progress step 169500/300000 — loss 0.0026758 — PSNR 25.768\r\n",
      "[08:34:20] Progress step 169600/300000 — loss 0.0026774 — PSNR 25.765\r\n",
      "[08:34:22] Progress step 169700/300000 — loss 0.0026849 — PSNR 25.753\r\n",
      "[08:34:23] Progress step 169800/300000 — loss 0.0026878 — PSNR 25.749\r\n",
      "[08:34:25] Progress step 169900/300000 — loss 0.0026921 — PSNR 25.741\r\n",
      "[08:34:27] Progress step 170000/300000 — loss 0.0026901 — PSNR 25.744\r\n",
      "[08:34:27] Eval @ 170000: train_loss 0.0026901 — train_PSNR 25.744 — val_loss 0.0033012 — val_PSNR 24.813\r\n",
      "[08:34:28] Progress step 170100/300000 — loss 0.0027262 — PSNR 25.683\r\n",
      "[08:34:30] Progress step 170200/300000 — loss 0.0027276 — PSNR 25.682\r\n",
      "[08:34:31] Progress step 170300/300000 — loss 0.0027291 — PSNR 25.681\r\n",
      "[08:34:33] Progress step 170400/300000 — loss 0.0027217 — PSNR 25.690\r\n",
      "[08:34:35] Progress step 170500/300000 — loss 0.0027107 — PSNR 25.707\r\n",
      "[08:34:36] Progress step 170600/300000 — loss 0.0026911 — PSNR 25.740\r\n",
      "[08:34:38] Progress step 170700/300000 — loss 0.0026918 — PSNR 25.740\r\n",
      "[08:34:39] Progress step 170800/300000 — loss 0.0026943 — PSNR 25.737\r\n",
      "[08:34:41] Progress step 170900/300000 — loss 0.0026941 — PSNR 25.736\r\n",
      "[08:34:43] Progress step 171000/300000 — loss 0.0026934 — PSNR 25.736\r\n",
      "[08:35:01] Eval @ 171000: train_loss 0.0026934 — train_PSNR 25.736 — val_loss 0.0026481 — val_PSNR 26.396\r\n",
      "[08:35:03] Progress step 171100/300000 — loss 0.0026396 — PSNR 25.825\r\n",
      "[08:35:05] Progress step 171200/300000 — loss 0.0026633 — PSNR 25.789\r\n",
      "[08:35:06] Progress step 171300/300000 — loss 0.0026772 — PSNR 25.766\r\n",
      "[08:35:08] Progress step 171400/300000 — loss 0.0026861 — PSNR 25.751\r\n",
      "[08:35:09] Progress step 171500/300000 — loss 0.0026945 — PSNR 25.735\r\n",
      "[08:35:11] Progress step 171600/300000 — loss 0.0026921 — PSNR 25.738\r\n",
      "[08:35:13] Progress step 171700/300000 — loss 0.0026929 — PSNR 25.737\r\n",
      "[08:35:14] Progress step 171800/300000 — loss 0.0026929 — PSNR 25.736\r\n",
      "[08:35:16] Progress step 171900/300000 — loss 0.0026920 — PSNR 25.737\r\n",
      "[08:35:17] Progress step 172000/300000 — loss 0.0026911 — PSNR 25.739\r\n",
      "[08:35:17] Eval @ 172000: train_loss 0.0026911 — train_PSNR 25.739 — val_loss 0.0032860 — val_PSNR 24.833\r\n",
      "[08:35:19] Progress step 172100/300000 — loss 0.0027821 — PSNR 25.598\r\n",
      "[08:35:21] Progress step 172200/300000 — loss 0.0027141 — PSNR 25.707\r\n",
      "[08:35:22] Progress step 172300/300000 — loss 0.0027167 — PSNR 25.704\r\n",
      "[08:35:24] Progress step 172400/300000 — loss 0.0027109 — PSNR 25.714\r\n",
      "[08:35:25] Progress step 172500/300000 — loss 0.0026948 — PSNR 25.740\r\n",
      "[08:35:27] Progress step 172600/300000 — loss 0.0026980 — PSNR 25.735\r\n",
      "[08:35:28] Progress step 172700/300000 — loss 0.0027023 — PSNR 25.727\r\n",
      "[08:35:30] Progress step 172800/300000 — loss 0.0027027 — PSNR 25.726\r\n",
      "[08:35:32] Progress step 172900/300000 — loss 0.0026975 — PSNR 25.735\r\n",
      "[08:35:33] Progress step 173000/300000 — loss 0.0026909 — PSNR 25.746\r\n",
      "[08:35:52] Eval @ 173000: train_loss 0.0026909 — train_PSNR 25.746 — val_loss 0.0026463 — val_PSNR 26.400\r\n",
      "[08:35:53] Progress step 173100/300000 — loss 0.0026678 — PSNR 25.785\r\n",
      "[08:35:55] Progress step 173200/300000 — loss 0.0027086 — PSNR 25.718\r\n",
      "[08:35:57] Progress step 173300/300000 — loss 0.0027073 — PSNR 25.718\r\n",
      "[08:35:58] Progress step 173400/300000 — loss 0.0027074 — PSNR 25.716\r\n",
      "[08:36:00] Progress step 173500/300000 — loss 0.0027147 — PSNR 25.704\r\n",
      "[08:36:02] Progress step 173600/300000 — loss 0.0027071 — PSNR 25.717\r\n",
      "[08:36:03] Progress step 173700/300000 — loss 0.0026929 — PSNR 25.741\r\n",
      "[08:36:05] Progress step 173800/300000 — loss 0.0026851 — PSNR 25.752\r\n",
      "[08:36:06] Progress step 173900/300000 — loss 0.0026872 — PSNR 25.749\r\n",
      "[08:36:08] Progress step 174000/300000 — loss 0.0026836 — PSNR 25.755\r\n",
      "[08:36:08] Eval @ 174000: train_loss 0.0026836 — train_PSNR 25.755 — val_loss 0.0032819 — val_PSNR 24.839\r\n",
      "[08:36:10] Progress step 174100/300000 — loss 0.0026809 — PSNR 25.754\r\n",
      "[08:36:11] Progress step 174200/300000 — loss 0.0026911 — PSNR 25.743\r\n",
      "[08:36:13] Progress step 174300/300000 — loss 0.0026857 — PSNR 25.753\r\n",
      "[08:36:14] Progress step 174400/300000 — loss 0.0026702 — PSNR 25.778\r\n",
      "[08:36:16] Progress step 174500/300000 — loss 0.0026707 — PSNR 25.775\r\n",
      "[08:36:17] Progress step 174600/300000 — loss 0.0026687 — PSNR 25.778\r\n",
      "[08:36:19] Progress step 174700/300000 — loss 0.0026729 — PSNR 25.772\r\n",
      "[08:36:21] Progress step 174800/300000 — loss 0.0026774 — PSNR 25.764\r\n",
      "[08:36:22] Progress step 174900/300000 — loss 0.0026781 — PSNR 25.763\r\n",
      "[08:36:24] Progress step 175000/300000 — loss 0.0026801 — PSNR 25.759\r\n",
      "[08:36:43] Eval @ 175000: train_loss 0.0026801 — train_PSNR 25.759 — val_loss 0.0026539 — val_PSNR 26.384\r\n",
      "[08:36:44] Progress step 175100/300000 — loss 0.0026682 — PSNR 25.773\r\n",
      "[08:36:46] Progress step 175200/300000 — loss 0.0026639 — PSNR 25.789\r\n",
      "[08:36:47] Progress step 175300/300000 — loss 0.0026734 — PSNR 25.773\r\n",
      "[08:36:49] Progress step 175400/300000 — loss 0.0026733 — PSNR 25.772\r\n",
      "[08:36:51] Progress step 175500/300000 — loss 0.0026691 — PSNR 25.777\r\n",
      "[08:36:52] Progress step 175600/300000 — loss 0.0026637 — PSNR 25.786\r\n",
      "[08:36:54] Progress step 175700/300000 — loss 0.0026685 — PSNR 25.779\r\n",
      "[08:36:55] Progress step 175800/300000 — loss 0.0026685 — PSNR 25.779\r\n",
      "[08:36:57] Progress step 175900/300000 — loss 0.0026739 — PSNR 25.770\r\n",
      "[08:36:59] Progress step 176000/300000 — loss 0.0026722 — PSNR 25.774\r\n",
      "[08:36:59] Eval @ 176000: train_loss 0.0026722 — train_PSNR 25.774 — val_loss 0.0032945 — val_PSNR 24.822\r\n",
      "[08:37:00] Progress step 176100/300000 — loss 0.0026842 — PSNR 25.760\r\n",
      "[08:37:02] Progress step 176200/300000 — loss 0.0027012 — PSNR 25.732\r\n",
      "[08:37:03] Progress step 176300/300000 — loss 0.0026892 — PSNR 25.749\r\n",
      "[08:37:05] Progress step 176400/300000 — loss 0.0026930 — PSNR 25.741\r\n",
      "[08:37:07] Progress step 176500/300000 — loss 0.0027000 — PSNR 25.728\r\n",
      "[08:37:08] Progress step 176600/300000 — loss 0.0026924 — PSNR 25.740\r\n",
      "[08:37:10] Progress step 176700/300000 — loss 0.0026889 — PSNR 25.746\r\n",
      "[08:37:11] Progress step 176800/300000 — loss 0.0026895 — PSNR 25.745\r\n",
      "[08:37:13] Progress step 176900/300000 — loss 0.0026909 — PSNR 25.743\r\n",
      "[08:37:14] Progress step 177000/300000 — loss 0.0026914 — PSNR 25.743\r\n",
      "[08:37:33] Eval @ 177000: train_loss 0.0026914 — train_PSNR 25.743 — val_loss 0.0026514 — val_PSNR 26.389\r\n",
      "[08:37:35] Progress step 177100/300000 — loss 0.0026305 — PSNR 25.847\r\n",
      "[08:37:36] Progress step 177200/300000 — loss 0.0026577 — PSNR 25.803\r\n",
      "[08:37:38] Progress step 177300/300000 — loss 0.0026468 — PSNR 25.818\r\n",
      "[08:37:40] Progress step 177400/300000 — loss 0.0026563 — PSNR 25.801\r\n",
      "[08:37:41] Progress step 177500/300000 — loss 0.0026539 — PSNR 25.804\r\n",
      "[08:37:43] Progress step 177600/300000 — loss 0.0026610 — PSNR 25.791\r\n",
      "[08:37:44] Progress step 177700/300000 — loss 0.0026634 — PSNR 25.787\r\n",
      "[08:37:46] Progress step 177800/300000 — loss 0.0026665 — PSNR 25.780\r\n",
      "[08:37:48] Progress step 177900/300000 — loss 0.0026629 — PSNR 25.785\r\n",
      "[08:37:49] Progress step 178000/300000 — loss 0.0026678 — PSNR 25.778\r\n",
      "[08:37:49] Eval @ 178000: train_loss 0.0026678 — train_PSNR 25.778 — val_loss 0.0032767 — val_PSNR 24.846\r\n",
      "[08:37:51] Progress step 178100/300000 — loss 0.0026795 — PSNR 25.752\r\n",
      "[08:37:52] Progress step 178200/300000 — loss 0.0026672 — PSNR 25.775\r\n",
      "[08:37:54] Progress step 178300/300000 — loss 0.0026647 — PSNR 25.780\r\n",
      "[08:37:56] Progress step 178400/300000 — loss 0.0026893 — PSNR 25.739\r\n",
      "[08:37:57] Progress step 178500/300000 — loss 0.0026838 — PSNR 25.749\r\n",
      "[08:37:59] Progress step 178600/300000 — loss 0.0026876 — PSNR 25.743\r\n",
      "[08:38:00] Progress step 178700/300000 — loss 0.0026804 — PSNR 25.755\r\n",
      "[08:38:02] Progress step 178800/300000 — loss 0.0026794 — PSNR 25.757\r\n",
      "[08:38:04] Progress step 178900/300000 — loss 0.0026815 — PSNR 25.754\r\n",
      "[08:38:05] Progress step 179000/300000 — loss 0.0026818 — PSNR 25.754\r\n",
      "[08:38:24] Eval @ 179000: train_loss 0.0026818 — train_PSNR 25.754 — val_loss 0.0026541 — val_PSNR 26.383\r\n",
      "[08:38:26] Progress step 179100/300000 — loss 0.0026943 — PSNR 25.737\r\n",
      "[08:38:27] Progress step 179200/300000 — loss 0.0026649 — PSNR 25.785\r\n",
      "[08:38:29] Progress step 179300/300000 — loss 0.0026889 — PSNR 25.747\r\n",
      "[08:38:30] Progress step 179400/300000 — loss 0.0026891 — PSNR 25.746\r\n",
      "[08:38:32] Progress step 179500/300000 — loss 0.0026891 — PSNR 25.748\r\n",
      "[08:38:34] Progress step 179600/300000 — loss 0.0026917 — PSNR 25.743\r\n",
      "[08:38:35] Progress step 179700/300000 — loss 0.0026941 — PSNR 25.739\r\n",
      "[08:38:37] Progress step 179800/300000 — loss 0.0026917 — PSNR 25.743\r\n",
      "[08:38:38] Progress step 179900/300000 — loss 0.0026886 — PSNR 25.749\r\n",
      "[08:38:40] Progress step 180000/300000 — loss 0.0026933 — PSNR 25.740\r\n",
      "[08:38:40] Eval @ 180000: train_loss 0.0026933 — train_PSNR 25.740 — val_loss 0.0032788 — val_PSNR 24.843\r\n",
      "[08:38:42] Progress step 180100/300000 — loss 0.0026615 — PSNR 25.782\r\n",
      "[08:38:43] Progress step 180200/300000 — loss 0.0026695 — PSNR 25.775\r\n",
      "[08:38:45] Progress step 180300/300000 — loss 0.0026722 — PSNR 25.769\r\n",
      "[08:38:46] Progress step 180400/300000 — loss 0.0026715 — PSNR 25.771\r\n",
      "[08:38:48] Progress step 180500/300000 — loss 0.0026746 — PSNR 25.767\r\n",
      "[08:38:50] Progress step 180600/300000 — loss 0.0026719 — PSNR 25.773\r\n",
      "[08:38:51] Progress step 180700/300000 — loss 0.0026725 — PSNR 25.772\r\n",
      "[08:38:53] Progress step 180800/300000 — loss 0.0026737 — PSNR 25.771\r\n",
      "[08:38:54] Progress step 180900/300000 — loss 0.0026760 — PSNR 25.767\r\n",
      "[08:38:56] Progress step 181000/300000 — loss 0.0026703 — PSNR 25.776\r\n",
      "[08:39:15] Eval @ 181000: train_loss 0.0026703 — train_PSNR 25.776 — val_loss 0.0026512 — val_PSNR 26.389\r\n",
      "[08:39:16] Progress step 181100/300000 — loss 0.0026865 — PSNR 25.762\r\n",
      "[08:39:18] Progress step 181200/300000 — loss 0.0026672 — PSNR 25.788\r\n",
      "[08:39:20] Progress step 181300/300000 — loss 0.0026650 — PSNR 25.790\r\n",
      "[08:39:21] Progress step 181400/300000 — loss 0.0026739 — PSNR 25.773\r\n",
      "[08:39:23] Progress step 181500/300000 — loss 0.0026721 — PSNR 25.776\r\n",
      "[08:39:24] Progress step 181600/300000 — loss 0.0026818 — PSNR 25.759\r\n",
      "[08:39:26] Progress step 181700/300000 — loss 0.0026838 — PSNR 25.756\r\n",
      "[08:39:28] Progress step 181800/300000 — loss 0.0026941 — PSNR 25.739\r\n",
      "[08:39:29] Progress step 181900/300000 — loss 0.0026989 — PSNR 25.731\r\n",
      "[08:39:31] Progress step 182000/300000 — loss 0.0026987 — PSNR 25.731\r\n",
      "[08:39:31] Eval @ 182000: train_loss 0.0026987 — train_PSNR 25.731 — val_loss 0.0032775 — val_PSNR 24.845\r\n",
      "[08:39:32] Progress step 182100/300000 — loss 0.0027186 — PSNR 25.699\r\n",
      "[08:39:34] Progress step 182200/300000 — loss 0.0026944 — PSNR 25.740\r\n",
      "[08:39:36] Progress step 182300/300000 — loss 0.0026770 — PSNR 25.768\r\n",
      "[08:39:37] Progress step 182400/300000 — loss 0.0026851 — PSNR 25.753\r\n",
      "[08:39:39] Progress step 182500/300000 — loss 0.0026856 — PSNR 25.751\r\n",
      "[08:39:40] Progress step 182600/300000 — loss 0.0026944 — PSNR 25.739\r\n",
      "[08:39:42] Progress step 182700/300000 — loss 0.0026947 — PSNR 25.738\r\n",
      "[08:39:44] Progress step 182800/300000 — loss 0.0027041 — PSNR 25.723\r\n",
      "[08:39:45] Progress step 182900/300000 — loss 0.0026988 — PSNR 25.730\r\n",
      "[08:39:47] Progress step 183000/300000 — loss 0.0026994 — PSNR 25.730\r\n",
      "[08:40:06] Eval @ 183000: train_loss 0.0026994 — train_PSNR 25.730 — val_loss 0.0026498 — val_PSNR 26.392\r\n",
      "[08:40:07] Progress step 183100/300000 — loss 0.0026332 — PSNR 25.835\r\n",
      "[08:40:09] Progress step 183200/300000 — loss 0.0026809 — PSNR 25.756\r\n",
      "[08:40:10] Progress step 183300/300000 — loss 0.0026852 — PSNR 25.749\r\n",
      "[08:40:12] Progress step 183400/300000 — loss 0.0026866 — PSNR 25.747\r\n",
      "[08:40:14] Progress step 183500/300000 — loss 0.0026868 — PSNR 25.750\r\n",
      "[08:40:15] Progress step 183600/300000 — loss 0.0026810 — PSNR 25.758\r\n",
      "[08:40:17] Progress step 183700/300000 — loss 0.0026790 — PSNR 25.761\r\n",
      "[08:40:18] Progress step 183800/300000 — loss 0.0026828 — PSNR 25.754\r\n",
      "[08:40:20] Progress step 183900/300000 — loss 0.0026855 — PSNR 25.750\r\n",
      "[08:40:22] Progress step 184000/300000 — loss 0.0026932 — PSNR 25.737\r\n",
      "[08:40:22] Eval @ 184000: train_loss 0.0026932 — train_PSNR 25.737 — val_loss 0.0032807 — val_PSNR 24.840\r\n",
      "[08:40:23] Progress step 184100/300000 — loss 0.0027337 — PSNR 25.673\r\n",
      "[08:40:25] Progress step 184200/300000 — loss 0.0026869 — PSNR 25.754\r\n",
      "[08:40:26] Progress step 184300/300000 — loss 0.0026575 — PSNR 25.797\r\n",
      "[08:40:28] Progress step 184400/300000 — loss 0.0026646 — PSNR 25.784\r\n",
      "[08:40:30] Progress step 184500/300000 — loss 0.0026849 — PSNR 25.752\r\n",
      "[08:40:31] Progress step 184600/300000 — loss 0.0026803 — PSNR 25.760\r\n",
      "[08:40:33] Progress step 184700/300000 — loss 0.0026746 — PSNR 25.768\r\n",
      "[08:40:34] Progress step 184800/300000 — loss 0.0026775 — PSNR 25.764\r\n",
      "[08:40:36] Progress step 184900/300000 — loss 0.0026782 — PSNR 25.762\r\n",
      "[08:40:37] Progress step 185000/300000 — loss 0.0026833 — PSNR 25.754\r\n",
      "[08:40:56] Eval @ 185000: train_loss 0.0026833 — train_PSNR 25.754 — val_loss 0.0026516 — val_PSNR 26.389\r\n",
      "[08:40:58] Progress step 185100/300000 — loss 0.0026268 — PSNR 25.850\r\n",
      "[08:40:59] Progress step 185200/300000 — loss 0.0026189 — PSNR 25.866\r\n",
      "[08:41:01] Progress step 185300/300000 — loss 0.0026352 — PSNR 25.836\r\n",
      "[08:41:03] Progress step 185400/300000 — loss 0.0026629 — PSNR 25.789\r\n",
      "[08:41:04] Progress step 185500/300000 — loss 0.0026718 — PSNR 25.775\r\n",
      "[08:41:06] Progress step 185600/300000 — loss 0.0026821 — PSNR 25.759\r\n",
      "[08:41:07] Progress step 185700/300000 — loss 0.0026840 — PSNR 25.755\r\n",
      "[08:41:09] Progress step 185800/300000 — loss 0.0026804 — PSNR 25.761\r\n",
      "[08:41:10] Progress step 185900/300000 — loss 0.0026868 — PSNR 25.751\r\n",
      "[08:41:12] Progress step 186000/300000 — loss 0.0026880 — PSNR 25.749\r\n",
      "[08:41:12] Eval @ 186000: train_loss 0.0026880 — train_PSNR 25.749 — val_loss 0.0032753 — val_PSNR 24.847\r\n",
      "[08:41:14] Progress step 186100/300000 — loss 0.0027129 — PSNR 25.715\r\n",
      "[08:41:15] Progress step 186200/300000 — loss 0.0026703 — PSNR 25.780\r\n",
      "[08:41:17] Progress step 186300/300000 — loss 0.0026835 — PSNR 25.755\r\n",
      "[08:41:19] Progress step 186400/300000 — loss 0.0026861 — PSNR 25.749\r\n",
      "[08:41:20] Progress step 186500/300000 — loss 0.0026905 — PSNR 25.741\r\n",
      "[08:41:22] Progress step 186600/300000 — loss 0.0026874 — PSNR 25.746\r\n",
      "[08:41:23] Progress step 186700/300000 — loss 0.0026938 — PSNR 25.736\r\n",
      "[08:41:25] Progress step 186800/300000 — loss 0.0026982 — PSNR 25.729\r\n",
      "[08:41:26] Progress step 186900/300000 — loss 0.0026867 — PSNR 25.748\r\n",
      "[08:41:28] Progress step 187000/300000 — loss 0.0026887 — PSNR 25.746\r\n",
      "[08:41:47] Eval @ 187000: train_loss 0.0026887 — train_PSNR 25.746 — val_loss 0.0026460 — val_PSNR 26.401\r\n",
      "[08:41:47] Saved best model at step 187000\r\n",
      "[08:41:48] Progress step 187100/300000 — loss 0.0026830 — PSNR 25.754\r\n",
      "[08:41:50] Progress step 187200/300000 — loss 0.0026939 — PSNR 25.734\r\n",
      "[08:41:51] Progress step 187300/300000 — loss 0.0026802 — PSNR 25.758\r\n",
      "[08:41:53] Progress step 187400/300000 — loss 0.0026813 — PSNR 25.755\r\n",
      "[08:41:55] Progress step 187500/300000 — loss 0.0026879 — PSNR 25.746\r\n",
      "[08:41:56] Progress step 187600/300000 — loss 0.0026869 — PSNR 25.746\r\n",
      "[08:41:58] Progress step 187700/300000 — loss 0.0026894 — PSNR 25.742\r\n",
      "[08:41:59] Progress step 187800/300000 — loss 0.0026889 — PSNR 25.743\r\n",
      "[08:42:01] Progress step 187900/300000 — loss 0.0026809 — PSNR 25.757\r\n",
      "[08:42:03] Progress step 188000/300000 — loss 0.0026831 — PSNR 25.754\r\n",
      "[08:42:03] Eval @ 188000: train_loss 0.0026831 — train_PSNR 25.754 — val_loss 0.0033062 — val_PSNR 24.807\r\n",
      "[08:42:04] Progress step 188100/300000 — loss 0.0027110 — PSNR 25.709\r\n",
      "[08:42:06] Progress step 188200/300000 — loss 0.0026714 — PSNR 25.776\r\n",
      "[08:42:07] Progress step 188300/300000 — loss 0.0026852 — PSNR 25.753\r\n",
      "[08:42:09] Progress step 188400/300000 — loss 0.0026861 — PSNR 25.751\r\n",
      "[08:42:10] Progress step 188500/300000 — loss 0.0026931 — PSNR 25.740\r\n",
      "[08:42:12] Progress step 188600/300000 — loss 0.0026937 — PSNR 25.738\r\n",
      "[08:42:14] Progress step 188700/300000 — loss 0.0026987 — PSNR 25.730\r\n",
      "[08:42:15] Progress step 188800/300000 — loss 0.0026944 — PSNR 25.736\r\n",
      "[08:42:17] Progress step 188900/300000 — loss 0.0026947 — PSNR 25.737\r\n",
      "[08:42:18] Progress step 189000/300000 — loss 0.0026943 — PSNR 25.738\r\n",
      "[08:42:37] Eval @ 189000: train_loss 0.0026943 — train_PSNR 25.738 — val_loss 0.0026482 — val_PSNR 26.396\r\n",
      "[08:42:39] Progress step 189100/300000 — loss 0.0027162 — PSNR 25.707\r\n",
      "[08:42:40] Progress step 189200/300000 — loss 0.0026868 — PSNR 25.755\r\n",
      "[08:42:42] Progress step 189300/300000 — loss 0.0026862 — PSNR 25.750\r\n",
      "[08:42:43] Progress step 189400/300000 — loss 0.0026824 — PSNR 25.756\r\n",
      "[08:42:45] Progress step 189500/300000 — loss 0.0026688 — PSNR 25.776\r\n",
      "[08:42:47] Progress step 189600/300000 — loss 0.0026680 — PSNR 25.776\r\n",
      "[08:42:48] Progress step 189700/300000 — loss 0.0026721 — PSNR 25.768\r\n",
      "[08:42:50] Progress step 189800/300000 — loss 0.0026831 — PSNR 25.751\r\n",
      "[08:42:51] Progress step 189900/300000 — loss 0.0026819 — PSNR 25.754\r\n",
      "[08:42:53] Progress step 190000/300000 — loss 0.0026840 — PSNR 25.750\r\n",
      "[08:42:53] Eval @ 190000: train_loss 0.0026840 — train_PSNR 25.750 — val_loss 0.0032751 — val_PSNR 24.848\r\n",
      "[08:42:55] Progress step 190100/300000 — loss 0.0027076 — PSNR 25.716\r\n",
      "[08:42:56] Progress step 190200/300000 — loss 0.0026840 — PSNR 25.753\r\n",
      "[08:42:58] Progress step 190300/300000 — loss 0.0026733 — PSNR 25.768\r\n",
      "[08:42:59] Progress step 190400/300000 — loss 0.0026947 — PSNR 25.734\r\n",
      "[08:43:01] Progress step 190500/300000 — loss 0.0026888 — PSNR 25.744\r\n",
      "[08:43:03] Progress step 190600/300000 — loss 0.0026786 — PSNR 25.761\r\n",
      "[08:43:04] Progress step 190700/300000 — loss 0.0026787 — PSNR 25.761\r\n",
      "[08:43:06] Progress step 190800/300000 — loss 0.0026689 — PSNR 25.775\r\n",
      "[08:43:07] Progress step 190900/300000 — loss 0.0026679 — PSNR 25.777\r\n",
      "[08:43:09] Progress step 191000/300000 — loss 0.0026727 — PSNR 25.769\r\n",
      "[08:43:28] Eval @ 191000: train_loss 0.0026727 — train_PSNR 25.769 — val_loss 0.0026459 — val_PSNR 26.401\r\n",
      "[08:43:28] Saved best model at step 191000\r\n",
      "[08:43:29] Progress step 191100/300000 — loss 0.0027162 — PSNR 25.709\r\n",
      "[08:43:31] Progress step 191200/300000 — loss 0.0026864 — PSNR 25.750\r\n",
      "[08:43:32] Progress step 191300/300000 — loss 0.0026646 — PSNR 25.790\r\n",
      "[08:43:34] Progress step 191400/300000 — loss 0.0026604 — PSNR 25.798\r\n",
      "[08:43:36] Progress step 191500/300000 — loss 0.0026505 — PSNR 25.813\r\n",
      "[08:43:37] Progress step 191600/300000 — loss 0.0026564 — PSNR 25.801\r\n",
      "[08:43:39] Progress step 191700/300000 — loss 0.0026560 — PSNR 25.803\r\n",
      "[08:43:40] Progress step 191800/300000 — loss 0.0026560 — PSNR 25.802\r\n",
      "[08:43:42] Progress step 191900/300000 — loss 0.0026617 — PSNR 25.793\r\n",
      "[08:43:44] Progress step 192000/300000 — loss 0.0026651 — PSNR 25.786\r\n",
      "[08:43:44] Eval @ 192000: train_loss 0.0026651 — train_PSNR 25.786 — val_loss 0.0032789 — val_PSNR 24.843\r\n",
      "[08:43:45] Progress step 192100/300000 — loss 0.0027004 — PSNR 25.726\r\n",
      "[08:43:47] Progress step 192200/300000 — loss 0.0026977 — PSNR 25.726\r\n",
      "[08:43:48] Progress step 192300/300000 — loss 0.0027129 — PSNR 25.706\r\n",
      "[08:43:50] Progress step 192400/300000 — loss 0.0026938 — PSNR 25.738\r\n",
      "[08:43:52] Progress step 192500/300000 — loss 0.0026997 — PSNR 25.729\r\n",
      "[08:43:53] Progress step 192600/300000 — loss 0.0027022 — PSNR 25.723\r\n",
      "[08:43:55] Progress step 192700/300000 — loss 0.0026983 — PSNR 25.731\r\n",
      "[08:43:56] Progress step 192800/300000 — loss 0.0026894 — PSNR 25.746\r\n",
      "[08:43:58] Progress step 192900/300000 — loss 0.0026849 — PSNR 25.752\r\n",
      "[08:44:00] Progress step 193000/300000 — loss 0.0026817 — PSNR 25.758\r\n",
      "[08:44:18] Eval @ 193000: train_loss 0.0026817 — train_PSNR 25.758 — val_loss 0.0026555 — val_PSNR 26.380\r\n",
      "[08:44:20] Progress step 193100/300000 — loss 0.0026404 — PSNR 25.826\r\n",
      "[08:44:21] Progress step 193200/300000 — loss 0.0026438 — PSNR 25.820\r\n",
      "[08:44:23] Progress step 193300/300000 — loss 0.0026754 — PSNR 25.768\r\n",
      "[08:44:25] Progress step 193400/300000 — loss 0.0026798 — PSNR 25.761\r\n",
      "[08:44:26] Progress step 193500/300000 — loss 0.0026860 — PSNR 25.752\r\n",
      "[08:44:28] Progress step 193600/300000 — loss 0.0026820 — PSNR 25.759\r\n",
      "[08:44:29] Progress step 193700/300000 — loss 0.0026780 — PSNR 25.766\r\n",
      "[08:44:31] Progress step 193800/300000 — loss 0.0026753 — PSNR 25.770\r\n",
      "[08:44:33] Progress step 193900/300000 — loss 0.0026726 — PSNR 25.775\r\n",
      "[08:44:34] Progress step 194000/300000 — loss 0.0026752 — PSNR 25.771\r\n",
      "[08:44:34] Eval @ 194000: train_loss 0.0026752 — train_PSNR 25.771 — val_loss 0.0032859 — val_PSNR 24.833\r\n",
      "[08:44:36] Progress step 194100/300000 — loss 0.0027364 — PSNR 25.675\r\n",
      "[08:44:37] Progress step 194200/300000 — loss 0.0026911 — PSNR 25.752\r\n",
      "[08:44:39] Progress step 194300/300000 — loss 0.0026936 — PSNR 25.747\r\n",
      "[08:44:41] Progress step 194400/300000 — loss 0.0026899 — PSNR 25.751\r\n",
      "[08:44:42] Progress step 194500/300000 — loss 0.0026806 — PSNR 25.763\r\n",
      "[08:44:44] Progress step 194600/300000 — loss 0.0026779 — PSNR 25.766\r\n",
      "[08:44:45] Progress step 194700/300000 — loss 0.0026890 — PSNR 25.750\r\n",
      "[08:44:47] Progress step 194800/300000 — loss 0.0026882 — PSNR 25.752\r\n",
      "[08:44:49] Progress step 194900/300000 — loss 0.0026906 — PSNR 25.747\r\n",
      "[08:44:50] Progress step 195000/300000 — loss 0.0026862 — PSNR 25.754\r\n",
      "[08:45:09] Eval @ 195000: train_loss 0.0026862 — train_PSNR 25.754 — val_loss 0.0026488 — val_PSNR 26.395\r\n",
      "[08:45:11] Progress step 195100/300000 — loss 0.0026389 — PSNR 25.830\r\n",
      "[08:45:12] Progress step 195200/300000 — loss 0.0026877 — PSNR 25.755\r\n",
      "[08:45:14] Progress step 195300/300000 — loss 0.0026838 — PSNR 25.758\r\n",
      "[08:45:15] Progress step 195400/300000 — loss 0.0026851 — PSNR 25.757\r\n",
      "[08:45:17] Progress step 195500/300000 — loss 0.0026722 — PSNR 25.778\r\n",
      "[08:45:18] Progress step 195600/300000 — loss 0.0026709 — PSNR 25.779\r\n",
      "[08:45:20] Progress step 195700/300000 — loss 0.0026635 — PSNR 25.790\r\n",
      "[08:45:22] Progress step 195800/300000 — loss 0.0026754 — PSNR 25.771\r\n",
      "[08:45:23] Progress step 195900/300000 — loss 0.0026728 — PSNR 25.774\r\n",
      "[08:45:25] Progress step 196000/300000 — loss 0.0026670 — PSNR 25.782\r\n",
      "[08:45:25] Eval @ 196000: train_loss 0.0026670 — train_PSNR 25.782 — val_loss 0.0032872 — val_PSNR 24.832\r\n",
      "[08:45:26] Progress step 196100/300000 — loss 0.0026784 — PSNR 25.756\r\n",
      "[08:45:28] Progress step 196200/300000 — loss 0.0026764 — PSNR 25.762\r\n",
      "[08:45:30] Progress step 196300/300000 — loss 0.0026852 — PSNR 25.749\r\n",
      "[08:45:31] Progress step 196400/300000 — loss 0.0026793 — PSNR 25.760\r\n",
      "[08:45:33] Progress step 196500/300000 — loss 0.0026701 — PSNR 25.777\r\n",
      "[08:45:35] Progress step 196600/300000 — loss 0.0026806 — PSNR 25.762\r\n",
      "[08:45:36] Progress step 196700/300000 — loss 0.0026761 — PSNR 25.770\r\n",
      "[08:45:38] Progress step 196800/300000 — loss 0.0026790 — PSNR 25.766\r\n",
      "[08:45:39] Progress step 196900/300000 — loss 0.0026843 — PSNR 25.757\r\n",
      "[08:45:41] Progress step 197000/300000 — loss 0.0026795 — PSNR 25.765\r\n",
      "[08:45:59] Eval @ 197000: train_loss 0.0026795 — train_PSNR 25.765 — val_loss 0.0026713 — val_PSNR 26.347\r\n",
      "[08:46:01] Progress step 197100/300000 — loss 0.0026515 — PSNR 25.800\r\n",
      "[08:46:03] Progress step 197200/300000 — loss 0.0026850 — PSNR 25.750\r\n",
      "[08:46:04] Progress step 197300/300000 — loss 0.0026846 — PSNR 25.748\r\n",
      "[08:46:06] Progress step 197400/300000 — loss 0.0026828 — PSNR 25.751\r\n",
      "[08:46:08] Progress step 197500/300000 — loss 0.0026880 — PSNR 25.745\r\n",
      "[08:46:09] Progress step 197600/300000 — loss 0.0026819 — PSNR 25.754\r\n",
      "[08:46:11] Progress step 197700/300000 — loss 0.0026788 — PSNR 25.760\r\n",
      "[08:46:12] Progress step 197800/300000 — loss 0.0026808 — PSNR 25.757\r\n",
      "[08:46:14] Progress step 197900/300000 — loss 0.0026824 — PSNR 25.754\r\n",
      "[08:46:15] Progress step 198000/300000 — loss 0.0026773 — PSNR 25.762\r\n",
      "[08:46:15] Eval @ 198000: train_loss 0.0026773 — train_PSNR 25.762 — val_loss 0.0033023 — val_PSNR 24.812\r\n",
      "[08:46:17] Progress step 198100/300000 — loss 0.0026963 — PSNR 25.739\r\n",
      "[08:46:19] Progress step 198200/300000 — loss 0.0027061 — PSNR 25.716\r\n",
      "[08:46:20] Progress step 198300/300000 — loss 0.0026855 — PSNR 25.750\r\n",
      "[08:46:22] Progress step 198400/300000 — loss 0.0026777 — PSNR 25.762\r\n",
      "[08:46:23] Progress step 198500/300000 — loss 0.0026807 — PSNR 25.756\r\n",
      "[08:46:25] Progress step 198600/300000 — loss 0.0026764 — PSNR 25.762\r\n",
      "[08:46:27] Progress step 198700/300000 — loss 0.0026834 — PSNR 25.752\r\n",
      "[08:46:28] Progress step 198800/300000 — loss 0.0026773 — PSNR 25.761\r\n",
      "[08:46:30] Progress step 198900/300000 — loss 0.0026830 — PSNR 25.754\r\n",
      "[08:46:31] Progress step 199000/300000 — loss 0.0026854 — PSNR 25.749\r\n",
      "[08:46:50] Eval @ 199000: train_loss 0.0026854 — train_PSNR 25.749 — val_loss 0.0026460 — val_PSNR 26.401\r\n",
      "[08:46:52] Progress step 199100/300000 — loss 0.0026232 — PSNR 25.853\r\n",
      "[08:46:53] Progress step 199200/300000 — loss 0.0026442 — PSNR 25.820\r\n",
      "[08:46:55] Progress step 199300/300000 — loss 0.0026554 — PSNR 25.801\r\n",
      "[08:46:56] Progress step 199400/300000 — loss 0.0026608 — PSNR 25.791\r\n",
      "[08:46:58] Progress step 199500/300000 — loss 0.0026684 — PSNR 25.778\r\n",
      "[08:47:00] Progress step 199600/300000 — loss 0.0026706 — PSNR 25.775\r\n",
      "[08:47:01] Progress step 199700/300000 — loss 0.0026583 — PSNR 25.795\r\n",
      "[08:47:03] Progress step 199800/300000 — loss 0.0026674 — PSNR 25.781\r\n",
      "[08:47:04] Progress step 199900/300000 — loss 0.0026662 — PSNR 25.783\r\n",
      "[08:47:06] Progress step 200000/300000 — loss 0.0026659 — PSNR 25.783\r\n",
      "[08:47:06] Eval @ 200000: train_loss 0.0026659 — train_PSNR 25.783 — val_loss 0.0032899 — val_PSNR 24.828\r\n",
      "[08:47:08] Progress step 200100/300000 — loss 0.0026871 — PSNR 25.749\r\n",
      "[08:47:09] Progress step 200200/300000 — loss 0.0026843 — PSNR 25.752\r\n",
      "[08:47:11] Progress step 200300/300000 — loss 0.0026804 — PSNR 25.760\r\n",
      "[08:47:12] Progress step 200400/300000 — loss 0.0026835 — PSNR 25.754\r\n",
      "[08:47:14] Progress step 200500/300000 — loss 0.0026925 — PSNR 25.739\r\n",
      "[08:47:15] Progress step 200600/300000 — loss 0.0026980 — PSNR 25.730\r\n",
      "[08:47:17] Progress step 200700/300000 — loss 0.0026905 — PSNR 25.742\r\n",
      "[08:47:19] Progress step 200800/300000 — loss 0.0026912 — PSNR 25.741\r\n",
      "[08:47:20] Progress step 200900/300000 — loss 0.0026882 — PSNR 25.746\r\n",
      "[08:47:22] Progress step 201000/300000 — loss 0.0026883 — PSNR 25.746\r\n",
      "[08:47:40] Eval @ 201000: train_loss 0.0026883 — train_PSNR 25.746 — val_loss 0.0026502 — val_PSNR 26.392\r\n",
      "[08:47:42] Progress step 201100/300000 — loss 0.0026867 — PSNR 25.757\r\n",
      "[08:47:44] Progress step 201200/300000 — loss 0.0026894 — PSNR 25.743\r\n",
      "[08:47:45] Progress step 201300/300000 — loss 0.0026749 — PSNR 25.766\r\n",
      "[08:47:47] Progress step 201400/300000 — loss 0.0026604 — PSNR 25.790\r\n",
      "[08:47:48] Progress step 201500/300000 — loss 0.0026615 — PSNR 25.787\r\n",
      "[08:47:50] Progress step 201600/300000 — loss 0.0026598 — PSNR 25.789\r\n",
      "[08:47:52] Progress step 201700/300000 — loss 0.0026594 — PSNR 25.792\r\n",
      "[08:47:53] Progress step 201800/300000 — loss 0.0026538 — PSNR 25.801\r\n",
      "[08:47:55] Progress step 201900/300000 — loss 0.0026552 — PSNR 25.800\r\n",
      "[08:47:56] Progress step 202000/300000 — loss 0.0026577 — PSNR 25.797\r\n",
      "[08:47:56] Eval @ 202000: train_loss 0.0026577 — train_PSNR 25.797 — val_loss 0.0032977 — val_PSNR 24.818\r\n",
      "[08:47:58] Progress step 202100/300000 — loss 0.0026910 — PSNR 25.736\r\n",
      "[08:48:00] Progress step 202200/300000 — loss 0.0026802 — PSNR 25.759\r\n",
      "[08:48:01] Progress step 202300/300000 — loss 0.0026933 — PSNR 25.739\r\n",
      "[08:48:03] Progress step 202400/300000 — loss 0.0026825 — PSNR 25.757\r\n",
      "[08:48:04] Progress step 202500/300000 — loss 0.0026843 — PSNR 25.755\r\n",
      "[08:48:06] Progress step 202600/300000 — loss 0.0026784 — PSNR 25.764\r\n",
      "[08:48:08] Progress step 202700/300000 — loss 0.0026772 — PSNR 25.764\r\n",
      "[08:48:09] Progress step 202800/300000 — loss 0.0026730 — PSNR 25.771\r\n",
      "[08:48:11] Progress step 202900/300000 — loss 0.0026737 — PSNR 25.769\r\n",
      "[08:48:12] Progress step 203000/300000 — loss 0.0026741 — PSNR 25.770\r\n",
      "[08:48:31] Eval @ 203000: train_loss 0.0026741 — train_PSNR 25.770 — val_loss 0.0026478 — val_PSNR 26.397\r\n",
      "[08:48:33] Progress step 203100/300000 — loss 0.0026645 — PSNR 25.774\r\n",
      "[08:48:34] Progress step 203200/300000 — loss 0.0026914 — PSNR 25.734\r\n",
      "[08:48:36] Progress step 203300/300000 — loss 0.0026926 — PSNR 25.733\r\n",
      "[08:48:37] Progress step 203400/300000 — loss 0.0026953 — PSNR 25.730\r\n",
      "[08:48:39] Progress step 203500/300000 — loss 0.0026951 — PSNR 25.732\r\n",
      "[08:48:40] Progress step 203600/300000 — loss 0.0026890 — PSNR 25.744\r\n",
      "[08:48:42] Progress step 203700/300000 — loss 0.0026853 — PSNR 25.749\r\n",
      "[08:48:44] Progress step 203800/300000 — loss 0.0026886 — PSNR 25.744\r\n",
      "[08:48:45] Progress step 203900/300000 — loss 0.0026878 — PSNR 25.747\r\n",
      "[08:48:47] Progress step 204000/300000 — loss 0.0026893 — PSNR 25.744\r\n",
      "[08:48:47] Eval @ 204000: train_loss 0.0026893 — train_PSNR 25.744 — val_loss 0.0032782 — val_PSNR 24.844\r\n",
      "[08:48:48] Progress step 204100/300000 — loss 0.0027062 — PSNR 25.707\r\n",
      "[08:48:50] Progress step 204200/300000 — loss 0.0026800 — PSNR 25.752\r\n",
      "[08:48:52] Progress step 204300/300000 — loss 0.0026955 — PSNR 25.729\r\n",
      "[08:48:53] Progress step 204400/300000 — loss 0.0026983 — PSNR 25.725\r\n",
      "[08:48:55] Progress step 204500/300000 — loss 0.0026948 — PSNR 25.734\r\n",
      "[08:48:56] Progress step 204600/300000 — loss 0.0026942 — PSNR 25.736\r\n",
      "[08:48:58] Progress step 204700/300000 — loss 0.0026924 — PSNR 25.738\r\n",
      "[08:49:00] Progress step 204800/300000 — loss 0.0026878 — PSNR 25.745\r\n",
      "[08:49:01] Progress step 204900/300000 — loss 0.0026853 — PSNR 25.750\r\n",
      "[08:49:03] Progress step 205000/300000 — loss 0.0026896 — PSNR 25.743\r\n",
      "[08:49:21] Eval @ 205000: train_loss 0.0026896 — train_PSNR 25.743 — val_loss 0.0026488 — val_PSNR 26.395\r\n",
      "[08:49:23] Progress step 205100/300000 — loss 0.0026693 — PSNR 25.787\r\n",
      "[08:49:25] Progress step 205200/300000 — loss 0.0026862 — PSNR 25.757\r\n",
      "[08:49:26] Progress step 205300/300000 — loss 0.0026962 — PSNR 25.739\r\n",
      "[08:49:28] Progress step 205400/300000 — loss 0.0026857 — PSNR 25.754\r\n",
      "[08:49:29] Progress step 205500/300000 — loss 0.0026949 — PSNR 25.739\r\n",
      "[08:49:31] Progress step 205600/300000 — loss 0.0026907 — PSNR 25.746\r\n",
      "[08:49:32] Progress step 205700/300000 — loss 0.0026942 — PSNR 25.738\r\n",
      "[08:49:34] Progress step 205800/300000 — loss 0.0026932 — PSNR 25.740\r\n",
      "[08:49:36] Progress step 205900/300000 — loss 0.0026938 — PSNR 25.740\r\n",
      "[08:49:37] Progress step 206000/300000 — loss 0.0026922 — PSNR 25.742\r\n",
      "[08:49:37] Eval @ 206000: train_loss 0.0026922 — train_PSNR 25.742 — val_loss 0.0032806 — val_PSNR 24.840\r\n",
      "[08:49:39] Progress step 206100/300000 — loss 0.0027284 — PSNR 25.682\r\n",
      "[08:49:41] Progress step 206200/300000 — loss 0.0026947 — PSNR 25.732\r\n",
      "[08:49:42] Progress step 206300/300000 — loss 0.0026898 — PSNR 25.743\r\n",
      "[08:49:44] Progress step 206400/300000 — loss 0.0026898 — PSNR 25.744\r\n",
      "[08:49:45] Progress step 206500/300000 — loss 0.0026853 — PSNR 25.751\r\n",
      "[08:49:47] Progress step 206600/300000 — loss 0.0026969 — PSNR 25.733\r\n",
      "[08:49:49] Progress step 206700/300000 — loss 0.0026956 — PSNR 25.737\r\n",
      "[08:49:50] Progress step 206800/300000 — loss 0.0026949 — PSNR 25.738\r\n",
      "[08:49:52] Progress step 206900/300000 — loss 0.0026938 — PSNR 25.739\r\n",
      "[08:49:53] Progress step 207000/300000 — loss 0.0026880 — PSNR 25.748\r\n",
      "[08:50:12] Eval @ 207000: train_loss 0.0026880 — train_PSNR 25.748 — val_loss 0.0026501 — val_PSNR 26.392\r\n",
      "[08:50:14] Progress step 207100/300000 — loss 0.0026635 — PSNR 25.784\r\n",
      "[08:50:15] Progress step 207200/300000 — loss 0.0026684 — PSNR 25.776\r\n",
      "[08:50:17] Progress step 207300/300000 — loss 0.0026605 — PSNR 25.787\r\n",
      "[08:50:18] Progress step 207400/300000 — loss 0.0026642 — PSNR 25.783\r\n",
      "[08:50:20] Progress step 207500/300000 — loss 0.0026754 — PSNR 25.767\r\n",
      "[08:50:22] Progress step 207600/300000 — loss 0.0026696 — PSNR 25.774\r\n",
      "[08:50:23] Progress step 207700/300000 — loss 0.0026649 — PSNR 25.782\r\n",
      "[08:50:25] Progress step 207800/300000 — loss 0.0026741 — PSNR 25.767\r\n",
      "[08:50:26] Progress step 207900/300000 — loss 0.0026769 — PSNR 25.765\r\n",
      "[08:50:28] Progress step 208000/300000 — loss 0.0026750 — PSNR 25.768\r\n",
      "[08:50:28] Eval @ 208000: train_loss 0.0026750 — train_PSNR 25.768 — val_loss 0.0032781 — val_PSNR 24.844\r\n",
      "[08:50:30] Progress step 208100/300000 — loss 0.0026859 — PSNR 25.748\r\n",
      "[08:50:31] Progress step 208200/300000 — loss 0.0026622 — PSNR 25.787\r\n",
      "[08:50:33] Progress step 208300/300000 — loss 0.0026477 — PSNR 25.811\r\n",
      "[08:50:34] Progress step 208400/300000 — loss 0.0026557 — PSNR 25.801\r\n",
      "[08:50:36] Progress step 208500/300000 — loss 0.0026493 — PSNR 25.812\r\n",
      "[08:50:38] Progress step 208600/300000 — loss 0.0026506 — PSNR 25.810\r\n",
      "[08:50:39] Progress step 208700/300000 — loss 0.0026569 — PSNR 25.801\r\n",
      "[08:50:41] Progress step 208800/300000 — loss 0.0026684 — PSNR 25.781\r\n",
      "[08:50:42] Progress step 208900/300000 — loss 0.0026679 — PSNR 25.782\r\n",
      "[08:50:44] Progress step 209000/300000 — loss 0.0026661 — PSNR 25.783\r\n",
      "[08:51:03] Eval @ 209000: train_loss 0.0026661 — train_PSNR 25.783 — val_loss 0.0026477 — val_PSNR 26.397\r\n",
      "[08:51:04] Progress step 209100/300000 — loss 0.0026770 — PSNR 25.769\r\n",
      "[08:51:06] Progress step 209200/300000 — loss 0.0026723 — PSNR 25.772\r\n",
      "[08:51:08] Progress step 209300/300000 — loss 0.0026755 — PSNR 25.767\r\n",
      "[08:51:09] Progress step 209400/300000 — loss 0.0026682 — PSNR 25.780\r\n",
      "[08:51:11] Progress step 209500/300000 — loss 0.0026686 — PSNR 25.780\r\n",
      "[08:51:13] Progress step 209600/300000 — loss 0.0026641 — PSNR 25.786\r\n",
      "[08:51:14] Progress step 209700/300000 — loss 0.0026741 — PSNR 25.770\r\n",
      "[08:51:16] Progress step 209800/300000 — loss 0.0026708 — PSNR 25.776\r\n",
      "[08:51:17] Progress step 209900/300000 — loss 0.0026762 — PSNR 25.766\r\n",
      "[08:51:19] Progress step 210000/300000 — loss 0.0026743 — PSNR 25.769\r\n",
      "[08:51:19] Eval @ 210000: train_loss 0.0026743 — train_PSNR 25.769 — val_loss 0.0032765 — val_PSNR 24.846\r\n",
      "[08:51:20] Progress step 210100/300000 — loss 0.0026828 — PSNR 25.761\r\n",
      "[08:51:22] Progress step 210200/300000 — loss 0.0026841 — PSNR 25.755\r\n",
      "[08:51:24] Progress step 210300/300000 — loss 0.0027122 — PSNR 25.710\r\n",
      "[08:51:25] Progress step 210400/300000 — loss 0.0027069 — PSNR 25.716\r\n",
      "[08:51:27] Progress step 210500/300000 — loss 0.0027061 — PSNR 25.719\r\n",
      "[08:51:28] Progress step 210600/300000 — loss 0.0027032 — PSNR 25.724\r\n",
      "[08:51:30] Progress step 210700/300000 — loss 0.0027044 — PSNR 25.722\r\n",
      "[08:51:32] Progress step 210800/300000 — loss 0.0027006 — PSNR 25.728\r\n",
      "[08:51:33] Progress step 210900/300000 — loss 0.0027043 — PSNR 25.721\r\n",
      "[08:51:35] Progress step 211000/300000 — loss 0.0027036 — PSNR 25.722\r\n",
      "[08:51:54] Eval @ 211000: train_loss 0.0027036 — train_PSNR 25.722 — val_loss 0.0026507 — val_PSNR 26.391\r\n",
      "[08:51:55] Progress step 211100/300000 — loss 0.0027269 — PSNR 25.678\r\n",
      "[08:51:57] Progress step 211200/300000 — loss 0.0027359 — PSNR 25.668\r\n",
      "[08:51:59] Progress step 211300/300000 — loss 0.0027083 — PSNR 25.715\r\n",
      "[08:52:00] Progress step 211400/300000 — loss 0.0027121 — PSNR 25.709\r\n",
      "[08:52:02] Progress step 211500/300000 — loss 0.0027165 — PSNR 25.700\r\n",
      "[08:52:03] Progress step 211600/300000 — loss 0.0027204 — PSNR 25.694\r\n",
      "[08:52:05] Progress step 211700/300000 — loss 0.0027059 — PSNR 25.717\r\n",
      "[08:52:07] Progress step 211800/300000 — loss 0.0027086 — PSNR 25.712\r\n",
      "[08:52:08] Progress step 211900/300000 — loss 0.0027035 — PSNR 25.721\r\n",
      "[08:52:10] Progress step 212000/300000 — loss 0.0027025 — PSNR 25.723\r\n",
      "[08:52:10] Eval @ 212000: train_loss 0.0027025 — train_PSNR 25.723 — val_loss 0.0032843 — val_PSNR 24.836\r\n",
      "[08:52:11] Progress step 212100/300000 — loss 0.0026795 — PSNR 25.761\r\n",
      "[08:52:13] Progress step 212200/300000 — loss 0.0026941 — PSNR 25.738\r\n",
      "[08:52:15] Progress step 212300/300000 — loss 0.0027109 — PSNR 25.711\r\n",
      "[08:52:16] Progress step 212400/300000 — loss 0.0026994 — PSNR 25.729\r\n",
      "[08:52:18] Progress step 212500/300000 — loss 0.0026867 — PSNR 25.749\r\n",
      "[08:52:19] Progress step 212600/300000 — loss 0.0026815 — PSNR 25.758\r\n",
      "[08:52:21] Progress step 212700/300000 — loss 0.0026838 — PSNR 25.753\r\n",
      "[08:52:22] Progress step 212800/300000 — loss 0.0026873 — PSNR 25.748\r\n",
      "[08:52:24] Progress step 212900/300000 — loss 0.0026896 — PSNR 25.744\r\n",
      "[08:52:26] Progress step 213000/300000 — loss 0.0026871 — PSNR 25.748\r\n",
      "[08:52:44] Eval @ 213000: train_loss 0.0026871 — train_PSNR 25.748 — val_loss 0.0026490 — val_PSNR 26.394\r\n",
      "[08:52:46] Progress step 213100/300000 — loss 0.0026305 — PSNR 25.842\r\n",
      "[08:52:48] Progress step 213200/300000 — loss 0.0027070 — PSNR 25.722\r\n",
      "[08:52:49] Progress step 213300/300000 — loss 0.0027059 — PSNR 25.725\r\n",
      "[08:52:51] Progress step 213400/300000 — loss 0.0026975 — PSNR 25.737\r\n",
      "[08:52:52] Progress step 213500/300000 — loss 0.0026992 — PSNR 25.735\r\n",
      "[08:52:54] Progress step 213600/300000 — loss 0.0026889 — PSNR 25.751\r\n",
      "[08:52:56] Progress step 213700/300000 — loss 0.0026963 — PSNR 25.740\r\n",
      "[08:52:57] Progress step 213800/300000 — loss 0.0027021 — PSNR 25.729\r\n",
      "[08:52:59] Progress step 213900/300000 — loss 0.0027042 — PSNR 25.725\r\n",
      "[08:53:00] Progress step 214000/300000 — loss 0.0027044 — PSNR 25.724\r\n",
      "[08:53:00] Eval @ 214000: train_loss 0.0027044 — train_PSNR 25.724 — val_loss 0.0032772 — val_PSNR 24.845\r\n",
      "[08:53:02] Progress step 214100/300000 — loss 0.0026386 — PSNR 25.835\r\n",
      "[08:53:04] Progress step 214200/300000 — loss 0.0026904 — PSNR 25.744\r\n",
      "[08:53:05] Progress step 214300/300000 — loss 0.0026848 — PSNR 25.757\r\n",
      "[08:53:07] Progress step 214400/300000 — loss 0.0026891 — PSNR 25.750\r\n",
      "[08:53:08] Progress step 214500/300000 — loss 0.0026865 — PSNR 25.752\r\n",
      "[08:53:10] Progress step 214600/300000 — loss 0.0026838 — PSNR 25.756\r\n",
      "[08:53:12] Progress step 214700/300000 — loss 0.0026862 — PSNR 25.751\r\n",
      "[08:53:13] Progress step 214800/300000 — loss 0.0026884 — PSNR 25.746\r\n",
      "[08:53:15] Progress step 214900/300000 — loss 0.0026852 — PSNR 25.752\r\n",
      "[08:53:16] Progress step 215000/300000 — loss 0.0026842 — PSNR 25.753\r\n",
      "[08:53:35] Eval @ 215000: train_loss 0.0026842 — train_PSNR 25.753 — val_loss 0.0026516 — val_PSNR 26.389\r\n",
      "[08:53:37] Progress step 215100/300000 — loss 0.0027011 — PSNR 25.726\r\n",
      "[08:53:39] Progress step 215200/300000 — loss 0.0026985 — PSNR 25.729\r\n",
      "[08:53:40] Progress step 215300/300000 — loss 0.0027014 — PSNR 25.723\r\n",
      "[08:53:42] Progress step 215400/300000 — loss 0.0026789 — PSNR 25.761\r\n",
      "[08:53:43] Progress step 215500/300000 — loss 0.0026887 — PSNR 25.746\r\n",
      "[08:53:45] Progress step 215600/300000 — loss 0.0026950 — PSNR 25.735\r\n",
      "[08:53:46] Progress step 215700/300000 — loss 0.0026962 — PSNR 25.734\r\n",
      "[08:53:48] Progress step 215800/300000 — loss 0.0026956 — PSNR 25.735\r\n",
      "[08:53:50] Progress step 215900/300000 — loss 0.0027016 — PSNR 25.726\r\n",
      "[08:53:51] Progress step 216000/300000 — loss 0.0027026 — PSNR 25.724\r\n",
      "[08:53:51] Eval @ 216000: train_loss 0.0027026 — train_PSNR 25.724 — val_loss 0.0032774 — val_PSNR 24.845\r\n",
      "[08:53:53] Progress step 216100/300000 — loss 0.0026864 — PSNR 25.738\r\n",
      "[08:53:54] Progress step 216200/300000 — loss 0.0026759 — PSNR 25.758\r\n",
      "[08:53:56] Progress step 216300/300000 — loss 0.0026742 — PSNR 25.763\r\n",
      "[08:53:58] Progress step 216400/300000 — loss 0.0026785 — PSNR 25.756\r\n",
      "[08:53:59] Progress step 216500/300000 — loss 0.0026828 — PSNR 25.750\r\n",
      "[08:54:01] Progress step 216600/300000 — loss 0.0026834 — PSNR 25.748\r\n",
      "[08:54:02] Progress step 216700/300000 — loss 0.0026746 — PSNR 25.762\r\n",
      "[08:54:04] Progress step 216800/300000 — loss 0.0026650 — PSNR 25.780\r\n",
      "[08:54:06] Progress step 216900/300000 — loss 0.0026663 — PSNR 25.778\r\n",
      "[08:54:07] Progress step 217000/300000 — loss 0.0026727 — PSNR 25.769\r\n",
      "[08:54:26] Eval @ 217000: train_loss 0.0026727 — train_PSNR 25.769 — val_loss 0.0026472 — val_PSNR 26.398\r\n",
      "[08:54:27] Progress step 217100/300000 — loss 0.0027258 — PSNR 25.680\r\n",
      "[08:54:29] Progress step 217200/300000 — loss 0.0027076 — PSNR 25.711\r\n",
      "[08:54:31] Progress step 217300/300000 — loss 0.0027229 — PSNR 25.686\r\n",
      "[08:54:32] Progress step 217400/300000 — loss 0.0027046 — PSNR 25.715\r\n",
      "[08:54:34] Progress step 217500/300000 — loss 0.0026991 — PSNR 25.725\r\n",
      "[08:54:35] Progress step 217600/300000 — loss 0.0026953 — PSNR 25.731\r\n",
      "[08:54:37] Progress step 217700/300000 — loss 0.0026931 — PSNR 25.735\r\n",
      "[08:54:39] Progress step 217800/300000 — loss 0.0026925 — PSNR 25.736\r\n",
      "[08:54:40] Progress step 217900/300000 — loss 0.0026979 — PSNR 25.727\r\n",
      "[08:54:42] Progress step 218000/300000 — loss 0.0026950 — PSNR 25.732\r\n",
      "[08:54:42] Eval @ 218000: train_loss 0.0026950 — train_PSNR 25.732 — val_loss 0.0032920 — val_PSNR 24.825\r\n",
      "[08:54:43] Progress step 218100/300000 — loss 0.0026758 — PSNR 25.768\r\n",
      "[08:54:45] Progress step 218200/300000 — loss 0.0026706 — PSNR 25.770\r\n",
      "[08:54:47] Progress step 218300/300000 — loss 0.0026748 — PSNR 25.768\r\n",
      "[08:54:48] Progress step 218400/300000 — loss 0.0026866 — PSNR 25.748\r\n",
      "[08:54:50] Progress step 218500/300000 — loss 0.0026812 — PSNR 25.758\r\n",
      "[08:54:51] Progress step 218600/300000 — loss 0.0026839 — PSNR 25.753\r\n",
      "[08:54:53] Progress step 218700/300000 — loss 0.0026888 — PSNR 25.746\r\n",
      "[08:54:55] Progress step 218800/300000 — loss 0.0026912 — PSNR 25.742\r\n",
      "[08:54:56] Progress step 218900/300000 — loss 0.0026974 — PSNR 25.732\r\n",
      "[08:54:58] Progress step 219000/300000 — loss 0.0026941 — PSNR 25.738\r\n",
      "[08:55:17] Eval @ 219000: train_loss 0.0026941 — train_PSNR 25.738 — val_loss 0.0026498 — val_PSNR 26.393\r\n",
      "[08:55:18] Progress step 219100/300000 — loss 0.0026047 — PSNR 25.875\r\n",
      "[08:55:20] Progress step 219200/300000 — loss 0.0026404 — PSNR 25.820\r\n",
      "[08:55:22] Progress step 219300/300000 — loss 0.0026527 — PSNR 25.801\r\n",
      "[08:55:23] Progress step 219400/300000 — loss 0.0026645 — PSNR 25.784\r\n",
      "[08:55:25] Progress step 219500/300000 — loss 0.0026588 — PSNR 25.792\r\n",
      "[08:55:26] Progress step 219600/300000 — loss 0.0026489 — PSNR 25.808\r\n",
      "[08:55:28] Progress step 219700/300000 — loss 0.0026569 — PSNR 25.796\r\n",
      "[08:55:30] Progress step 219800/300000 — loss 0.0026661 — PSNR 25.783\r\n",
      "[08:55:31] Progress step 219900/300000 — loss 0.0026642 — PSNR 25.786\r\n",
      "[08:55:33] Progress step 220000/300000 — loss 0.0026691 — PSNR 25.778\r\n",
      "[08:55:33] Eval @ 220000: train_loss 0.0026691 — train_PSNR 25.778 — val_loss 0.0032942 — val_PSNR 24.823\r\n",
      "[08:55:34] Progress step 220100/300000 — loss 0.0026652 — PSNR 25.800\r\n",
      "[08:55:36] Progress step 220200/300000 — loss 0.0026525 — PSNR 25.809\r\n",
      "[08:55:38] Progress step 220300/300000 — loss 0.0026693 — PSNR 25.780\r\n",
      "[08:55:39] Progress step 220400/300000 — loss 0.0026783 — PSNR 25.765\r\n",
      "[08:55:41] Progress step 220500/300000 — loss 0.0026822 — PSNR 25.758\r\n",
      "[08:55:42] Progress step 220600/300000 — loss 0.0026862 — PSNR 25.751\r\n",
      "[08:55:44] Progress step 220700/300000 — loss 0.0026872 — PSNR 25.750\r\n",
      "[08:55:46] Progress step 220800/300000 — loss 0.0026766 — PSNR 25.766\r\n",
      "[08:55:47] Progress step 220900/300000 — loss 0.0026762 — PSNR 25.768\r\n",
      "[08:55:49] Progress step 221000/300000 — loss 0.0026807 — PSNR 25.760\r\n",
      "[08:56:07] Eval @ 221000: train_loss 0.0026807 — train_PSNR 25.760 — val_loss 0.0026474 — val_PSNR 26.398\r\n",
      "[08:56:09] Progress step 221100/300000 — loss 0.0026491 — PSNR 25.823\r\n",
      "[08:56:11] Progress step 221200/300000 — loss 0.0026506 — PSNR 25.815\r\n",
      "[08:56:12] Progress step 221300/300000 — loss 0.0026630 — PSNR 25.795\r\n",
      "[08:56:14] Progress step 221400/300000 — loss 0.0026605 — PSNR 25.795\r\n",
      "[08:56:15] Progress step 221500/300000 — loss 0.0026515 — PSNR 25.808\r\n",
      "[08:56:17] Progress step 221600/300000 — loss 0.0026580 — PSNR 25.799\r\n",
      "[08:56:19] Progress step 221700/300000 — loss 0.0026614 — PSNR 25.793\r\n",
      "[08:56:20] Progress step 221800/300000 — loss 0.0026697 — PSNR 25.779\r\n",
      "[08:56:22] Progress step 221900/300000 — loss 0.0026688 — PSNR 25.781\r\n",
      "[08:56:23] Progress step 222000/300000 — loss 0.0026733 — PSNR 25.774\r\n",
      "[08:56:23] Eval @ 222000: train_loss 0.0026733 — train_PSNR 25.774 — val_loss 0.0032778 — val_PSNR 24.844\r\n",
      "[08:56:25] Progress step 222100/300000 — loss 0.0026975 — PSNR 25.728\r\n",
      "[08:56:27] Progress step 222200/300000 — loss 0.0026879 — PSNR 25.749\r\n",
      "[08:56:28] Progress step 222300/300000 — loss 0.0026929 — PSNR 25.739\r\n",
      "[08:56:30] Progress step 222400/300000 — loss 0.0026825 — PSNR 25.758\r\n",
      "[08:56:31] Progress step 222500/300000 — loss 0.0026935 — PSNR 25.739\r\n",
      "[08:56:33] Progress step 222600/300000 — loss 0.0026724 — PSNR 25.774\r\n",
      "[08:56:34] Progress step 222700/300000 — loss 0.0026657 — PSNR 25.784\r\n",
      "[08:56:36] Progress step 222800/300000 — loss 0.0026689 — PSNR 25.778\r\n",
      "[08:56:38] Progress step 222900/300000 — loss 0.0026778 — PSNR 25.765\r\n",
      "[08:56:39] Progress step 223000/300000 — loss 0.0026791 — PSNR 25.762\r\n",
      "[08:56:58] Eval @ 223000: train_loss 0.0026791 — train_PSNR 25.762 — val_loss 0.0026471 — val_PSNR 26.398\r\n",
      "[08:57:00] Progress step 223100/300000 — loss 0.0026586 — PSNR 25.785\r\n",
      "[08:57:01] Progress step 223200/300000 — loss 0.0026754 — PSNR 25.764\r\n",
      "[08:57:03] Progress step 223300/300000 — loss 0.0026758 — PSNR 25.764\r\n",
      "[08:57:04] Progress step 223400/300000 — loss 0.0026784 — PSNR 25.759\r\n",
      "[08:57:06] Progress step 223500/300000 — loss 0.0026810 — PSNR 25.756\r\n",
      "[08:57:08] Progress step 223600/300000 — loss 0.0026804 — PSNR 25.758\r\n",
      "[08:57:09] Progress step 223700/300000 — loss 0.0026857 — PSNR 25.751\r\n",
      "[08:57:11] Progress step 223800/300000 — loss 0.0026817 — PSNR 25.756\r\n",
      "[08:57:12] Progress step 223900/300000 — loss 0.0026925 — PSNR 25.740\r\n",
      "[08:57:14] Progress step 224000/300000 — loss 0.0026958 — PSNR 25.734\r\n",
      "[08:57:14] Eval @ 224000: train_loss 0.0026958 — train_PSNR 25.734 — val_loss 0.0032853 — val_PSNR 24.834\r\n",
      "[08:57:16] Progress step 224100/300000 — loss 0.0026502 — PSNR 25.810\r\n",
      "[08:57:17] Progress step 224200/300000 — loss 0.0026725 — PSNR 25.773\r\n",
      "[08:57:19] Progress step 224300/300000 — loss 0.0026771 — PSNR 25.763\r\n",
      "[08:57:20] Progress step 224400/300000 — loss 0.0026802 — PSNR 25.759\r\n",
      "[08:57:22] Progress step 224500/300000 — loss 0.0026841 — PSNR 25.753\r\n",
      "[08:57:24] Progress step 224600/300000 — loss 0.0026834 — PSNR 25.754\r\n",
      "[08:57:25] Progress step 224700/300000 — loss 0.0027007 — PSNR 25.728\r\n",
      "[08:57:27] Progress step 224800/300000 — loss 0.0026989 — PSNR 25.730\r\n",
      "[08:57:28] Progress step 224900/300000 — loss 0.0026922 — PSNR 25.740\r\n",
      "[08:57:30] Progress step 225000/300000 — loss 0.0026906 — PSNR 25.743\r\n",
      "[08:57:49] Eval @ 225000: train_loss 0.0026906 — train_PSNR 25.743 — val_loss 0.0026467 — val_PSNR 26.399\r\n",
      "[08:57:50] Progress step 225100/300000 — loss 0.0025971 — PSNR 25.891\r\n",
      "[08:57:52] Progress step 225200/300000 — loss 0.0026571 — PSNR 25.802\r\n",
      "[08:57:54] Progress step 225300/300000 — loss 0.0026706 — PSNR 25.785\r\n",
      "[08:57:55] Progress step 225400/300000 — loss 0.0026668 — PSNR 25.789\r\n",
      "[08:57:57] Progress step 225500/300000 — loss 0.0026650 — PSNR 25.790\r\n",
      "[08:57:58] Progress step 225600/300000 — loss 0.0026638 — PSNR 25.793\r\n",
      "[08:58:00] Progress step 225700/300000 — loss 0.0026702 — PSNR 25.782\r\n",
      "[08:58:02] Progress step 225800/300000 — loss 0.0026743 — PSNR 25.775\r\n",
      "[08:58:03] Progress step 225900/300000 — loss 0.0026784 — PSNR 25.768\r\n",
      "[08:58:05] Progress step 226000/300000 — loss 0.0026749 — PSNR 25.773\r\n",
      "[08:58:05] Eval @ 226000: train_loss 0.0026749 — train_PSNR 25.773 — val_loss 0.0032758 — val_PSNR 24.847\r\n",
      "[08:58:06] Progress step 226100/300000 — loss 0.0025997 — PSNR 25.890\r\n",
      "[08:58:08] Progress step 226200/300000 — loss 0.0026594 — PSNR 25.792\r\n",
      "[08:58:10] Progress step 226300/300000 — loss 0.0026585 — PSNR 25.796\r\n",
      "[08:58:11] Progress step 226400/300000 — loss 0.0026675 — PSNR 25.779\r\n",
      "[08:58:13] Progress step 226500/300000 — loss 0.0026711 — PSNR 25.774\r\n",
      "[08:58:14] Progress step 226600/300000 — loss 0.0026725 — PSNR 25.772\r\n",
      "[08:58:16] Progress step 226700/300000 — loss 0.0026808 — PSNR 25.758\r\n",
      "[08:58:18] Progress step 226800/300000 — loss 0.0026810 — PSNR 25.757\r\n",
      "[08:58:19] Progress step 226900/300000 — loss 0.0026769 — PSNR 25.764\r\n",
      "[08:58:21] Progress step 227000/300000 — loss 0.0026756 — PSNR 25.766\r\n",
      "[08:58:39] Eval @ 227000: train_loss 0.0026756 — train_PSNR 25.766 — val_loss 0.0026460 — val_PSNR 26.401\r\n",
      "[08:58:41] Progress step 227100/300000 — loss 0.0027156 — PSNR 25.697\r\n",
      "[08:58:43] Progress step 227200/300000 — loss 0.0027076 — PSNR 25.708\r\n",
      "[08:58:44] Progress step 227300/300000 — loss 0.0027032 — PSNR 25.718\r\n",
      "[08:58:46] Progress step 227400/300000 — loss 0.0026975 — PSNR 25.727\r\n",
      "[08:58:47] Progress step 227500/300000 — loss 0.0026886 — PSNR 25.741\r\n",
      "[08:58:49] Progress step 227600/300000 — loss 0.0026923 — PSNR 25.734\r\n",
      "[08:58:51] Progress step 227700/300000 — loss 0.0026892 — PSNR 25.741\r\n",
      "[08:58:52] Progress step 227800/300000 — loss 0.0026891 — PSNR 25.741\r\n",
      "[08:58:54] Progress step 227900/300000 — loss 0.0026823 — PSNR 25.753\r\n",
      "[08:58:55] Progress step 228000/300000 — loss 0.0026815 — PSNR 25.755\r\n",
      "[08:58:55] Eval @ 228000: train_loss 0.0026815 — train_PSNR 25.755 — val_loss 0.0032764 — val_PSNR 24.846\r\n",
      "[08:58:57] Progress step 228100/300000 — loss 0.0026360 — PSNR 25.829\r\n",
      "[08:58:59] Progress step 228200/300000 — loss 0.0026568 — PSNR 25.796\r\n",
      "[08:59:00] Progress step 228300/300000 — loss 0.0026700 — PSNR 25.773\r\n",
      "[08:59:02] Progress step 228400/300000 — loss 0.0026714 — PSNR 25.771\r\n",
      "[08:59:03] Progress step 228500/300000 — loss 0.0026614 — PSNR 25.787\r\n",
      "[08:59:05] Progress step 228600/300000 — loss 0.0026723 — PSNR 25.770\r\n",
      "[08:59:07] Progress step 228700/300000 — loss 0.0026757 — PSNR 25.764\r\n",
      "[08:59:08] Progress step 228800/300000 — loss 0.0026787 — PSNR 25.761\r\n",
      "[08:59:10] Progress step 228900/300000 — loss 0.0026779 — PSNR 25.762\r\n",
      "[08:59:11] Progress step 229000/300000 — loss 0.0026791 — PSNR 25.761\r\n",
      "[08:59:30] Eval @ 229000: train_loss 0.0026791 — train_PSNR 25.761 — val_loss 0.0026503 — val_PSNR 26.392\r\n",
      "[08:59:32] Progress step 229100/300000 — loss 0.0026823 — PSNR 25.759\r\n",
      "[08:59:33] Progress step 229200/300000 — loss 0.0026536 — PSNR 25.803\r\n",
      "[08:59:35] Progress step 229300/300000 — loss 0.0026773 — PSNR 25.762\r\n",
      "[08:59:37] Progress step 229400/300000 — loss 0.0026888 — PSNR 25.744\r\n",
      "[08:59:38] Progress step 229500/300000 — loss 0.0026884 — PSNR 25.744\r\n",
      "[08:59:40] Progress step 229600/300000 — loss 0.0026795 — PSNR 25.759\r\n",
      "[08:59:41] Progress step 229700/300000 — loss 0.0026762 — PSNR 25.764\r\n",
      "[08:59:43] Progress step 229800/300000 — loss 0.0026746 — PSNR 25.768\r\n",
      "[08:59:45] Progress step 229900/300000 — loss 0.0026729 — PSNR 25.769\r\n",
      "[08:59:46] Progress step 230000/300000 — loss 0.0026713 — PSNR 25.772\r\n",
      "[08:59:46] Eval @ 230000: train_loss 0.0026713 — train_PSNR 25.772 — val_loss 0.0032782 — val_PSNR 24.844\r\n",
      "[08:59:48] Progress step 230100/300000 — loss 0.0026872 — PSNR 25.749\r\n",
      "[08:59:49] Progress step 230200/300000 — loss 0.0026870 — PSNR 25.750\r\n",
      "[08:59:51] Progress step 230300/300000 — loss 0.0027049 — PSNR 25.722\r\n",
      "[08:59:53] Progress step 230400/300000 — loss 0.0027031 — PSNR 25.728\r\n",
      "[08:59:54] Progress step 230500/300000 — loss 0.0027011 — PSNR 25.730\r\n",
      "[08:59:56] Progress step 230600/300000 — loss 0.0026910 — PSNR 25.745\r\n",
      "[08:59:57] Progress step 230700/300000 — loss 0.0026824 — PSNR 25.758\r\n",
      "[08:59:59] Progress step 230800/300000 — loss 0.0026952 — PSNR 25.739\r\n",
      "[09:00:01] Progress step 230900/300000 — loss 0.0026989 — PSNR 25.732\r\n",
      "[09:00:02] Progress step 231000/300000 — loss 0.0026927 — PSNR 25.741\r\n",
      "[09:00:21] Eval @ 231000: train_loss 0.0026927 — train_PSNR 25.741 — val_loss 0.0026515 — val_PSNR 26.389\r\n",
      "[09:00:23] Progress step 231100/300000 — loss 0.0027060 — PSNR 25.721\r\n",
      "[09:00:24] Progress step 231200/300000 — loss 0.0026809 — PSNR 25.760\r\n",
      "[09:00:26] Progress step 231300/300000 — loss 0.0026910 — PSNR 25.741\r\n",
      "[09:00:28] Progress step 231400/300000 — loss 0.0027044 — PSNR 25.723\r\n",
      "[09:00:29] Progress step 231500/300000 — loss 0.0027104 — PSNR 25.713\r\n",
      "[09:00:31] Progress step 231600/300000 — loss 0.0027090 — PSNR 25.714\r\n",
      "[09:00:32] Progress step 231700/300000 — loss 0.0027029 — PSNR 25.724\r\n",
      "[09:00:34] Progress step 231800/300000 — loss 0.0026962 — PSNR 25.734\r\n",
      "[09:00:35] Progress step 231900/300000 — loss 0.0026987 — PSNR 25.732\r\n",
      "[09:00:37] Progress step 232000/300000 — loss 0.0026916 — PSNR 25.743\r\n",
      "[09:00:37] Eval @ 232000: train_loss 0.0026916 — train_PSNR 25.743 — val_loss 0.0032806 — val_PSNR 24.841\r\n",
      "[09:00:39] Progress step 232100/300000 — loss 0.0026870 — PSNR 25.743\r\n",
      "[09:00:40] Progress step 232200/300000 — loss 0.0026692 — PSNR 25.775\r\n",
      "[09:00:42] Progress step 232300/300000 — loss 0.0026823 — PSNR 25.755\r\n",
      "[09:00:43] Progress step 232400/300000 — loss 0.0027101 — PSNR 25.713\r\n",
      "[09:00:45] Progress step 232500/300000 — loss 0.0027008 — PSNR 25.730\r\n",
      "[09:00:47] Progress step 232600/300000 — loss 0.0026928 — PSNR 25.742\r\n",
      "[09:00:48] Progress step 232700/300000 — loss 0.0026887 — PSNR 25.750\r\n",
      "[09:00:50] Progress step 232800/300000 — loss 0.0026858 — PSNR 25.754\r\n",
      "[09:00:51] Progress step 232900/300000 — loss 0.0026860 — PSNR 25.753\r\n",
      "[09:00:53] Progress step 233000/300000 — loss 0.0026846 — PSNR 25.754\r\n",
      "[09:01:12] Eval @ 233000: train_loss 0.0026846 — train_PSNR 25.754 — val_loss 0.0026466 — val_PSNR 26.399\r\n",
      "[09:01:13] Progress step 233100/300000 — loss 0.0026961 — PSNR 25.731\r\n",
      "[09:01:15] Progress step 233200/300000 — loss 0.0026733 — PSNR 25.765\r\n",
      "[09:01:17] Progress step 233300/300000 — loss 0.0026724 — PSNR 25.769\r\n",
      "[09:01:18] Progress step 233400/300000 — loss 0.0026724 — PSNR 25.770\r\n",
      "[09:01:20] Progress step 233500/300000 — loss 0.0026717 — PSNR 25.771\r\n",
      "[09:01:21] Progress step 233600/300000 — loss 0.0026790 — PSNR 25.760\r\n",
      "[09:01:23] Progress step 233700/300000 — loss 0.0026735 — PSNR 25.769\r\n",
      "[09:01:25] Progress step 233800/300000 — loss 0.0026705 — PSNR 25.774\r\n",
      "[09:01:26] Progress step 233900/300000 — loss 0.0026819 — PSNR 25.756\r\n",
      "[09:01:28] Progress step 234000/300000 — loss 0.0026768 — PSNR 25.765\r\n",
      "[09:01:28] Eval @ 234000: train_loss 0.0026768 — train_PSNR 25.765 — val_loss 0.0032921 — val_PSNR 24.825\r\n",
      "[09:01:29] Progress step 234100/300000 — loss 0.0027318 — PSNR 25.678\r\n",
      "[09:01:31] Progress step 234200/300000 — loss 0.0027191 — PSNR 25.700\r\n",
      "[09:01:33] Progress step 234300/300000 — loss 0.0026850 — PSNR 25.755\r\n",
      "[09:01:34] Progress step 234400/300000 — loss 0.0026816 — PSNR 25.760\r\n",
      "[09:01:36] Progress step 234500/300000 — loss 0.0026780 — PSNR 25.766\r\n",
      "[09:01:37] Progress step 234600/300000 — loss 0.0026847 — PSNR 25.754\r\n",
      "[09:01:39] Progress step 234700/300000 — loss 0.0026852 — PSNR 25.753\r\n",
      "[09:01:41] Progress step 234800/300000 — loss 0.0026877 — PSNR 25.748\r\n",
      "[09:01:42] Progress step 234900/300000 — loss 0.0026897 — PSNR 25.745\r\n",
      "[09:01:44] Progress step 235000/300000 — loss 0.0026867 — PSNR 25.749\r\n",
      "[09:02:03] Eval @ 235000: train_loss 0.0026867 — train_PSNR 25.749 — val_loss 0.0026476 — val_PSNR 26.397\r\n",
      "[09:02:04] Progress step 235100/300000 — loss 0.0026862 — PSNR 25.748\r\n",
      "[09:02:06] Progress step 235200/300000 — loss 0.0026807 — PSNR 25.755\r\n",
      "[09:02:07] Progress step 235300/300000 — loss 0.0026853 — PSNR 25.749\r\n",
      "[09:02:09] Progress step 235400/300000 — loss 0.0026942 — PSNR 25.735\r\n",
      "[09:02:11] Progress step 235500/300000 — loss 0.0026829 — PSNR 25.754\r\n",
      "[09:02:12] Progress step 235600/300000 — loss 0.0026803 — PSNR 25.758\r\n",
      "[09:02:14] Progress step 235700/300000 — loss 0.0026824 — PSNR 25.756\r\n",
      "[09:02:15] Progress step 235800/300000 — loss 0.0026915 — PSNR 25.741\r\n",
      "[09:02:17] Progress step 235900/300000 — loss 0.0026872 — PSNR 25.749\r\n",
      "[09:02:19] Progress step 236000/300000 — loss 0.0026964 — PSNR 25.735\r\n",
      "[09:02:19] Eval @ 236000: train_loss 0.0026964 — train_PSNR 25.735 — val_loss 0.0033125 — val_PSNR 24.798\r\n",
      "[09:02:20] Progress step 236100/300000 — loss 0.0027668 — PSNR 25.627\r\n",
      "[09:02:22] Progress step 236200/300000 — loss 0.0027444 — PSNR 25.662\r\n",
      "[09:02:23] Progress step 236300/300000 — loss 0.0027502 — PSNR 25.650\r\n",
      "[09:02:25] Progress step 236400/300000 — loss 0.0027267 — PSNR 25.687\r\n",
      "[09:02:26] Progress step 236500/300000 — loss 0.0027348 — PSNR 25.673\r\n",
      "[09:02:28] Progress step 236600/300000 — loss 0.0027271 — PSNR 25.686\r\n",
      "[09:02:30] Progress step 236700/300000 — loss 0.0027162 — PSNR 25.703\r\n",
      "[09:02:31] Progress step 236800/300000 — loss 0.0027087 — PSNR 25.716\r\n",
      "[09:02:33] Progress step 236900/300000 — loss 0.0027088 — PSNR 25.715\r\n",
      "[09:02:35] Progress step 237000/300000 — loss 0.0027026 — PSNR 25.725\r\n",
      "[09:02:53] Eval @ 237000: train_loss 0.0027026 — train_PSNR 25.725 — val_loss 0.0026459 — val_PSNR 26.401\r\n",
      "[09:02:55] Progress step 237100/300000 — loss 0.0026814 — PSNR 25.753\r\n",
      "[09:02:57] Progress step 237200/300000 — loss 0.0027144 — PSNR 25.707\r\n",
      "[09:02:58] Progress step 237300/300000 — loss 0.0027130 — PSNR 25.711\r\n",
      "[09:03:00] Progress step 237400/300000 — loss 0.0027145 — PSNR 25.709\r\n",
      "[09:03:01] Progress step 237500/300000 — loss 0.0026984 — PSNR 25.734\r\n",
      "[09:03:03] Progress step 237600/300000 — loss 0.0027077 — PSNR 25.718\r\n",
      "[09:03:05] Progress step 237700/300000 — loss 0.0026985 — PSNR 25.733\r\n",
      "[09:03:06] Progress step 237800/300000 — loss 0.0026980 — PSNR 25.734\r\n",
      "[09:03:08] Progress step 237900/300000 — loss 0.0026941 — PSNR 25.739\r\n",
      "[09:03:09] Progress step 238000/300000 — loss 0.0026917 — PSNR 25.742\r\n",
      "[09:03:09] Eval @ 238000: train_loss 0.0026917 — train_PSNR 25.742 — val_loss 0.0032853 — val_PSNR 24.834\r\n",
      "[09:03:11] Progress step 238100/300000 — loss 0.0026166 — PSNR 25.863\r\n",
      "[09:03:13] Progress step 238200/300000 — loss 0.0026211 — PSNR 25.857\r\n",
      "[09:03:14] Progress step 238300/300000 — loss 0.0026325 — PSNR 25.838\r\n",
      "[09:03:16] Progress step 238400/300000 — loss 0.0026488 — PSNR 25.813\r\n",
      "[09:03:17] Progress step 238500/300000 — loss 0.0026690 — PSNR 25.782\r\n",
      "[09:03:19] Progress step 238600/300000 — loss 0.0026813 — PSNR 25.760\r\n",
      "[09:03:21] Progress step 238700/300000 — loss 0.0026707 — PSNR 25.777\r\n",
      "[09:03:22] Progress step 238800/300000 — loss 0.0026740 — PSNR 25.773\r\n",
      "[09:03:24] Progress step 238900/300000 — loss 0.0026736 — PSNR 25.773\r\n",
      "[09:03:25] Progress step 239000/300000 — loss 0.0026797 — PSNR 25.763\r\n",
      "[09:03:44] Eval @ 239000: train_loss 0.0026797 — train_PSNR 25.763 — val_loss 0.0026555 — val_PSNR 26.380\r\n",
      "[09:03:46] Progress step 239100/300000 — loss 0.0027132 — PSNR 25.717\r\n",
      "[09:03:47] Progress step 239200/300000 — loss 0.0026751 — PSNR 25.771\r\n",
      "[09:03:49] Progress step 239300/300000 — loss 0.0026768 — PSNR 25.768\r\n",
      "[09:03:51] Progress step 239400/300000 — loss 0.0026892 — PSNR 25.744\r\n",
      "[09:03:52] Progress step 239500/300000 — loss 0.0026965 — PSNR 25.733\r\n",
      "[09:03:54] Progress step 239600/300000 — loss 0.0026944 — PSNR 25.737\r\n",
      "[09:03:55] Progress step 239700/300000 — loss 0.0026911 — PSNR 25.742\r\n",
      "[09:03:57] Progress step 239800/300000 — loss 0.0026946 — PSNR 25.736\r\n",
      "[09:03:58] Progress step 239900/300000 — loss 0.0026933 — PSNR 25.738\r\n",
      "[09:04:00] Progress step 240000/300000 — loss 0.0026910 — PSNR 25.742\r\n",
      "[09:04:00] Eval @ 240000: train_loss 0.0026910 — train_PSNR 25.742 — val_loss 0.0032757 — val_PSNR 24.847\r\n",
      "[09:04:02] Progress step 240100/300000 — loss 0.0027071 — PSNR 25.714\r\n",
      "[09:04:03] Progress step 240200/300000 — loss 0.0026647 — PSNR 25.783\r\n",
      "[09:04:05] Progress step 240300/300000 — loss 0.0026848 — PSNR 25.755\r\n",
      "[09:04:07] Progress step 240400/300000 — loss 0.0026767 — PSNR 25.765\r\n",
      "[09:04:08] Progress step 240500/300000 — loss 0.0026800 — PSNR 25.758\r\n",
      "[09:04:10] Progress step 240600/300000 — loss 0.0026899 — PSNR 25.743\r\n",
      "[09:04:11] Progress step 240700/300000 — loss 0.0026902 — PSNR 25.743\r\n",
      "[09:04:13] Progress step 240800/300000 — loss 0.0026849 — PSNR 25.750\r\n",
      "[09:04:15] Progress step 240900/300000 — loss 0.0026808 — PSNR 25.757\r\n",
      "[09:04:16] Progress step 241000/300000 — loss 0.0026774 — PSNR 25.762\r\n",
      "[09:04:35] Eval @ 241000: train_loss 0.0026774 — train_PSNR 25.762 — val_loss 0.0026464 — val_PSNR 26.400\r\n",
      "[09:04:37] Progress step 241100/300000 — loss 0.0026745 — PSNR 25.770\r\n",
      "[09:04:38] Progress step 241200/300000 — loss 0.0026824 — PSNR 25.753\r\n",
      "[09:04:40] Progress step 241300/300000 — loss 0.0026709 — PSNR 25.774\r\n",
      "[09:04:41] Progress step 241400/300000 — loss 0.0026919 — PSNR 25.741\r\n",
      "[09:04:43] Progress step 241500/300000 — loss 0.0026881 — PSNR 25.746\r\n",
      "[09:04:45] Progress step 241600/300000 — loss 0.0026809 — PSNR 25.759\r\n",
      "[09:04:46] Progress step 241700/300000 — loss 0.0026709 — PSNR 25.776\r\n",
      "[09:04:48] Progress step 241800/300000 — loss 0.0026781 — PSNR 25.765\r\n",
      "[09:04:49] Progress step 241900/300000 — loss 0.0026831 — PSNR 25.756\r\n",
      "[09:04:51] Progress step 242000/300000 — loss 0.0026762 — PSNR 25.768\r\n",
      "[09:04:51] Eval @ 242000: train_loss 0.0026762 — train_PSNR 25.768 — val_loss 0.0032965 — val_PSNR 24.819\r\n",
      "[09:04:53] Progress step 242100/300000 — loss 0.0027104 — PSNR 25.714\r\n",
      "[09:04:54] Progress step 242200/300000 — loss 0.0026756 — PSNR 25.770\r\n",
      "[09:04:56] Progress step 242300/300000 — loss 0.0026685 — PSNR 25.780\r\n",
      "[09:04:57] Progress step 242400/300000 — loss 0.0026705 — PSNR 25.774\r\n",
      "[09:04:59] Progress step 242500/300000 — loss 0.0026900 — PSNR 25.743\r\n",
      "[09:05:01] Progress step 242600/300000 — loss 0.0026973 — PSNR 25.731\r\n",
      "[09:05:02] Progress step 242700/300000 — loss 0.0026939 — PSNR 25.737\r\n",
      "[09:05:04] Progress step 242800/300000 — loss 0.0026952 — PSNR 25.734\r\n",
      "[09:05:05] Progress step 242900/300000 — loss 0.0026934 — PSNR 25.738\r\n",
      "[09:05:07] Progress step 243000/300000 — loss 0.0026951 — PSNR 25.734\r\n",
      "[09:05:26] Eval @ 243000: train_loss 0.0026951 — train_PSNR 25.734 — val_loss 0.0026461 — val_PSNR 26.400\r\n",
      "[09:05:27] Progress step 243100/300000 — loss 0.0027120 — PSNR 25.708\r\n",
      "[09:05:29] Progress step 243200/300000 — loss 0.0026974 — PSNR 25.727\r\n",
      "[09:05:31] Progress step 243300/300000 — loss 0.0026768 — PSNR 25.761\r\n",
      "[09:05:32] Progress step 243400/300000 — loss 0.0026644 — PSNR 25.779\r\n",
      "[09:05:34] Progress step 243500/300000 — loss 0.0026769 — PSNR 25.760\r\n",
      "[09:05:35] Progress step 243600/300000 — loss 0.0026792 — PSNR 25.759\r\n",
      "[09:05:37] Progress step 243700/300000 — loss 0.0026903 — PSNR 25.743\r\n",
      "[09:05:39] Progress step 243800/300000 — loss 0.0026898 — PSNR 25.744\r\n",
      "[09:05:40] Progress step 243900/300000 — loss 0.0026896 — PSNR 25.745\r\n",
      "[09:05:42] Progress step 244000/300000 — loss 0.0026898 — PSNR 25.744\r\n",
      "[09:05:42] Eval @ 244000: train_loss 0.0026898 — train_PSNR 25.744 — val_loss 0.0032813 — val_PSNR 24.840\r\n",
      "[09:05:44] Progress step 244100/300000 — loss 0.0026165 — PSNR 25.861\r\n",
      "[09:05:45] Progress step 244200/300000 — loss 0.0026361 — PSNR 25.836\r\n",
      "[09:05:47] Progress step 244300/300000 — loss 0.0026524 — PSNR 25.811\r\n",
      "[09:05:48] Progress step 244400/300000 — loss 0.0026576 — PSNR 25.800\r\n",
      "[09:05:50] Progress step 244500/300000 — loss 0.0026649 — PSNR 25.788\r\n",
      "[09:05:51] Progress step 244600/300000 — loss 0.0026684 — PSNR 25.780\r\n",
      "[09:05:53] Progress step 244700/300000 — loss 0.0026653 — PSNR 25.786\r\n",
      "[09:05:55] Progress step 244800/300000 — loss 0.0026696 — PSNR 25.779\r\n",
      "[09:05:56] Progress step 244900/300000 — loss 0.0026648 — PSNR 25.787\r\n",
      "[09:05:58] Progress step 245000/300000 — loss 0.0026686 — PSNR 25.782\r\n",
      "[09:06:17] Eval @ 245000: train_loss 0.0026686 — train_PSNR 25.782 — val_loss 0.0026461 — val_PSNR 26.400\r\n",
      "[09:06:18] Progress step 245100/300000 — loss 0.0026565 — PSNR 25.801\r\n",
      "[09:06:20] Progress step 245200/300000 — loss 0.0026772 — PSNR 25.765\r\n",
      "[09:06:21] Progress step 245300/300000 — loss 0.0026802 — PSNR 25.764\r\n",
      "[09:06:23] Progress step 245400/300000 — loss 0.0026977 — PSNR 25.737\r\n",
      "[09:06:25] Progress step 245500/300000 — loss 0.0026871 — PSNR 25.754\r\n",
      "[09:06:26] Progress step 245600/300000 — loss 0.0026881 — PSNR 25.752\r\n",
      "[09:06:28] Progress step 245700/300000 — loss 0.0026815 — PSNR 25.761\r\n",
      "[09:06:29] Progress step 245800/300000 — loss 0.0026867 — PSNR 25.752\r\n",
      "[09:06:31] Progress step 245900/300000 — loss 0.0026888 — PSNR 25.749\r\n",
      "[09:06:33] Progress step 246000/300000 — loss 0.0026925 — PSNR 25.743\r\n",
      "[09:06:33] Eval @ 246000: train_loss 0.0026925 — train_PSNR 25.743 — val_loss 0.0033403 — val_PSNR 24.762\r\n",
      "[09:06:34] Progress step 246100/300000 — loss 0.0026213 — PSNR 25.851\r\n",
      "[09:06:36] Progress step 246200/300000 — loss 0.0026438 — PSNR 25.815\r\n",
      "[09:06:37] Progress step 246300/300000 — loss 0.0026675 — PSNR 25.777\r\n",
      "[09:06:39] Progress step 246400/300000 — loss 0.0026671 — PSNR 25.779\r\n",
      "[09:06:40] Progress step 246500/300000 — loss 0.0026719 — PSNR 25.771\r\n",
      "[09:06:42] Progress step 246600/300000 — loss 0.0026719 — PSNR 25.773\r\n",
      "[09:06:44] Progress step 246700/300000 — loss 0.0026743 — PSNR 25.769\r\n",
      "[09:06:45] Progress step 246800/300000 — loss 0.0026741 — PSNR 25.770\r\n",
      "[09:06:47] Progress step 246900/300000 — loss 0.0026729 — PSNR 25.773\r\n",
      "[09:06:48] Progress step 247000/300000 — loss 0.0026716 — PSNR 25.774\r\n",
      "[09:07:07] Eval @ 247000: train_loss 0.0026716 — train_PSNR 25.774 — val_loss 0.0026484 — val_PSNR 26.395\r\n",
      "[09:07:09] Progress step 247100/300000 — loss 0.0026956 — PSNR 25.742\r\n",
      "[09:07:11] Progress step 247200/300000 — loss 0.0026837 — PSNR 25.754\r\n",
      "[09:07:12] Progress step 247300/300000 — loss 0.0026825 — PSNR 25.753\r\n",
      "[09:07:14] Progress step 247400/300000 — loss 0.0026737 — PSNR 25.769\r\n",
      "[09:07:15] Progress step 247500/300000 — loss 0.0026750 — PSNR 25.768\r\n",
      "[09:07:17] Progress step 247600/300000 — loss 0.0026778 — PSNR 25.763\r\n",
      "[09:07:19] Progress step 247700/300000 — loss 0.0026794 — PSNR 25.760\r\n",
      "[09:07:20] Progress step 247800/300000 — loss 0.0026740 — PSNR 25.768\r\n",
      "[09:07:22] Progress step 247900/300000 — loss 0.0026800 — PSNR 25.758\r\n",
      "[09:07:23] Progress step 248000/300000 — loss 0.0026800 — PSNR 25.758\r\n",
      "[09:07:23] Eval @ 248000: train_loss 0.0026800 — train_PSNR 25.758 — val_loss 0.0032853 — val_PSNR 24.834\r\n",
      "[09:07:25] Progress step 248100/300000 — loss 0.0027730 — PSNR 25.615\r\n",
      "[09:07:27] Progress step 248200/300000 — loss 0.0027177 — PSNR 25.704\r\n",
      "[09:07:28] Progress step 248300/300000 — loss 0.0027083 — PSNR 25.721\r\n",
      "[09:07:30] Progress step 248400/300000 — loss 0.0027078 — PSNR 25.723\r\n",
      "[09:07:31] Progress step 248500/300000 — loss 0.0027057 — PSNR 25.724\r\n",
      "[09:07:33] Progress step 248600/300000 — loss 0.0026966 — PSNR 25.738\r\n",
      "[09:07:35] Progress step 248700/300000 — loss 0.0026989 — PSNR 25.733\r\n",
      "[09:07:36] Progress step 248800/300000 — loss 0.0026999 — PSNR 25.732\r\n",
      "[09:07:38] Progress step 248900/300000 — loss 0.0026959 — PSNR 25.737\r\n",
      "[09:07:39] Progress step 249000/300000 — loss 0.0026901 — PSNR 25.746\r\n",
      "[09:07:58] Eval @ 249000: train_loss 0.0026901 — train_PSNR 25.746 — val_loss 0.0026500 — val_PSNR 26.392\r\n",
      "[09:08:00] Progress step 249100/300000 — loss 0.0026991 — PSNR 25.727\r\n",
      "[09:08:01] Progress step 249200/300000 — loss 0.0026864 — PSNR 25.745\r\n",
      "[09:08:03] Progress step 249300/300000 — loss 0.0026772 — PSNR 25.760\r\n",
      "[09:08:05] Progress step 249400/300000 — loss 0.0026795 — PSNR 25.757\r\n",
      "[09:08:06] Progress step 249500/300000 — loss 0.0026807 — PSNR 25.755\r\n",
      "[09:08:08] Progress step 249600/300000 — loss 0.0026803 — PSNR 25.757\r\n",
      "[09:08:09] Progress step 249700/300000 — loss 0.0026839 — PSNR 25.751\r\n",
      "[09:08:11] Progress step 249800/300000 — loss 0.0026909 — PSNR 25.741\r\n",
      "[09:08:13] Progress step 249900/300000 — loss 0.0026894 — PSNR 25.743\r\n",
      "[09:08:14] Progress step 250000/300000 — loss 0.0026871 — PSNR 25.748\r\n",
      "[09:08:14] Eval @ 250000: train_loss 0.0026871 — train_PSNR 25.748 — val_loss 0.0032826 — val_PSNR 24.838\r\n",
      "[09:08:16] Progress step 250100/300000 — loss 0.0026197 — PSNR 25.854\r\n",
      "[09:08:17] Progress step 250200/300000 — loss 0.0026732 — PSNR 25.775\r\n",
      "[09:08:19] Progress step 250300/300000 — loss 0.0026750 — PSNR 25.772\r\n",
      "[09:08:21] Progress step 250400/300000 — loss 0.0026557 — PSNR 25.802\r\n",
      "[09:08:22] Progress step 250500/300000 — loss 0.0026623 — PSNR 25.790\r\n",
      "[09:08:24] Progress step 250600/300000 — loss 0.0026744 — PSNR 25.770\r\n",
      "[09:08:25] Progress step 250700/300000 — loss 0.0026780 — PSNR 25.765\r\n",
      "[09:08:27] Progress step 250800/300000 — loss 0.0026783 — PSNR 25.764\r\n",
      "[09:08:29] Progress step 250900/300000 — loss 0.0026770 — PSNR 25.765\r\n",
      "[09:08:30] Progress step 251000/300000 — loss 0.0026797 — PSNR 25.761\r\n",
      "[09:08:49] Eval @ 251000: train_loss 0.0026797 — train_PSNR 25.761 — val_loss 0.0026633 — val_PSNR 26.364\r\n",
      "[09:08:51] Progress step 251100/300000 — loss 0.0026638 — PSNR 25.786\r\n",
      "[09:08:52] Progress step 251200/300000 — loss 0.0026705 — PSNR 25.773\r\n",
      "[09:08:54] Progress step 251300/300000 — loss 0.0026697 — PSNR 25.775\r\n",
      "[09:08:55] Progress step 251400/300000 — loss 0.0026720 — PSNR 25.772\r\n",
      "[09:08:57] Progress step 251500/300000 — loss 0.0026671 — PSNR 25.778\r\n",
      "[09:08:58] Progress step 251600/300000 — loss 0.0026828 — PSNR 25.752\r\n",
      "[09:09:00] Progress step 251700/300000 — loss 0.0026776 — PSNR 25.760\r\n",
      "[09:09:02] Progress step 251800/300000 — loss 0.0026796 — PSNR 25.756\r\n",
      "[09:09:03] Progress step 251900/300000 — loss 0.0026762 — PSNR 25.762\r\n",
      "[09:09:05] Progress step 252000/300000 — loss 0.0026808 — PSNR 25.756\r\n",
      "[09:09:05] Eval @ 252000: train_loss 0.0026808 — train_PSNR 25.756 — val_loss 0.0032774 — val_PSNR 24.845\r\n",
      "[09:09:06] Progress step 252100/300000 — loss 0.0026317 — PSNR 25.850\r\n",
      "[09:09:08] Progress step 252200/300000 — loss 0.0026445 — PSNR 25.823\r\n",
      "[09:09:10] Progress step 252300/300000 — loss 0.0026505 — PSNR 25.813\r\n",
      "[09:09:11] Progress step 252400/300000 — loss 0.0026484 — PSNR 25.816\r\n",
      "[09:09:13] Progress step 252500/300000 — loss 0.0026565 — PSNR 25.804\r\n",
      "[09:09:14] Progress step 252600/300000 — loss 0.0026714 — PSNR 25.780\r\n",
      "[09:09:16] Progress step 252700/300000 — loss 0.0026772 — PSNR 25.771\r\n",
      "[09:09:18] Progress step 252800/300000 — loss 0.0026714 — PSNR 25.780\r\n",
      "[09:09:19] Progress step 252900/300000 — loss 0.0026709 — PSNR 25.778\r\n",
      "[09:09:21] Progress step 253000/300000 — loss 0.0026632 — PSNR 25.791\r\n",
      "[09:09:39] Eval @ 253000: train_loss 0.0026632 — train_PSNR 25.791 — val_loss 0.0026468 — val_PSNR 26.399\r\n",
      "[09:09:41] Progress step 253100/300000 — loss 0.0026359 — PSNR 25.834\r\n",
      "[09:09:43] Progress step 253200/300000 — loss 0.0026432 — PSNR 25.822\r\n",
      "[09:09:44] Progress step 253300/300000 — loss 0.0026458 — PSNR 25.817\r\n",
      "[09:09:46] Progress step 253400/300000 — loss 0.0026591 — PSNR 25.795\r\n",
      "[09:09:48] Progress step 253500/300000 — loss 0.0026550 — PSNR 25.801\r\n",
      "[09:09:49] Progress step 253600/300000 — loss 0.0026659 — PSNR 25.782\r\n",
      "[09:09:51] Progress step 253700/300000 — loss 0.0026636 — PSNR 25.787\r\n",
      "[09:09:52] Progress step 253800/300000 — loss 0.0026672 — PSNR 25.782\r\n",
      "[09:09:54] Progress step 253900/300000 — loss 0.0026659 — PSNR 25.784\r\n",
      "[09:09:56] Progress step 254000/300000 — loss 0.0026778 — PSNR 25.766\r\n",
      "[09:09:56] Eval @ 254000: train_loss 0.0026778 — train_PSNR 25.766 — val_loss 0.0032882 — val_PSNR 24.830\r\n",
      "[09:09:57] Progress step 254100/300000 — loss 0.0027082 — PSNR 25.715\r\n",
      "[09:09:59] Progress step 254200/300000 — loss 0.0027174 — PSNR 25.703\r\n",
      "[09:10:00] Progress step 254300/300000 — loss 0.0027106 — PSNR 25.717\r\n",
      "[09:10:02] Progress step 254400/300000 — loss 0.0027044 — PSNR 25.725\r\n",
      "[09:10:03] Progress step 254500/300000 — loss 0.0027015 — PSNR 25.728\r\n",
      "[09:10:05] Progress step 254600/300000 — loss 0.0026959 — PSNR 25.737\r\n",
      "[09:10:07] Progress step 254700/300000 — loss 0.0026860 — PSNR 25.752\r\n",
      "[09:10:08] Progress step 254800/300000 — loss 0.0026776 — PSNR 25.766\r\n",
      "[09:10:10] Progress step 254900/300000 — loss 0.0026791 — PSNR 25.764\r\n",
      "[09:10:11] Progress step 255000/300000 — loss 0.0026791 — PSNR 25.763\r\n",
      "[09:10:30] Eval @ 255000: train_loss 0.0026791 — train_PSNR 25.763 — val_loss 0.0026534 — val_PSNR 26.385\r\n",
      "[09:10:32] Progress step 255100/300000 — loss 0.0027103 — PSNR 25.708\r\n",
      "[09:10:33] Progress step 255200/300000 — loss 0.0027022 — PSNR 25.721\r\n",
      "[09:10:35] Progress step 255300/300000 — loss 0.0026909 — PSNR 25.742\r\n",
      "[09:10:37] Progress step 255400/300000 — loss 0.0026882 — PSNR 25.748\r\n",
      "[09:10:38] Progress step 255500/300000 — loss 0.0026943 — PSNR 25.740\r\n",
      "[09:10:40] Progress step 255600/300000 — loss 0.0026853 — PSNR 25.754\r\n",
      "[09:10:41] Progress step 255700/300000 — loss 0.0026803 — PSNR 25.760\r\n",
      "[09:10:43] Progress step 255800/300000 — loss 0.0026867 — PSNR 25.750\r\n",
      "[09:10:45] Progress step 255900/300000 — loss 0.0026862 — PSNR 25.751\r\n",
      "[09:10:46] Progress step 256000/300000 — loss 0.0026902 — PSNR 25.744\r\n",
      "[09:10:46] Eval @ 256000: train_loss 0.0026902 — train_PSNR 25.744 — val_loss 0.0032905 — val_PSNR 24.827\r\n",
      "[09:10:48] Progress step 256100/300000 — loss 0.0026871 — PSNR 25.747\r\n",
      "[09:10:49] Progress step 256200/300000 — loss 0.0027174 — PSNR 25.704\r\n",
      "[09:10:51] Progress step 256300/300000 — loss 0.0027114 — PSNR 25.710\r\n",
      "[09:10:53] Progress step 256400/300000 — loss 0.0027097 — PSNR 25.713\r\n",
      "[09:10:54] Progress step 256500/300000 — loss 0.0027116 — PSNR 25.708\r\n",
      "[09:10:56] Progress step 256600/300000 — loss 0.0027000 — PSNR 25.726\r\n",
      "[09:10:57] Progress step 256700/300000 — loss 0.0027033 — PSNR 25.720\r\n",
      "[09:10:59] Progress step 256800/300000 — loss 0.0026934 — PSNR 25.737\r\n",
      "[09:11:01] Progress step 256900/300000 — loss 0.0026896 — PSNR 25.743\r\n",
      "[09:11:02] Progress step 257000/300000 — loss 0.0026907 — PSNR 25.741\r\n",
      "[09:11:21] Eval @ 257000: train_loss 0.0026907 — train_PSNR 25.741 — val_loss 0.0026560 — val_PSNR 26.379\r\n",
      "[09:11:22] Progress step 257100/300000 — loss 0.0027009 — PSNR 25.722\r\n",
      "[09:11:24] Progress step 257200/300000 — loss 0.0026729 — PSNR 25.773\r\n",
      "[09:11:26] Progress step 257300/300000 — loss 0.0026734 — PSNR 25.770\r\n",
      "[09:11:27] Progress step 257400/300000 — loss 0.0026804 — PSNR 25.757\r\n",
      "[09:11:29] Progress step 257500/300000 — loss 0.0026874 — PSNR 25.747\r\n",
      "[09:11:30] Progress step 257600/300000 — loss 0.0026970 — PSNR 25.732\r\n",
      "[09:11:32] Progress step 257700/300000 — loss 0.0027055 — PSNR 25.718\r\n",
      "[09:11:34] Progress step 257800/300000 — loss 0.0027079 — PSNR 25.716\r\n",
      "[09:11:35] Progress step 257900/300000 — loss 0.0027081 — PSNR 25.715\r\n",
      "[09:11:37] Progress step 258000/300000 — loss 0.0027120 — PSNR 25.709\r\n",
      "[09:11:37] Eval @ 258000: train_loss 0.0027120 — train_PSNR 25.709 — val_loss 0.0032756 — val_PSNR 24.847\r\n",
      "[09:11:38] Progress step 258100/300000 — loss 0.0026787 — PSNR 25.764\r\n",
      "[09:11:40] Progress step 258200/300000 — loss 0.0026805 — PSNR 25.758\r\n",
      "[09:11:42] Progress step 258300/300000 — loss 0.0026726 — PSNR 25.772\r\n",
      "[09:11:43] Progress step 258400/300000 — loss 0.0026810 — PSNR 25.758\r\n",
      "[09:11:45] Progress step 258500/300000 — loss 0.0026790 — PSNR 25.761\r\n",
      "[09:11:46] Progress step 258600/300000 — loss 0.0026773 — PSNR 25.764\r\n",
      "[09:11:48] Progress step 258700/300000 — loss 0.0026801 — PSNR 25.760\r\n",
      "[09:11:50] Progress step 258800/300000 — loss 0.0026823 — PSNR 25.758\r\n",
      "[09:11:51] Progress step 258900/300000 — loss 0.0026842 — PSNR 25.754\r\n",
      "[09:11:53] Progress step 259000/300000 — loss 0.0026861 — PSNR 25.751\r\n",
      "[09:12:12] Eval @ 259000: train_loss 0.0026861 — train_PSNR 25.751 — val_loss 0.0026466 — val_PSNR 26.400\r\n",
      "[09:12:13] Progress step 259100/300000 — loss 0.0027041 — PSNR 25.719\r\n",
      "[09:12:15] Progress step 259200/300000 — loss 0.0026627 — PSNR 25.787\r\n",
      "[09:12:16] Progress step 259300/300000 — loss 0.0026467 — PSNR 25.814\r\n",
      "[09:12:18] Progress step 259400/300000 — loss 0.0026504 — PSNR 25.811\r\n",
      "[09:12:20] Progress step 259500/300000 — loss 0.0026421 — PSNR 25.824\r\n",
      "[09:12:21] Progress step 259600/300000 — loss 0.0026530 — PSNR 25.806\r\n",
      "[09:12:23] Progress step 259700/300000 — loss 0.0026537 — PSNR 25.804\r\n",
      "[09:12:24] Progress step 259800/300000 — loss 0.0026533 — PSNR 25.804\r\n",
      "[09:12:26] Progress step 259900/300000 — loss 0.0026573 — PSNR 25.797\r\n",
      "[09:12:28] Progress step 260000/300000 — loss 0.0026615 — PSNR 25.789\r\n",
      "[09:12:28] Eval @ 260000: train_loss 0.0026615 — train_PSNR 25.789 — val_loss 0.0033273 — val_PSNR 24.779\r\n",
      "[09:12:29] Progress step 260100/300000 — loss 0.0027091 — PSNR 25.717\r\n",
      "[09:12:31] Progress step 260200/300000 — loss 0.0027189 — PSNR 25.703\r\n",
      "[09:12:33] Progress step 260300/300000 — loss 0.0027260 — PSNR 25.692\r\n",
      "[09:12:34] Progress step 260400/300000 — loss 0.0027182 — PSNR 25.704\r\n",
      "[09:12:36] Progress step 260500/300000 — loss 0.0027121 — PSNR 25.712\r\n",
      "[09:12:37] Progress step 260600/300000 — loss 0.0026989 — PSNR 25.733\r\n",
      "[09:12:39] Progress step 260700/300000 — loss 0.0026954 — PSNR 25.738\r\n",
      "[09:12:40] Progress step 260800/300000 — loss 0.0026911 — PSNR 25.744\r\n",
      "[09:12:42] Progress step 260900/300000 — loss 0.0026844 — PSNR 25.754\r\n",
      "[09:12:44] Progress step 261000/300000 — loss 0.0026820 — PSNR 25.757\r\n",
      "[09:13:02] Eval @ 261000: train_loss 0.0026820 — train_PSNR 25.757 — val_loss 0.0026473 — val_PSNR 26.398\r\n",
      "[09:13:04] Progress step 261100/300000 — loss 0.0027019 — PSNR 25.712\r\n",
      "[09:13:06] Progress step 261200/300000 — loss 0.0027029 — PSNR 25.717\r\n",
      "[09:13:07] Progress step 261300/300000 — loss 0.0026805 — PSNR 25.757\r\n",
      "[09:13:09] Progress step 261400/300000 — loss 0.0026796 — PSNR 25.761\r\n",
      "[09:13:11] Progress step 261500/300000 — loss 0.0026868 — PSNR 25.750\r\n",
      "[09:13:12] Progress step 261600/300000 — loss 0.0026882 — PSNR 25.746\r\n",
      "[09:13:14] Progress step 261700/300000 — loss 0.0026812 — PSNR 25.757\r\n",
      "[09:13:15] Progress step 261800/300000 — loss 0.0026808 — PSNR 25.757\r\n",
      "[09:13:17] Progress step 261900/300000 — loss 0.0026801 — PSNR 25.759\r\n",
      "[09:13:18] Progress step 262000/300000 — loss 0.0026762 — PSNR 25.766\r\n",
      "[09:13:18] Eval @ 262000: train_loss 0.0026762 — train_PSNR 25.766 — val_loss 0.0032803 — val_PSNR 24.841\r\n",
      "[09:13:20] Progress step 262100/300000 — loss 0.0026757 — PSNR 25.770\r\n",
      "[09:13:22] Progress step 262200/300000 — loss 0.0026585 — PSNR 25.794\r\n",
      "[09:13:23] Progress step 262300/300000 — loss 0.0026530 — PSNR 25.803\r\n",
      "[09:13:25] Progress step 262400/300000 — loss 0.0026478 — PSNR 25.810\r\n",
      "[09:13:26] Progress step 262500/300000 — loss 0.0026527 — PSNR 25.803\r\n",
      "[09:13:28] Progress step 262600/300000 — loss 0.0026583 — PSNR 25.794\r\n",
      "[09:13:30] Progress step 262700/300000 — loss 0.0026658 — PSNR 25.783\r\n",
      "[09:13:31] Progress step 262800/300000 — loss 0.0026769 — PSNR 25.767\r\n",
      "[09:13:33] Progress step 262900/300000 — loss 0.0026767 — PSNR 25.767\r\n",
      "[09:13:34] Progress step 263000/300000 — loss 0.0026760 — PSNR 25.768\r\n",
      "[09:13:53] Eval @ 263000: train_loss 0.0026760 — train_PSNR 25.768 — val_loss 0.0026464 — val_PSNR 26.400\r\n",
      "[09:13:55] Progress step 263100/300000 — loss 0.0027184 — PSNR 25.690\r\n",
      "[09:13:56] Progress step 263200/300000 — loss 0.0026898 — PSNR 25.741\r\n",
      "[09:13:58] Progress step 263300/300000 — loss 0.0026903 — PSNR 25.740\r\n",
      "[09:14:00] Progress step 263400/300000 — loss 0.0026839 — PSNR 25.753\r\n",
      "[09:14:01] Progress step 263500/300000 — loss 0.0026823 — PSNR 25.757\r\n",
      "[09:14:03] Progress step 263600/300000 — loss 0.0026768 — PSNR 25.768\r\n",
      "[09:14:04] Progress step 263700/300000 — loss 0.0026793 — PSNR 25.761\r\n",
      "[09:14:06] Progress step 263800/300000 — loss 0.0026774 — PSNR 25.764\r\n",
      "[09:14:08] Progress step 263900/300000 — loss 0.0026779 — PSNR 25.764\r\n",
      "[09:14:09] Progress step 264000/300000 — loss 0.0026807 — PSNR 25.759\r\n",
      "[09:14:09] Eval @ 264000: train_loss 0.0026807 — train_PSNR 25.759 — val_loss 0.0032800 — val_PSNR 24.841\r\n",
      "[09:14:11] Progress step 264100/300000 — loss 0.0026914 — PSNR 25.738\r\n",
      "[09:14:12] Progress step 264200/300000 — loss 0.0026950 — PSNR 25.736\r\n",
      "[09:14:14] Progress step 264300/300000 — loss 0.0026908 — PSNR 25.740\r\n",
      "[09:14:16] Progress step 264400/300000 — loss 0.0027039 — PSNR 25.722\r\n",
      "[09:14:17] Progress step 264500/300000 — loss 0.0026883 — PSNR 25.745\r\n",
      "[09:14:19] Progress step 264600/300000 — loss 0.0026811 — PSNR 25.757\r\n",
      "[09:14:20] Progress step 264700/300000 — loss 0.0026737 — PSNR 25.768\r\n",
      "[09:14:22] Progress step 264800/300000 — loss 0.0026673 — PSNR 25.779\r\n",
      "[09:14:24] Progress step 264900/300000 — loss 0.0026707 — PSNR 25.773\r\n",
      "[09:14:25] Progress step 265000/300000 — loss 0.0026672 — PSNR 25.779\r\n",
      "[09:14:44] Eval @ 265000: train_loss 0.0026672 — train_PSNR 25.779 — val_loss 0.0026469 — val_PSNR 26.399\r\n",
      "[09:14:45] Progress step 265100/300000 — loss 0.0027303 — PSNR 25.673\r\n",
      "[09:14:47] Progress step 265200/300000 — loss 0.0027144 — PSNR 25.701\r\n",
      "[09:14:49] Progress step 265300/300000 — loss 0.0027005 — PSNR 25.726\r\n",
      "[09:14:50] Progress step 265400/300000 — loss 0.0026951 — PSNR 25.734\r\n",
      "[09:14:52] Progress step 265500/300000 — loss 0.0026915 — PSNR 25.739\r\n",
      "[09:14:53] Progress step 265600/300000 — loss 0.0026851 — PSNR 25.750\r\n",
      "[09:14:55] Progress step 265700/300000 — loss 0.0026888 — PSNR 25.743\r\n",
      "[09:14:57] Progress step 265800/300000 — loss 0.0026926 — PSNR 25.737\r\n",
      "[09:14:58] Progress step 265900/300000 — loss 0.0026979 — PSNR 25.728\r\n",
      "[09:15:00] Progress step 266000/300000 — loss 0.0026982 — PSNR 25.728\r\n",
      "[09:15:00] Eval @ 266000: train_loss 0.0026982 — train_PSNR 25.728 — val_loss 0.0032741 — val_PSNR 24.849\r\n",
      "[09:15:02] Progress step 266100/300000 — loss 0.0027256 — PSNR 25.692\r\n",
      "[09:15:03] Progress step 266200/300000 — loss 0.0027255 — PSNR 25.691\r\n",
      "[09:15:05] Progress step 266300/300000 — loss 0.0027052 — PSNR 25.724\r\n",
      "[09:15:06] Progress step 266400/300000 — loss 0.0026992 — PSNR 25.734\r\n",
      "[09:15:08] Progress step 266500/300000 — loss 0.0026976 — PSNR 25.736\r\n",
      "[09:15:10] Progress step 266600/300000 — loss 0.0026912 — PSNR 25.743\r\n",
      "[09:15:11] Progress step 266700/300000 — loss 0.0026925 — PSNR 25.741\r\n",
      "[09:15:13] Progress step 266800/300000 — loss 0.0026938 — PSNR 25.738\r\n",
      "[09:15:14] Progress step 266900/300000 — loss 0.0026911 — PSNR 25.743\r\n",
      "[09:15:16] Progress step 267000/300000 — loss 0.0026905 — PSNR 25.744\r\n",
      "[09:15:35] Eval @ 267000: train_loss 0.0026905 — train_PSNR 25.744 — val_loss 0.0026504 — val_PSNR 26.391\r\n",
      "[09:15:36] Progress step 267100/300000 — loss 0.0027008 — PSNR 25.725\r\n",
      "[09:15:38] Progress step 267200/300000 — loss 0.0026947 — PSNR 25.741\r\n",
      "[09:15:40] Progress step 267300/300000 — loss 0.0027155 — PSNR 25.707\r\n",
      "[09:15:41] Progress step 267400/300000 — loss 0.0027019 — PSNR 25.726\r\n",
      "[09:15:43] Progress step 267500/300000 — loss 0.0027054 — PSNR 25.719\r\n",
      "[09:15:45] Progress step 267600/300000 — loss 0.0027043 — PSNR 25.721\r\n",
      "[09:15:46] Progress step 267700/300000 — loss 0.0026965 — PSNR 25.735\r\n",
      "[09:15:48] Progress step 267800/300000 — loss 0.0026892 — PSNR 25.747\r\n",
      "[09:15:49] Progress step 267900/300000 — loss 0.0026971 — PSNR 25.734\r\n",
      "[09:15:51] Progress step 268000/300000 — loss 0.0026994 — PSNR 25.730\r\n",
      "[09:15:51] Eval @ 268000: train_loss 0.0026994 — train_PSNR 25.730 — val_loss 0.0032751 — val_PSNR 24.848\r\n",
      "[09:15:53] Progress step 268100/300000 — loss 0.0027642 — PSNR 25.637\r\n",
      "[09:15:54] Progress step 268200/300000 — loss 0.0027218 — PSNR 25.693\r\n",
      "[09:15:56] Progress step 268300/300000 — loss 0.0027325 — PSNR 25.676\r\n",
      "[09:15:57] Progress step 268400/300000 — loss 0.0027282 — PSNR 25.683\r\n",
      "[09:15:59] Progress step 268500/300000 — loss 0.0027211 — PSNR 25.696\r\n",
      "[09:16:00] Progress step 268600/300000 — loss 0.0027056 — PSNR 25.721\r\n",
      "[09:16:02] Progress step 268700/300000 — loss 0.0027023 — PSNR 25.727\r\n",
      "[09:16:04] Progress step 268800/300000 — loss 0.0026953 — PSNR 25.738\r\n",
      "[09:16:05] Progress step 268900/300000 — loss 0.0026904 — PSNR 25.746\r\n",
      "[09:16:07] Progress step 269000/300000 — loss 0.0026869 — PSNR 25.753\r\n",
      "[09:16:26] Eval @ 269000: train_loss 0.0026869 — train_PSNR 25.753 — val_loss 0.0026553 — val_PSNR 26.381\r\n",
      "[09:16:27] Progress step 269100/300000 — loss 0.0026766 — PSNR 25.776\r\n",
      "[09:16:29] Progress step 269200/300000 — loss 0.0027082 — PSNR 25.719\r\n",
      "[09:16:31] Progress step 269300/300000 — loss 0.0027053 — PSNR 25.722\r\n",
      "[09:16:32] Progress step 269400/300000 — loss 0.0026933 — PSNR 25.738\r\n",
      "[09:16:34] Progress step 269500/300000 — loss 0.0026880 — PSNR 25.747\r\n",
      "[09:16:35] Progress step 269600/300000 — loss 0.0026950 — PSNR 25.735\r\n",
      "[09:16:37] Progress step 269700/300000 — loss 0.0026873 — PSNR 25.749\r\n",
      "[09:16:39] Progress step 269800/300000 — loss 0.0026820 — PSNR 25.758\r\n",
      "[09:16:40] Progress step 269900/300000 — loss 0.0026834 — PSNR 25.756\r\n",
      "[09:16:42] Progress step 270000/300000 — loss 0.0026889 — PSNR 25.747\r\n",
      "[09:16:42] Eval @ 270000: train_loss 0.0026889 — train_PSNR 25.747 — val_loss 0.0033065 — val_PSNR 24.806\r\n",
      "[09:16:43] Progress step 270100/300000 — loss 0.0026741 — PSNR 25.770\r\n",
      "[09:16:45] Progress step 270200/300000 — loss 0.0027039 — PSNR 25.727\r\n",
      "[09:16:47] Progress step 270300/300000 — loss 0.0026812 — PSNR 25.765\r\n",
      "[09:16:48] Progress step 270400/300000 — loss 0.0026910 — PSNR 25.747\r\n",
      "[09:16:50] Progress step 270500/300000 — loss 0.0026897 — PSNR 25.747\r\n",
      "[09:16:51] Progress step 270600/300000 — loss 0.0026946 — PSNR 25.740\r\n",
      "[09:16:53] Progress step 270700/300000 — loss 0.0026911 — PSNR 25.745\r\n",
      "[09:16:55] Progress step 270800/300000 — loss 0.0026845 — PSNR 25.756\r\n",
      "[09:16:56] Progress step 270900/300000 — loss 0.0026882 — PSNR 25.749\r\n",
      "[09:16:58] Progress step 271000/300000 — loss 0.0026942 — PSNR 25.740\r\n",
      "[09:17:16] Eval @ 271000: train_loss 0.0026942 — train_PSNR 25.740 — val_loss 0.0026473 — val_PSNR 26.398\r\n",
      "[09:17:18] Progress step 271100/300000 — loss 0.0026988 — PSNR 25.719\r\n",
      "[09:17:20] Progress step 271200/300000 — loss 0.0026506 — PSNR 25.802\r\n",
      "[09:17:21] Progress step 271300/300000 — loss 0.0026445 — PSNR 25.814\r\n",
      "[09:17:23] Progress step 271400/300000 — loss 0.0026698 — PSNR 25.776\r\n",
      "[09:17:24] Progress step 271500/300000 — loss 0.0026594 — PSNR 25.792\r\n",
      "[09:17:26] Progress step 271600/300000 — loss 0.0026683 — PSNR 25.777\r\n",
      "[09:17:28] Progress step 271700/300000 — loss 0.0026738 — PSNR 25.769\r\n",
      "[09:17:29] Progress step 271800/300000 — loss 0.0026719 — PSNR 25.772\r\n",
      "[09:17:31] Progress step 271900/300000 — loss 0.0026708 — PSNR 25.773\r\n",
      "[09:17:32] Progress step 272000/300000 — loss 0.0026758 — PSNR 25.765\r\n",
      "[09:17:32] Eval @ 272000: train_loss 0.0026758 — train_PSNR 25.765 — val_loss 0.0032990 — val_PSNR 24.816\r\n",
      "[09:17:34] Progress step 272100/300000 — loss 0.0026979 — PSNR 25.726\r\n",
      "[09:17:36] Progress step 272200/300000 — loss 0.0027197 — PSNR 25.692\r\n",
      "[09:17:37] Progress step 272300/300000 — loss 0.0027289 — PSNR 25.676\r\n",
      "[09:17:39] Progress step 272400/300000 — loss 0.0027143 — PSNR 25.699\r\n",
      "[09:17:40] Progress step 272500/300000 — loss 0.0027094 — PSNR 25.706\r\n",
      "[09:17:42] Progress step 272600/300000 — loss 0.0027120 — PSNR 25.703\r\n",
      "[09:17:43] Progress step 272700/300000 — loss 0.0027161 — PSNR 25.695\r\n",
      "[09:17:45] Progress step 272800/300000 — loss 0.0027054 — PSNR 25.713\r\n",
      "[09:17:47] Progress step 272900/300000 — loss 0.0027110 — PSNR 25.705\r\n",
      "[09:17:48] Progress step 273000/300000 — loss 0.0026980 — PSNR 25.727\r\n",
      "[09:18:07] Eval @ 273000: train_loss 0.0026980 — train_PSNR 25.727 — val_loss 0.0026464 — val_PSNR 26.400\r\n",
      "[09:18:09] Progress step 273100/300000 — loss 0.0026490 — PSNR 25.815\r\n",
      "[09:18:11] Progress step 273200/300000 — loss 0.0026573 — PSNR 25.801\r\n",
      "[09:18:12] Progress step 273300/300000 — loss 0.0026606 — PSNR 25.795\r\n",
      "[09:18:14] Progress step 273400/300000 — loss 0.0026612 — PSNR 25.794\r\n",
      "[09:18:15] Progress step 273500/300000 — loss 0.0026699 — PSNR 25.777\r\n",
      "[09:18:17] Progress step 273600/300000 — loss 0.0026767 — PSNR 25.766\r\n",
      "[09:18:19] Progress step 273700/300000 — loss 0.0026742 — PSNR 25.769\r\n",
      "[09:18:20] Progress step 273800/300000 — loss 0.0026760 — PSNR 25.767\r\n",
      "[09:18:22] Progress step 273900/300000 — loss 0.0026769 — PSNR 25.766\r\n",
      "[09:18:23] Progress step 274000/300000 — loss 0.0026812 — PSNR 25.759\r\n",
      "[09:18:23] Eval @ 274000: train_loss 0.0026812 — train_PSNR 25.759 — val_loss 0.0032790 — val_PSNR 24.843\r\n",
      "[09:18:25] Progress step 274100/300000 — loss 0.0026283 — PSNR 25.844\r\n",
      "[09:18:27] Progress step 274200/300000 — loss 0.0027259 — PSNR 25.686\r\n",
      "[09:18:28] Progress step 274300/300000 — loss 0.0026946 — PSNR 25.735\r\n",
      "[09:18:30] Progress step 274400/300000 — loss 0.0026979 — PSNR 25.729\r\n",
      "[09:18:31] Progress step 274500/300000 — loss 0.0026944 — PSNR 25.733\r\n",
      "[09:18:33] Progress step 274600/300000 — loss 0.0026981 — PSNR 25.727\r\n",
      "[09:18:35] Progress step 274700/300000 — loss 0.0026906 — PSNR 25.740\r\n",
      "[09:18:36] Progress step 274800/300000 — loss 0.0026925 — PSNR 25.737\r\n",
      "[09:18:38] Progress step 274900/300000 — loss 0.0026980 — PSNR 25.729\r\n",
      "[09:18:39] Progress step 275000/300000 — loss 0.0026896 — PSNR 25.743\r\n",
      "[09:18:58] Eval @ 275000: train_loss 0.0026896 — train_PSNR 25.743 — val_loss 0.0026640 — val_PSNR 26.362\r\n",
      "[09:19:00] Progress step 275100/300000 — loss 0.0026829 — PSNR 25.764\r\n",
      "[09:19:01] Progress step 275200/300000 — loss 0.0026667 — PSNR 25.781\r\n",
      "[09:19:03] Progress step 275300/300000 — loss 0.0026802 — PSNR 25.761\r\n",
      "[09:19:05] Progress step 275400/300000 — loss 0.0026849 — PSNR 25.753\r\n",
      "[09:19:06] Progress step 275500/300000 — loss 0.0026783 — PSNR 25.764\r\n",
      "[09:19:08] Progress step 275600/300000 — loss 0.0026838 — PSNR 25.756\r\n",
      "[09:19:09] Progress step 275700/300000 — loss 0.0026720 — PSNR 25.775\r\n",
      "[09:19:11] Progress step 275800/300000 — loss 0.0026747 — PSNR 25.770\r\n",
      "[09:19:13] Progress step 275900/300000 — loss 0.0026786 — PSNR 25.763\r\n",
      "[09:19:14] Progress step 276000/300000 — loss 0.0026748 — PSNR 25.769\r\n",
      "[09:19:14] Eval @ 276000: train_loss 0.0026748 — train_PSNR 25.769 — val_loss 0.0032848 — val_PSNR 24.835\r\n",
      "[09:19:16] Progress step 276100/300000 — loss 0.0026957 — PSNR 25.738\r\n",
      "[09:19:17] Progress step 276200/300000 — loss 0.0026647 — PSNR 25.791\r\n",
      "[09:19:19] Progress step 276300/300000 — loss 0.0026569 — PSNR 25.801\r\n",
      "[09:19:21] Progress step 276400/300000 — loss 0.0026574 — PSNR 25.800\r\n",
      "[09:19:22] Progress step 276500/300000 — loss 0.0026643 — PSNR 25.788\r\n",
      "[09:19:24] Progress step 276600/300000 — loss 0.0026543 — PSNR 25.803\r\n",
      "[09:19:25] Progress step 276700/300000 — loss 0.0026568 — PSNR 25.799\r\n",
      "[09:19:27] Progress step 276800/300000 — loss 0.0026632 — PSNR 25.790\r\n",
      "[09:19:29] Progress step 276900/300000 — loss 0.0026629 — PSNR 25.789\r\n",
      "[09:19:30] Progress step 277000/300000 — loss 0.0026624 — PSNR 25.791\r\n",
      "[09:19:49] Eval @ 277000: train_loss 0.0026624 — train_PSNR 25.791 — val_loss 0.0026504 — val_PSNR 26.391\r\n",
      "[09:19:51] Progress step 277100/300000 — loss 0.0026447 — PSNR 25.805\r\n",
      "[09:19:52] Progress step 277200/300000 — loss 0.0026480 — PSNR 25.808\r\n",
      "[09:19:54] Progress step 277300/300000 — loss 0.0026603 — PSNR 25.787\r\n",
      "[09:19:55] Progress step 277400/300000 — loss 0.0026880 — PSNR 25.746\r\n",
      "[09:19:57] Progress step 277500/300000 — loss 0.0026882 — PSNR 25.746\r\n",
      "[09:19:59] Progress step 277600/300000 — loss 0.0026902 — PSNR 25.743\r\n",
      "[09:20:00] Progress step 277700/300000 — loss 0.0026947 — PSNR 25.735\r\n",
      "[09:20:02] Progress step 277800/300000 — loss 0.0026958 — PSNR 25.734\r\n",
      "[09:20:03] Progress step 277900/300000 — loss 0.0026953 — PSNR 25.735\r\n",
      "[09:20:05] Progress step 278000/300000 — loss 0.0026895 — PSNR 25.745\r\n",
      "[09:20:05] Eval @ 278000: train_loss 0.0026895 — train_PSNR 25.745 — val_loss 0.0032786 — val_PSNR 24.843\r\n",
      "[09:20:06] Progress step 278100/300000 — loss 0.0026917 — PSNR 25.742\r\n",
      "[09:20:08] Progress step 278200/300000 — loss 0.0026938 — PSNR 25.734\r\n",
      "[09:20:10] Progress step 278300/300000 — loss 0.0026694 — PSNR 25.776\r\n",
      "[09:20:11] Progress step 278400/300000 — loss 0.0026596 — PSNR 25.788\r\n",
      "[09:20:13] Progress step 278500/300000 — loss 0.0026618 — PSNR 25.785\r\n",
      "[09:20:14] Progress step 278600/300000 — loss 0.0026592 — PSNR 25.789\r\n",
      "[09:20:16] Progress step 278700/300000 — loss 0.0026682 — PSNR 25.775\r\n",
      "[09:20:18] Progress step 278800/300000 — loss 0.0026617 — PSNR 25.785\r\n",
      "[09:20:19] Progress step 278900/300000 — loss 0.0026651 — PSNR 25.779\r\n",
      "[09:20:21] Progress step 279000/300000 — loss 0.0026695 — PSNR 25.773\r\n",
      "[09:20:40] Eval @ 279000: train_loss 0.0026695 — train_PSNR 25.773 — val_loss 0.0026606 — val_PSNR 26.369\r\n",
      "[09:20:41] Progress step 279100/300000 — loss 0.0027193 — PSNR 25.687\r\n",
      "[09:20:43] Progress step 279200/300000 — loss 0.0027098 — PSNR 25.705\r\n",
      "[09:20:44] Progress step 279300/300000 — loss 0.0027156 — PSNR 25.700\r\n",
      "[09:20:46] Progress step 279400/300000 — loss 0.0027111 — PSNR 25.709\r\n",
      "[09:20:48] Progress step 279500/300000 — loss 0.0027164 — PSNR 25.702\r\n",
      "[09:20:49] Progress step 279600/300000 — loss 0.0027118 — PSNR 25.710\r\n",
      "[09:20:51] Progress step 279700/300000 — loss 0.0027131 — PSNR 25.708\r\n",
      "[09:20:52] Progress step 279800/300000 — loss 0.0027154 — PSNR 25.705\r\n",
      "[09:20:54] Progress step 279900/300000 — loss 0.0027130 — PSNR 25.709\r\n",
      "[09:20:56] Progress step 280000/300000 — loss 0.0027064 — PSNR 25.719\r\n",
      "[09:20:56] Eval @ 280000: train_loss 0.0027064 — train_PSNR 25.719 — val_loss 0.0033116 — val_PSNR 24.800\r\n",
      "[09:20:57] Progress step 280100/300000 — loss 0.0026857 — PSNR 25.753\r\n",
      "[09:20:59] Progress step 280200/300000 — loss 0.0026795 — PSNR 25.762\r\n",
      "[09:21:01] Progress step 280300/300000 — loss 0.0026917 — PSNR 25.743\r\n",
      "[09:21:02] Progress step 280400/300000 — loss 0.0027000 — PSNR 25.727\r\n",
      "[09:21:04] Progress step 280500/300000 — loss 0.0026900 — PSNR 25.743\r\n",
      "[09:21:05] Progress step 280600/300000 — loss 0.0026891 — PSNR 25.746\r\n",
      "[09:21:07] Progress step 280700/300000 — loss 0.0026843 — PSNR 25.754\r\n",
      "[09:21:08] Progress step 280800/300000 — loss 0.0026845 — PSNR 25.752\r\n",
      "[09:21:10] Progress step 280900/300000 — loss 0.0026866 — PSNR 25.749\r\n",
      "[09:21:12] Progress step 281000/300000 — loss 0.0026876 — PSNR 25.746\r\n",
      "[09:21:30] Eval @ 281000: train_loss 0.0026876 — train_PSNR 25.746 — val_loss 0.0026465 — val_PSNR 26.400\r\n",
      "[09:21:32] Progress step 281100/300000 — loss 0.0027601 — PSNR 25.636\r\n",
      "[09:21:34] Progress step 281200/300000 — loss 0.0027243 — PSNR 25.693\r\n",
      "[09:21:35] Progress step 281300/300000 — loss 0.0027079 — PSNR 25.719\r\n",
      "[09:21:37] Progress step 281400/300000 — loss 0.0027130 — PSNR 25.712\r\n",
      "[09:21:38] Progress step 281500/300000 — loss 0.0027026 — PSNR 25.727\r\n",
      "[09:21:40] Progress step 281600/300000 — loss 0.0027061 — PSNR 25.721\r\n",
      "[09:21:42] Progress step 281700/300000 — loss 0.0027043 — PSNR 25.723\r\n",
      "[09:21:43] Progress step 281800/300000 — loss 0.0026983 — PSNR 25.733\r\n",
      "[09:21:45] Progress step 281900/300000 — loss 0.0026998 — PSNR 25.730\r\n",
      "[09:21:46] Progress step 282000/300000 — loss 0.0026976 — PSNR 25.733\r\n",
      "[09:21:46] Eval @ 282000: train_loss 0.0026976 — train_PSNR 25.733 — val_loss 0.0032730 — val_PSNR 24.851\r\n",
      "[09:21:48] Progress step 282100/300000 — loss 0.0026348 — PSNR 25.826\r\n",
      "[09:21:50] Progress step 282200/300000 — loss 0.0026908 — PSNR 25.738\r\n",
      "[09:21:51] Progress step 282300/300000 — loss 0.0026881 — PSNR 25.745\r\n",
      "[09:21:53] Progress step 282400/300000 — loss 0.0027158 — PSNR 25.703\r\n",
      "[09:21:54] Progress step 282500/300000 — loss 0.0027163 — PSNR 25.703\r\n",
      "[09:21:56] Progress step 282600/300000 — loss 0.0027127 — PSNR 25.709\r\n",
      "[09:21:58] Progress step 282700/300000 — loss 0.0026950 — PSNR 25.738\r\n",
      "[09:21:59] Progress step 282800/300000 — loss 0.0026937 — PSNR 25.739\r\n",
      "[09:22:01] Progress step 282900/300000 — loss 0.0026960 — PSNR 25.736\r\n",
      "[09:22:02] Progress step 283000/300000 — loss 0.0026854 — PSNR 25.752\r\n",
      "[09:22:21] Eval @ 283000: train_loss 0.0026854 — train_PSNR 25.752 — val_loss 0.0026483 — val_PSNR 26.396\r\n",
      "[09:22:23] Progress step 283100/300000 — loss 0.0026320 — PSNR 25.841\r\n",
      "[09:22:25] Progress step 283200/300000 — loss 0.0026367 — PSNR 25.829\r\n",
      "[09:22:26] Progress step 283300/300000 — loss 0.0026382 — PSNR 25.830\r\n",
      "[09:22:28] Progress step 283400/300000 — loss 0.0026532 — PSNR 25.805\r\n",
      "[09:22:29] Progress step 283500/300000 — loss 0.0026582 — PSNR 25.796\r\n",
      "[09:22:31] Progress step 283600/300000 — loss 0.0026572 — PSNR 25.795\r\n",
      "[09:22:33] Progress step 283700/300000 — loss 0.0026676 — PSNR 25.779\r\n",
      "[09:22:34] Progress step 283800/300000 — loss 0.0026733 — PSNR 25.771\r\n",
      "[09:22:36] Progress step 283900/300000 — loss 0.0026743 — PSNR 25.769\r\n",
      "[09:22:37] Progress step 284000/300000 — loss 0.0026804 — PSNR 25.759\r\n",
      "[09:22:37] Eval @ 284000: train_loss 0.0026804 — train_PSNR 25.759 — val_loss 0.0032753 — val_PSNR 24.847\r\n",
      "[09:22:39] Progress step 284100/300000 — loss 0.0027047 — PSNR 25.728\r\n",
      "[09:22:41] Progress step 284200/300000 — loss 0.0026942 — PSNR 25.737\r\n",
      "[09:22:42] Progress step 284300/300000 — loss 0.0026891 — PSNR 25.745\r\n",
      "[09:22:44] Progress step 284400/300000 — loss 0.0026804 — PSNR 25.760\r\n",
      "[09:22:45] Progress step 284500/300000 — loss 0.0026724 — PSNR 25.774\r\n",
      "[09:22:47] Progress step 284600/300000 — loss 0.0026718 — PSNR 25.775\r\n",
      "[09:22:49] Progress step 284700/300000 — loss 0.0026667 — PSNR 25.784\r\n",
      "[09:22:50] Progress step 284800/300000 — loss 0.0026660 — PSNR 25.784\r\n",
      "[09:22:52] Progress step 284900/300000 — loss 0.0026679 — PSNR 25.781\r\n",
      "[09:22:53] Progress step 285000/300000 — loss 0.0026759 — PSNR 25.768\r\n",
      "[09:23:12] Eval @ 285000: train_loss 0.0026759 — train_PSNR 25.768 — val_loss 0.0026475 — val_PSNR 26.397\r\n",
      "[09:23:14] Progress step 285100/300000 — loss 0.0026517 — PSNR 25.802\r\n",
      "[09:23:15] Progress step 285200/300000 — loss 0.0027252 — PSNR 25.685\r\n",
      "[09:23:17] Progress step 285300/300000 — loss 0.0027034 — PSNR 25.725\r\n",
      "[09:23:19] Progress step 285400/300000 — loss 0.0027090 — PSNR 25.715\r\n",
      "[09:23:20] Progress step 285500/300000 — loss 0.0027054 — PSNR 25.719\r\n",
      "[09:23:22] Progress step 285600/300000 — loss 0.0026916 — PSNR 25.742\r\n",
      "[09:23:23] Progress step 285700/300000 — loss 0.0026917 — PSNR 25.743\r\n",
      "[09:23:25] Progress step 285800/300000 — loss 0.0026866 — PSNR 25.751\r\n",
      "[09:23:27] Progress step 285900/300000 — loss 0.0026898 — PSNR 25.745\r\n",
      "[09:23:28] Progress step 286000/300000 — loss 0.0026863 — PSNR 25.751\r\n",
      "[09:23:28] Eval @ 286000: train_loss 0.0026863 — train_PSNR 25.751 — val_loss 0.0032981 — val_PSNR 24.817\r\n",
      "[09:23:30] Progress step 286100/300000 — loss 0.0027059 — PSNR 25.721\r\n",
      "[09:23:31] Progress step 286200/300000 — loss 0.0026985 — PSNR 25.729\r\n",
      "[09:23:33] Progress step 286300/300000 — loss 0.0026954 — PSNR 25.738\r\n",
      "[09:23:35] Progress step 286400/300000 — loss 0.0026806 — PSNR 25.763\r\n",
      "[09:23:36] Progress step 286500/300000 — loss 0.0026682 — PSNR 25.781\r\n",
      "[09:23:38] Progress step 286600/300000 — loss 0.0026749 — PSNR 25.770\r\n",
      "[09:23:39] Progress step 286700/300000 — loss 0.0026859 — PSNR 25.753\r\n",
      "[09:23:41] Progress step 286800/300000 — loss 0.0026987 — PSNR 25.733\r\n",
      "[09:23:43] Progress step 286900/300000 — loss 0.0026998 — PSNR 25.732\r\n",
      "[09:23:44] Progress step 287000/300000 — loss 0.0027031 — PSNR 25.726\r\n",
      "[09:24:03] Eval @ 287000: train_loss 0.0027031 — train_PSNR 25.726 — val_loss 0.0026468 — val_PSNR 26.399\r\n",
      "[09:24:05] Progress step 287100/300000 — loss 0.0026669 — PSNR 25.775\r\n",
      "[09:24:06] Progress step 287200/300000 — loss 0.0026617 — PSNR 25.788\r\n",
      "[09:24:08] Progress step 287300/300000 — loss 0.0026694 — PSNR 25.774\r\n",
      "[09:24:10] Progress step 287400/300000 — loss 0.0026724 — PSNR 25.772\r\n",
      "[09:24:11] Progress step 287500/300000 — loss 0.0026800 — PSNR 25.760\r\n",
      "[09:24:13] Progress step 287600/300000 — loss 0.0026872 — PSNR 25.748\r\n",
      "[09:24:14] Progress step 287700/300000 — loss 0.0026928 — PSNR 25.739\r\n",
      "[09:24:16] Progress step 287800/300000 — loss 0.0026970 — PSNR 25.733\r\n",
      "[09:24:18] Progress step 287900/300000 — loss 0.0026948 — PSNR 25.736\r\n",
      "[09:24:19] Progress step 288000/300000 — loss 0.0026921 — PSNR 25.740\r\n",
      "[09:24:19] Eval @ 288000: train_loss 0.0026921 — train_PSNR 25.740 — val_loss 0.0032893 — val_PSNR 24.829\r\n",
      "[09:24:21] Progress step 288100/300000 — loss 0.0026616 — PSNR 25.784\r\n",
      "[09:24:22] Progress step 288200/300000 — loss 0.0026786 — PSNR 25.754\r\n",
      "[09:24:24] Progress step 288300/300000 — loss 0.0026711 — PSNR 25.767\r\n",
      "[09:24:26] Progress step 288400/300000 — loss 0.0026856 — PSNR 25.747\r\n",
      "[09:24:27] Progress step 288500/300000 — loss 0.0026719 — PSNR 25.771\r\n",
      "[09:24:29] Progress step 288600/300000 — loss 0.0026791 — PSNR 25.761\r\n",
      "[09:24:30] Progress step 288700/300000 — loss 0.0026798 — PSNR 25.759\r\n",
      "[09:24:32] Progress step 288800/300000 — loss 0.0026818 — PSNR 25.755\r\n",
      "[09:24:33] Progress step 288900/300000 — loss 0.0026718 — PSNR 25.772\r\n",
      "[09:24:35] Progress step 289000/300000 — loss 0.0026705 — PSNR 25.774\r\n",
      "[09:24:54] Eval @ 289000: train_loss 0.0026705 — train_PSNR 25.774 — val_loss 0.0026475 — val_PSNR 26.397\r\n",
      "[09:24:55] Progress step 289100/300000 — loss 0.0026453 — PSNR 25.813\r\n",
      "[09:24:57] Progress step 289200/300000 — loss 0.0026752 — PSNR 25.768\r\n",
      "[09:24:59] Progress step 289300/300000 — loss 0.0026709 — PSNR 25.775\r\n",
      "[09:25:00] Progress step 289400/300000 — loss 0.0026606 — PSNR 25.791\r\n",
      "[09:25:02] Progress step 289500/300000 — loss 0.0026550 — PSNR 25.801\r\n",
      "[09:25:03] Progress step 289600/300000 — loss 0.0026618 — PSNR 25.790\r\n",
      "[09:25:05] Progress step 289700/300000 — loss 0.0026592 — PSNR 25.794\r\n",
      "[09:25:07] Progress step 289800/300000 — loss 0.0026604 — PSNR 25.793\r\n",
      "[09:25:08] Progress step 289900/300000 — loss 0.0026645 — PSNR 25.786\r\n",
      "[09:25:10] Progress step 290000/300000 — loss 0.0026654 — PSNR 25.785\r\n",
      "[09:25:10] Eval @ 290000: train_loss 0.0026654 — train_PSNR 25.785 — val_loss 0.0032994 — val_PSNR 24.816\r\n",
      "[09:25:11] Progress step 290100/300000 — loss 0.0026734 — PSNR 25.771\r\n",
      "[09:25:13] Progress step 290200/300000 — loss 0.0026697 — PSNR 25.779\r\n",
      "[09:25:15] Progress step 290300/300000 — loss 0.0026651 — PSNR 25.786\r\n",
      "[09:25:16] Progress step 290400/300000 — loss 0.0026853 — PSNR 25.753\r\n",
      "[09:25:18] Progress step 290500/300000 — loss 0.0026839 — PSNR 25.757\r\n",
      "[09:25:19] Progress step 290600/300000 — loss 0.0026817 — PSNR 25.760\r\n",
      "[09:25:21] Progress step 290700/300000 — loss 0.0026735 — PSNR 25.774\r\n",
      "[09:25:23] Progress step 290800/300000 — loss 0.0026783 — PSNR 25.765\r\n",
      "[09:25:24] Progress step 290900/300000 — loss 0.0026862 — PSNR 25.753\r\n",
      "[09:25:26] Progress step 291000/300000 — loss 0.0026895 — PSNR 25.748\r\n",
      "[09:25:44] Eval @ 291000: train_loss 0.0026895 — train_PSNR 25.748 — val_loss 0.0026458 — val_PSNR 26.401\r\n",
      "[09:25:44] Saved best model at step 291000\r\n",
      "[09:25:46] Progress step 291100/300000 — loss 0.0026227 — PSNR 25.850\r\n",
      "[09:25:48] Progress step 291200/300000 — loss 0.0026473 — PSNR 25.812\r\n",
      "[09:25:49] Progress step 291300/300000 — loss 0.0026752 — PSNR 25.766\r\n",
      "[09:25:51] Progress step 291400/300000 — loss 0.0026626 — PSNR 25.786\r\n",
      "[09:25:53] Progress step 291500/300000 — loss 0.0026628 — PSNR 25.788\r\n",
      "[09:25:54] Progress step 291600/300000 — loss 0.0026650 — PSNR 25.785\r\n",
      "[09:25:56] Progress step 291700/300000 — loss 0.0026720 — PSNR 25.773\r\n",
      "[09:25:57] Progress step 291800/300000 — loss 0.0026734 — PSNR 25.771\r\n",
      "[09:25:59] Progress step 291900/300000 — loss 0.0026783 — PSNR 25.762\r\n",
      "[09:26:01] Progress step 292000/300000 — loss 0.0026808 — PSNR 25.759\r\n",
      "[09:26:01] Eval @ 292000: train_loss 0.0026808 — train_PSNR 25.759 — val_loss 0.0032823 — val_PSNR 24.838\r\n",
      "[09:26:02] Progress step 292100/300000 — loss 0.0026812 — PSNR 25.757\r\n",
      "[09:26:04] Progress step 292200/300000 — loss 0.0027008 — PSNR 25.732\r\n",
      "[09:26:05] Progress step 292300/300000 — loss 0.0027032 — PSNR 25.726\r\n",
      "[09:26:07] Progress step 292400/300000 — loss 0.0026896 — PSNR 25.746\r\n",
      "[09:26:09] Progress step 292500/300000 — loss 0.0026829 — PSNR 25.757\r\n",
      "[09:26:10] Progress step 292600/300000 — loss 0.0026913 — PSNR 25.742\r\n",
      "[09:26:12] Progress step 292700/300000 — loss 0.0026830 — PSNR 25.756\r\n",
      "[09:26:13] Progress step 292800/300000 — loss 0.0026736 — PSNR 25.772\r\n",
      "[09:26:15] Progress step 292900/300000 — loss 0.0026761 — PSNR 25.768\r\n",
      "[09:26:17] Progress step 293000/300000 — loss 0.0026740 — PSNR 25.772\r\n",
      "[09:26:35] Eval @ 293000: train_loss 0.0026740 — train_PSNR 25.772 — val_loss 0.0026458 — val_PSNR 26.401\r\n",
      "[09:26:35] Saved best model at step 293000\r\n",
      "[09:26:37] Progress step 293100/300000 — loss 0.0026394 — PSNR 25.830\r\n",
      "[09:26:39] Progress step 293200/300000 — loss 0.0026522 — PSNR 25.809\r\n",
      "[09:26:40] Progress step 293300/300000 — loss 0.0026480 — PSNR 25.816\r\n",
      "[09:26:42] Progress step 293400/300000 — loss 0.0026608 — PSNR 25.796\r\n",
      "[09:26:43] Progress step 293500/300000 — loss 0.0026690 — PSNR 25.781\r\n",
      "[09:26:45] Progress step 293600/300000 — loss 0.0026699 — PSNR 25.779\r\n",
      "[09:26:47] Progress step 293700/300000 — loss 0.0026697 — PSNR 25.779\r\n",
      "[09:26:48] Progress step 293800/300000 — loss 0.0026777 — PSNR 25.765\r\n",
      "[09:26:50] Progress step 293900/300000 — loss 0.0026815 — PSNR 25.760\r\n",
      "[09:26:51] Progress step 294000/300000 — loss 0.0026801 — PSNR 25.761\r\n",
      "[09:26:51] Eval @ 294000: train_loss 0.0026801 — train_PSNR 25.761 — val_loss 0.0032873 — val_PSNR 24.832\r\n",
      "[09:26:53] Progress step 294100/300000 — loss 0.0026823 — PSNR 25.752\r\n",
      "[09:26:55] Progress step 294200/300000 — loss 0.0026962 — PSNR 25.733\r\n",
      "[09:26:56] Progress step 294300/300000 — loss 0.0026958 — PSNR 25.733\r\n",
      "[09:26:58] Progress step 294400/300000 — loss 0.0026868 — PSNR 25.745\r\n",
      "[09:26:59] Progress step 294500/300000 — loss 0.0026841 — PSNR 25.750\r\n",
      "[09:27:01] Progress step 294600/300000 — loss 0.0026936 — PSNR 25.734\r\n",
      "[09:27:03] Progress step 294700/300000 — loss 0.0026874 — PSNR 25.745\r\n",
      "[09:27:04] Progress step 294800/300000 — loss 0.0026846 — PSNR 25.750\r\n",
      "[09:27:06] Progress step 294900/300000 — loss 0.0026899 — PSNR 25.743\r\n",
      "[09:27:07] Progress step 295000/300000 — loss 0.0026900 — PSNR 25.742\r\n",
      "[09:27:26] Eval @ 295000: train_loss 0.0026900 — train_PSNR 25.742 — val_loss 0.0026543 — val_PSNR 26.383\r\n",
      "[09:27:28] Progress step 295100/300000 — loss 0.0027296 — PSNR 25.673\r\n",
      "[09:27:30] Progress step 295200/300000 — loss 0.0027252 — PSNR 25.683\r\n",
      "[09:27:31] Progress step 295300/300000 — loss 0.0026913 — PSNR 25.739\r\n",
      "[09:27:33] Progress step 295400/300000 — loss 0.0026850 — PSNR 25.752\r\n",
      "[09:27:35] Progress step 295500/300000 — loss 0.0026868 — PSNR 25.748\r\n",
      "[09:27:36] Progress step 295600/300000 — loss 0.0026986 — PSNR 25.729\r\n",
      "[09:27:38] Progress step 295700/300000 — loss 0.0026981 — PSNR 25.729\r\n",
      "[09:27:39] Progress step 295800/300000 — loss 0.0027020 — PSNR 25.723\r\n",
      "[09:27:41] Progress step 295900/300000 — loss 0.0027009 — PSNR 25.725\r\n",
      "[09:27:43] Progress step 296000/300000 — loss 0.0026999 — PSNR 25.727\r\n",
      "[09:27:43] Eval @ 296000: train_loss 0.0026999 — train_PSNR 25.727 — val_loss 0.0032882 — val_PSNR 24.830\r\n",
      "[09:27:44] Progress step 296100/300000 — loss 0.0026519 — PSNR 25.818\r\n",
      "[09:27:46] Progress step 296200/300000 — loss 0.0026619 — PSNR 25.797\r\n",
      "[09:27:47] Progress step 296300/300000 — loss 0.0026767 — PSNR 25.770\r\n",
      "[09:27:49] Progress step 296400/300000 — loss 0.0026862 — PSNR 25.755\r\n",
      "[09:27:51] Progress step 296500/300000 — loss 0.0026801 — PSNR 25.764\r\n",
      "[09:27:52] Progress step 296600/300000 — loss 0.0026840 — PSNR 25.757\r\n",
      "[09:27:54] Progress step 296700/300000 — loss 0.0026809 — PSNR 25.761\r\n",
      "[09:27:55] Progress step 296800/300000 — loss 0.0026793 — PSNR 25.763\r\n",
      "[09:27:57] Progress step 296900/300000 — loss 0.0026824 — PSNR 25.758\r\n",
      "[09:27:59] Progress step 297000/300000 — loss 0.0026871 — PSNR 25.751\r\n",
      "[09:28:18] Eval @ 297000: train_loss 0.0026871 — train_PSNR 25.751 — val_loss 0.0026490 — val_PSNR 26.394\r\n",
      "[09:28:19] Progress step 297100/300000 — loss 0.0026331 — PSNR 25.847\r\n",
      "[09:28:21] Progress step 297200/300000 — loss 0.0026749 — PSNR 25.770\r\n",
      "[09:28:22] Progress step 297300/300000 — loss 0.0026824 — PSNR 25.759\r\n",
      "[09:28:24] Progress step 297400/300000 — loss 0.0026710 — PSNR 25.778\r\n",
      "[09:28:26] Progress step 297500/300000 — loss 0.0026731 — PSNR 25.772\r\n",
      "[09:28:27] Progress step 297600/300000 — loss 0.0026796 — PSNR 25.761\r\n",
      "[09:28:29] Progress step 297700/300000 — loss 0.0026730 — PSNR 25.772\r\n",
      "[09:28:31] Progress step 297800/300000 — loss 0.0026733 — PSNR 25.770\r\n",
      "[09:28:32] Progress step 297900/300000 — loss 0.0026730 — PSNR 25.769\r\n",
      "[09:28:34] Progress step 298000/300000 — loss 0.0026777 — PSNR 25.761\r\n",
      "[09:28:34] Eval @ 298000: train_loss 0.0026777 — train_PSNR 25.761 — val_loss 0.0032815 — val_PSNR 24.839\r\n",
      "[09:28:35] Progress step 298100/300000 — loss 0.0026516 — PSNR 25.799\r\n",
      "[09:28:37] Progress step 298200/300000 — loss 0.0026735 — PSNR 25.763\r\n",
      "[09:28:39] Progress step 298300/300000 — loss 0.0026878 — PSNR 25.743\r\n",
      "[09:28:40] Progress step 298400/300000 — loss 0.0026915 — PSNR 25.738\r\n",
      "[09:28:42] Progress step 298500/300000 — loss 0.0026744 — PSNR 25.767\r\n",
      "[09:28:43] Progress step 298600/300000 — loss 0.0026828 — PSNR 25.754\r\n",
      "[09:28:45] Progress step 298700/300000 — loss 0.0026903 — PSNR 25.741\r\n",
      "[09:28:47] Progress step 298800/300000 — loss 0.0026995 — PSNR 25.727\r\n",
      "[09:28:48] Progress step 298900/300000 — loss 0.0027045 — PSNR 25.720\r\n",
      "[09:28:50] Progress step 299000/300000 — loss 0.0026979 — PSNR 25.731\r\n",
      "[09:29:09] Eval @ 299000: train_loss 0.0026979 — train_PSNR 25.731 — val_loss 0.0026461 — val_PSNR 26.400\r\n",
      "[09:29:10] Progress step 299100/300000 — loss 0.0026534 — PSNR 25.808\r\n",
      "[09:29:12] Progress step 299200/300000 — loss 0.0026439 — PSNR 25.824\r\n",
      "[09:29:14] Progress step 299300/300000 — loss 0.0026613 — PSNR 25.797\r\n",
      "[09:29:15] Progress step 299400/300000 — loss 0.0026716 — PSNR 25.781\r\n",
      "[09:29:17] Progress step 299500/300000 — loss 0.0026779 — PSNR 25.768\r\n",
      "[09:29:18] Progress step 299600/300000 — loss 0.0026683 — PSNR 25.783\r\n",
      "[09:29:20] Progress step 299700/300000 — loss 0.0026696 — PSNR 25.781\r\n",
      "[09:29:22] Progress step 299800/300000 — loss 0.0026688 — PSNR 25.780\r\n",
      "[09:29:23] Progress step 299900/300000 — loss 0.0026746 — PSNR 25.771\r\n",
      "[09:29:25] Progress step 300000/300000 — loss 0.0026756 — PSNR 25.769\r\n",
      "[09:29:25] Eval @ 300000: train_loss 0.0026756 — train_PSNR 25.769 — val_loss 0.0032779 — val_PSNR 24.844\r\n",
      "[09:29:25] Training complete.\r\n"
     ]
    }
   ],
   "source": [
    "# train SRCNN-955 model\n",
    "!rm -rf dataset/*.npy\n",
    "!python train.py  --steps=300000                    \\\n",
    "                  --architecture=\"955\"              \\\n",
    "                  --batch_size=512                  \\\n",
    "                  --save-best-only=1                \\\n",
    "                  --save-every=1000                 \\\n",
    "                  --save-log=1                      \\\n",
    "                  --ckpt-dir=\"checkpoint/SRCNN955\"  \\\n",
    "                  --num-worker=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b5f6e",
   "metadata": {
    "papermill": {
     "duration": 0.134283,
     "end_time": "2025-05-03T09:29:28.977300",
     "exception": false,
     "start_time": "2025-05-03T09:29:28.843017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b739cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T09:29:29.244022Z",
     "iopub.status.busy": "2025-05-03T09:29:29.243429Z",
     "iopub.status.idle": "2025-05-03T09:29:41.496349Z",
     "shell.execute_reply": "2025-05-03T09:29:41.495598Z"
    },
    "papermill": {
     "duration": 12.388259,
     "end_time": "2025-05-03T09:29:41.497744",
     "exception": false,
     "start_time": "2025-05-03T09:29:29.109485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.2664306640625\r\n",
      "16.26265106201172\r\n",
      "16.26767578125\r\n"
     ]
    }
   ],
   "source": [
    "# Test on Set5\n",
    "!python test.py --scale=2 --architecture=955 --ckpt-path=\"default\"\n",
    "!python test.py --scale=3 --architecture=955 --ckpt-path=\"default\"\n",
    "!python test.py --scale=4 --architecture=955 --ckpt-path=\"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6093030c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T09:29:41.763670Z",
     "iopub.status.busy": "2025-05-03T09:29:41.763397Z",
     "iopub.status.idle": "2025-05-03T09:29:54.899601Z",
     "shell.execute_reply": "2025-05-03T09:29:54.898874Z"
    },
    "papermill": {
     "duration": 13.270033,
     "end_time": "2025-05-03T09:29:54.901097",
     "exception": false,
     "start_time": "2025-05-03T09:29:41.631064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.232242584228516\r\n",
      "20.23294194539388\r\n",
      "20.232686360677082\r\n"
     ]
    }
   ],
   "source": [
    "# Test on FLIR data\n",
    "!python test-ir.py --scale=2 --architecture=955 --ckpt-path=\"default\"\n",
    "!python test-ir.py --scale=3 --architecture=955 --ckpt-path=\"default\"\n",
    "!python test-ir.py --scale=4 --architecture=955 --ckpt-path=\"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289e08c",
   "metadata": {
    "id": "HNMxCqEnIm5B",
    "papermill": {
     "duration": 0.130612,
     "end_time": "2025-05-03T09:29:55.161672",
     "exception": false,
     "start_time": "2025-05-03T09:29:55.031060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Demo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99745d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T09:29:55.484346Z",
     "iopub.status.busy": "2025-05-03T09:29:55.484067Z",
     "iopub.status.idle": "2025-05-03T09:29:59.678690Z",
     "shell.execute_reply": "2025-05-03T09:29:59.677621Z"
    },
    "id": "j2bJTpBek-Ic",
    "papermill": {
     "duration": 4.390706,
     "end_time": "2025-05-03T09:29:59.680406",
     "exception": false,
     "start_time": "2025-05-03T09:29:55.289700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python demo.py --image-path=\"dataset/test1.png\" \\\n",
    "                --architecture=\"955\"             \\\n",
    "                --ckpt-path=\"default\"            \\\n",
    "                --scale=4"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOFelCBfes8SA3E/Qh6kLE4",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SRCNN-Pytorch.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7945.950387,
   "end_time": "2025-05-03T09:30:00.190586",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-03T07:17:34.240199",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
